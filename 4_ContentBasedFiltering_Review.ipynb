{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ContentBasedFiltering - Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from ast import literal_eval\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics, svm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "df_re = pd.read_csv('data/df_reT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1863906 entries, 0 to 1863905\n",
      "Data columns (total 5 columns):\n",
      "asin          1863906 non-null object\n",
      "title         1863906 non-null object\n",
      "reviewerID    1863906 non-null object\n",
      "overall       1863906 non-null float64\n",
      "review        1863906 non-null object\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 71.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_re.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000N6DDJQ</td>\n",
       "      <td>The Scarlet Letter A Romance</td>\n",
       "      <td>A1D2C0WDCSHUWZ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>When people think of a \"scarlet letter,\" we im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000N6DDJQ</td>\n",
       "      <td>The Scarlet Letter A Romance</td>\n",
       "      <td>A2M3NCTFUGI4SR</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Hawthorne's best work is central to understand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000N6DDJQ</td>\n",
       "      <td>The Scarlet Letter A Romance</td>\n",
       "      <td>A1OXI0N58TMYY9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is a review for not the novel itself but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0006DG9OM</td>\n",
       "      <td>Tess of the D'Urbervilles: A pure woman (Harpe...</td>\n",
       "      <td>AZ05JR3XQN9IP</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A question that often appears in agony aunt co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0006DG9OM</td>\n",
       "      <td>Tess of the D'Urbervilles: A pure woman (Harpe...</td>\n",
       "      <td>A1R77GO77FBLMJ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Truly an excellently written book. From the ve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                                              title  \\\n",
       "0  B000N6DDJQ                       The Scarlet Letter A Romance   \n",
       "1  B000N6DDJQ                       The Scarlet Letter A Romance   \n",
       "2  B000N6DDJQ                       The Scarlet Letter A Romance   \n",
       "3  B0006DG9OM  Tess of the D'Urbervilles: A pure woman (Harpe...   \n",
       "4  B0006DG9OM  Tess of the D'Urbervilles: A pure woman (Harpe...   \n",
       "\n",
       "       reviewerID  overall                                             review  \n",
       "0  A1D2C0WDCSHUWZ      5.0  When people think of a \"scarlet letter,\" we im...  \n",
       "1  A2M3NCTFUGI4SR      5.0  Hawthorne's best work is central to understand...  \n",
       "2  A1OXI0N58TMYY9      5.0  This is a review for not the novel itself but ...  \n",
       "3   AZ05JR3XQN9IP      5.0  A question that often appears in agony aunt co...  \n",
       "4  A1R77GO77FBLMJ      5.0  Truly an excellently written book. From the ve...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_re.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will be using the tf-idf vectorizer to build a term frequency matrix for the review data, it is important to alter the pure review text into a format that the vectorizer can use. <br>\n",
    "These include removing any special characters, keeping all texts in lower-case.<br> Also tokenizing the documents in to lists of words and removing stopwords that will only decrease accuracy.\n",
    "\n",
    "In this review text, we will not consider bigram or higher form of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Takes in text\n",
    "\n",
    "Outputs text with all lower case and special characters removed\n",
    "'''\n",
    "def cleanText(t):\n",
    "    \n",
    "    #change to lower case\n",
    "    t = str(t).lower()\n",
    "    #remove special characters\n",
    "    t = re.sub(\"(\\\\W)+\",\" \",t)\n",
    "    \n",
    "    return t\n",
    "\n",
    "\n",
    "#build stopwords\n",
    "eng_stopwords = set(stopwords.words('english') + ['book','books','author','authors'])\n",
    "\n",
    "\n",
    "'''\n",
    "Takes in text\n",
    "\n",
    "Outputs tokenized text with stopwords removed\n",
    "'''\n",
    "def removeStopwords(t,stopwords = eng_stopwords):\n",
    "    \n",
    "    #tokenize : only single words, no n-grams\n",
    "    t = word_tokenize(t,language='english')\n",
    "    \n",
    "    filtered = []\n",
    "    \n",
    "    for word in t:\n",
    "        if word not in stopwords:\n",
    "            filtered.append(word)\n",
    "    \n",
    "    \n",
    "    return filtered\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Column 'title'**\n",
    "\n",
    "Both title and asin are unique identifiers for books in our dataset. Therefore, they represent redundant data.  <br> Since asin is easier to maintain and smaller in size, we will strip out the unique asin-title to a seperate dataframe and remove the title column from review dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up asin, title, reviewerID\n",
    "df_re['asin'] = df_re['asin'].apply(lambda x: x.lower())\n",
    "df_re['title'] = df_re['title'].apply(lambda x: cleanText(x))\n",
    "df_re['reviewerID'] = df_re['reviewerID'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate unique asin-title\n",
    "asin_title = df_re[['asin','title']].drop_duplicates(keep='first')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop redundant title \n",
    "df_re.drop(columns='title',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Column 'review'**\n",
    "\n",
    "This is the field to be used for review content-based filtering, therefore will be transformed to td-idf vectorizer.\n",
    "\n",
    "We will need to create a set of stopwords that we can use to filter out some word that may not be useful during modeling. <br> Aside from the regular english stopwords, we will also add words that are specific to book genre as it will cause unnecessary importance.  <br> Some examples are book, books, author, authors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up review\n",
    "df_re['review'] = df_re['review'].apply(lambda x: cleanText(x))\n",
    "\n",
    "#build stopwords\n",
    "eng_stopwords = set(stopwords.words('english') + ['book','books','author','authors'])\n",
    "\n",
    "\n",
    "#tokenize and remove stopwords\n",
    "df_re['review'] = df_re['review'].apply(lambda x: removeStopwords(x, eng_stopwords))\n",
    "\n",
    "#lemmatize each work token to root word given we know the pos_tag of the word\n",
    "df_re['review_lemmatized'] = df_re['review'].apply(lambda x: lemmatize_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up review\n",
    "df_re['review'] = df_re['review'].apply(lambda x: cleanText(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build stopwords\n",
    "eng_stopwords = set(stopwords.words('english') + ['book','books','author','authors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize and remove stopwords\n",
    "df_re['review'] = df_re['review'].apply(lambda x: removeStopwords(x, eng_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will lemmatize the tokens to their root word\n",
    "\n",
    "'''\n",
    "Takes in word\n",
    "\n",
    "Outputs the word's POS_tag: v, a, n, r\n",
    "'''\n",
    "def get_wordnet_pos(word):\n",
    "\n",
    "    #get first letter of word tag\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    \n",
    "    #create simple dict to associate tag to wordnet attributes   \n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV,\n",
    "                \"C\": wordnet.NOUN,\n",
    "                \"S\": wordnet.ADJ_SAT}\n",
    "\n",
    "    #we put a conditional here to account for cases where tag is not within expected range\n",
    "    if tag_dict.get(tag):\n",
    "        return tag_dict.get(tag)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "#initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_words(words):\n",
    "    \n",
    "    #lemmatize the list of words provided\n",
    "    return [lemmatizer.lemmatize(w, get_wordnet_pos(w)) if get_wordnet_pos(w) != '' else lemmatizer.lemmatize(w) for w in words]\n",
    "    \n",
    "#does nothing\n",
    "def dummy(doc):\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatize each work token to root word given we know the pos_tag of the word\n",
    "df_re['review_lemmatized'] = df_re['review'].apply(lambda x: lemmatize_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization process took about 12 hours to complete. <br> Aside from stemming, lemmatization was the best choice to move forward in dealing with variation of same root words. <br> Stemming showed the results in much too simplified fashion so decision was made to go with lemmatization although resource-heavy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 CountVectorizer Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saved for checkpoint\n",
    "df_re.to_csv('data/reT_tokenized.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when reading in our word list again, pandas parses it as string instead of list of words.\n",
    "#using literal_eval to fix this\n",
    "df_re = pd.read_csv('data/reT_tokenized.csv',converters={'review_lemmatized': literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate documents into corpora\n",
    "corpora = df_re['review_lemmatized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate CountVectorizer with default settings: no lower casing, preprocessing or tokenizing.\n",
    "vectorizer = CountVectorizer(lowercase=False,preprocessor=dummy, tokenizer=dummy)\n",
    "\n",
    "#tokenize and build vocab fitting the corpora then tranform to make count vector\n",
    "count_vector = vectorizer.fit_transform(corpora)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the vectorizer, we can see that we get back an expected number of sparse matrix rows as this is the number of documents in our corpora.  <br> We can also see that we have a total of 199638 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of vocab:  199638\n"
     ]
    }
   ],
   "source": [
    "print('number of vocab: ', len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_vocab = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since these vocabularies are sorted in alphabetical oder, we will slice to view sections of vocabs to see if they are within expected range.\n",
    "\n",
    "-  tokens that start with _\n",
    "-  tokens with numeric variables\n",
    "-  tokens that start with numbers then string\n",
    "-  tokens that includes noise\n",
    "\n",
    "As seen below, until upto 6100th vocab, we are getting incorrect word tokens that starts with _ that have not been properly fixed for punctuation. <br> As well as words that start with numbers that are incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_yanked_', '_year', '_yes_', '_yet', '_yet_', '_you', '_you_', '_your']\n",
      "['0', '00', '000', '0000', '00000', '0000000000', '00000oh', '00000th', '00001', '0001']\n",
      "['00a', '00am', '00audio', '00beware', '00first', '00pm', '00s', '00story', '00taken', '01']\n",
      "['zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz', 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzugh', 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzz', 'zzzzzzzzzzzzzzzzzzzzzzzzzz', 'zzzzzzzzzzzzzzzzzzzzzzzorro', 'zzzzzzzzzzzzzzzzzzzzzzz']\n"
     ]
    }
   ],
   "source": [
    "print(full_vocab[6069:6077])\n",
    "print(full_vocab[:10])\n",
    "print(full_vocab[40:50])\n",
    "print(full_vocab[:-7:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting noise found in token is like below. <br> The term 'Klausner' is most likely a part of name and the tokenizer did not separate these most likely due to incorrect formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['klausnerexceptional', 'klausnerexciting', 'klausnerexhilarating', 'klausnerfabulous', 'klausnerfanastic', 'klausnerfans', 'klausnerfantastic', 'klausnerfascinating', 'klausnerfine', 'klausnerfor']\n"
     ]
    }
   ],
   "source": [
    "print(full_vocab[100050:100060])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizer Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate CountVectorizer with default settings: no lower casing, preprocessing or tokenizing.\n",
    "vectorizer_2 = CountVectorizer(lowercase=False,preprocessor=dummy, tokenizer=dummy, min_df=5)\n",
    "\n",
    "#tokenize and build vocab fitting the corpora then tranform to make count vector\n",
    "count_vector_2 = vectorizer_2.fit_transform(corpora)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of vocab:  115297\n"
     ]
    }
   ],
   "source": [
    "print('number of vocab: ', len(vectorizer_2.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We increased the min_df to 5 to reduce any words that are too unique. <br> But we are modifying this parameter in the expense of the possibility of losing some of the unique keywords for different books.  <br> Since each of our books in the review data contains at least 50 reviews, having a min_df = 5 should not hurt this too much.\n",
    "\n",
    "Same to be done for max_df paramter.  Unlike min_df, we will use max_df to remove words that are repeated too much.  <br> We will say that if a word appears in more than half of the documents in corpus, remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate CountVectorizer with default settings: no lower casing, preprocessing or tokenizing.\n",
    "vectorizer_3 = CountVectorizer(lowercase=False,preprocessor=dummy, tokenizer=dummy, min_df=5, max_df=0.5)\n",
    "\n",
    "#tokenize and build vocab fitting the corpora then tranform to make count vector\n",
    "count_vector_3 = vectorizer_3.fit_transform(corpora)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of vocab:  115296\n"
     ]
    }
   ],
   "source": [
    "print('number of vocab: ', len(vectorizer_3.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting max_df to 0.5, there are only one less word in our vocabulary.  <br>This means that from words that passed the min_df=5 limit, only one word appeared in over half of the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate CountVectorizer with default settings: no lower casing, preprocessing or tokenizing.\n",
    "vectorizer_4 = CountVectorizer(lowercase=False,preprocessor=dummy, tokenizer=dummy, min_df=5, max_df=0.5, max_features=50000)\n",
    "\n",
    "#tokenize and build vocab fitting the corpora then tranform to make count vector\n",
    "count_vector_4 = vectorizer_4.fit_transform(corpora)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of vocab:  50000\n"
     ]
    }
   ],
   "source": [
    "print('number of vocab: ', len(vectorizer_4.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look into these noisy text. <br> \n",
    "\n",
    "**Alphanumeric Tokens**\n",
    "\n",
    "Starting with alphanumeric tokens, these were thought to be incorrect spacing issue but closely examining the data reveals review-spamming issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>review</th>\n",
       "      <th>review_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60465</th>\n",
       "      <td>b000133q20</td>\n",
       "      <td>agg9c66toljzb</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['fourth', 'outing', 'wonderful', 'precious', ...</td>\n",
       "      <td>[fourth, out, wonderful, precious, ramotswe, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141320</th>\n",
       "      <td>b0007c963i</td>\n",
       "      <td>aeqfyoi6yj83z</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['blood', 'meridian', 'traces', 'life', 'namel...</td>\n",
       "      <td>[blood, meridian, trace, life, nameless, kid, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197120</th>\n",
       "      <td>1417616903</td>\n",
       "      <td>a1tjpmb7n776ws</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['write', 'review', 'three', 'times', 'first',...</td>\n",
       "      <td>[write, review, three, time, first, draft, mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214937</th>\n",
       "      <td>b000n757qc</td>\n",
       "      <td>a15q7abiu9o9yz</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['years', 'ago', 'maybe', 'innocent', 'time', ...</td>\n",
       "      <td>[year, ago, maybe, innocent, time, minimum, le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256408</th>\n",
       "      <td>b000gli9hy</td>\n",
       "      <td>a1twtulvd6f22o</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['difficult', 'review', 'much', 'lehane', 'lat...</td>\n",
       "      <td>[difficult, review, much, lehane, late, quot, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin      reviewerID  overall  \\\n",
       "60465   b000133q20   agg9c66toljzb      5.0   \n",
       "141320  b0007c963i   aeqfyoi6yj83z      5.0   \n",
       "197120  1417616903  a1tjpmb7n776ws      5.0   \n",
       "214937  b000n757qc  a15q7abiu9o9yz      5.0   \n",
       "256408  b000gli9hy  a1twtulvd6f22o      5.0   \n",
       "\n",
       "                                                   review  \\\n",
       "60465   ['fourth', 'outing', 'wonderful', 'precious', ...   \n",
       "141320  ['blood', 'meridian', 'traces', 'life', 'namel...   \n",
       "197120  ['write', 'review', 'three', 'times', 'first',...   \n",
       "214937  ['years', 'ago', 'maybe', 'innocent', 'time', ...   \n",
       "256408  ['difficult', 'review', 'much', 'lehane', 'lat...   \n",
       "\n",
       "                                        review_lemmatized  \n",
       "60465   [fourth, out, wonderful, precious, ramotswe, 1...  \n",
       "141320  [blood, meridian, trace, life, nameless, kid, ...  \n",
       "197120  [write, review, three, time, first, draft, mak...  \n",
       "214937  [year, ago, maybe, innocent, time, minimum, le...  \n",
       "256408  [difficult, review, much, lehane, late, quot, ...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_re.loc[df_re.review.str.contains('afficianado')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is what we should expect to see for most vocabularies. Diverse reviews from different reviewers.<br> \n",
    "Below examples are what is seen for most of the alphanumeric tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of identical reviews:  15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>review</th>\n",
       "      <th>review_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163089</th>\n",
       "      <td>b0007hut02</td>\n",
       "      <td>a5qynf99oo4zw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['extraordinary', 'talent', 'unique', 'powerfu...</td>\n",
       "      <td>[extraordinary, talent, unique, powerful, crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384515</th>\n",
       "      <td>b000mom96m</td>\n",
       "      <td>a5qynf99oo4zw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['extraordinary', 'talent', 'unique', 'powerfu...</td>\n",
       "      <td>[extraordinary, talent, unique, powerful, crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425719</th>\n",
       "      <td>b000mnees4</td>\n",
       "      <td>a5qynf99oo4zw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['extraordinary', 'talent', 'unique', 'powerfu...</td>\n",
       "      <td>[extraordinary, talent, unique, powerful, crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564627</th>\n",
       "      <td>0786108789</td>\n",
       "      <td>a5qynf99oo4zw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['extraordinary', 'talent', 'unique', 'powerfu...</td>\n",
       "      <td>[extraordinary, talent, unique, powerful, crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632028</th>\n",
       "      <td>b000fom3my</td>\n",
       "      <td>a5qynf99oo4zw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['extraordinary', 'talent', 'unique', 'powerfu...</td>\n",
       "      <td>[extraordinary, talent, unique, powerful, crea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin     reviewerID  overall  \\\n",
       "163089  b0007hut02  a5qynf99oo4zw      5.0   \n",
       "384515  b000mom96m  a5qynf99oo4zw      5.0   \n",
       "425719  b000mnees4  a5qynf99oo4zw      5.0   \n",
       "564627  0786108789  a5qynf99oo4zw      5.0   \n",
       "632028  b000fom3my  a5qynf99oo4zw      5.0   \n",
       "\n",
       "                                                   review  \\\n",
       "163089  ['extraordinary', 'talent', 'unique', 'powerfu...   \n",
       "384515  ['extraordinary', 'talent', 'unique', 'powerfu...   \n",
       "425719  ['extraordinary', 'talent', 'unique', 'powerfu...   \n",
       "564627  ['extraordinary', 'talent', 'unique', 'powerfu...   \n",
       "632028  ['extraordinary', 'talent', 'unique', 'powerfu...   \n",
       "\n",
       "                                        review_lemmatized  \n",
       "163089  [extraordinary, talent, unique, powerful, crea...  \n",
       "384515  [extraordinary, talent, unique, powerful, crea...  \n",
       "425719  [extraordinary, talent, unique, powerful, crea...  \n",
       "564627  [extraordinary, talent, unique, powerful, crea...  \n",
       "632028  [extraordinary, talent, unique, powerful, crea...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_re.loc[df_re.review.str.contains('2012extraordinary')]\n",
    "print('number of identical reviews: ', x.shape[0])\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of reviews:  16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>review</th>\n",
       "      <th>review_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>b000tz19tc</td>\n",
       "      <td>a3fzmqw5eb9s08</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['metaphors', 'complication', 'similies', 'fah...</td>\n",
       "      <td>[metaphor, complication, similies, fahrenheit,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>b000gl8umi</td>\n",
       "      <td>a3fzmqw5eb9s08</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['metaphors', 'complications', 'similies', 'fa...</td>\n",
       "      <td>[metaphor, complication, similies, fahrenheit,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>b000k0g43c</td>\n",
       "      <td>a3fzmqw5eb9s08</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['metaphors', 'complications', 'similies', 'fa...</td>\n",
       "      <td>[metaphor, complication, similies, fahrenheit,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0003300277</td>\n",
       "      <td>a3fzmqw5eb9s08</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['metaphors', 'complications', 'similies', 'fa...</td>\n",
       "      <td>[metaphor, complication, similies, fahrenheit,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8225</th>\n",
       "      <td>b000ovsqcy</td>\n",
       "      <td>a3fzmqw5eb9s08</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['metaphors', 'complications', 'similies', 'fa...</td>\n",
       "      <td>[metaphor, complication, similies, fahrenheit,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            asin      reviewerID  overall  \\\n",
       "140   b000tz19tc  a3fzmqw5eb9s08      4.5   \n",
       "322   b000gl8umi  a3fzmqw5eb9s08      4.5   \n",
       "1764  b000k0g43c  a3fzmqw5eb9s08      4.5   \n",
       "4138  0003300277  a3fzmqw5eb9s08      4.5   \n",
       "8225  b000ovsqcy  a3fzmqw5eb9s08      4.5   \n",
       "\n",
       "                                                 review  \\\n",
       "140   ['metaphors', 'complication', 'similies', 'fah...   \n",
       "322   ['metaphors', 'complications', 'similies', 'fa...   \n",
       "1764  ['metaphors', 'complications', 'similies', 'fa...   \n",
       "4138  ['metaphors', 'complications', 'similies', 'fa...   \n",
       "8225  ['metaphors', 'complications', 'similies', 'fa...   \n",
       "\n",
       "                                      review_lemmatized  \n",
       "140   [metaphor, complication, similies, fahrenheit,...  \n",
       "322   [metaphor, complication, similies, fahrenheit,...  \n",
       "1764  [metaphor, complication, similies, fahrenheit,...  \n",
       "4138  [metaphor, complication, similies, fahrenheit,...  \n",
       "8225  [metaphor, complication, similies, fahrenheit,...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_re.loc[df_re.review.str.contains('451through')]\n",
    "print('number of reviews: ', x.shape[0])\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of reviews:  55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>review</th>\n",
       "      <th>review_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74438</th>\n",
       "      <td>0694520187</td>\n",
       "      <td>a37r9my02w1ekz</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['man', 'lots', 'reviews', 'pretentious', 'tal...</td>\n",
       "      <td>[man, lot, review, pretentious, talk, sort, hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175542</th>\n",
       "      <td>b000kpf11s</td>\n",
       "      <td>a37r9my02w1ekz</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['man', 'lots', 'reviews', 'pretentious', 'tal...</td>\n",
       "      <td>[man, lot, review, pretentious, talk, sort, hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185845</th>\n",
       "      <td>b0006al5rg</td>\n",
       "      <td>a37r9my02w1ekz</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['man', 'lots', 'reviews', 'pretentious', 'tal...</td>\n",
       "      <td>[man, lot, review, pretentious, talk, sort, hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186436</th>\n",
       "      <td>b000j6dlbu</td>\n",
       "      <td>a37r9my02w1ekz</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['man', 'lots', 'reviews', 'pretentious', 'tal...</td>\n",
       "      <td>[man, lot, review, pretentious, talk, sort, hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192208</th>\n",
       "      <td>b0006awvpg</td>\n",
       "      <td>a37r9my02w1ekz</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['man', 'lots', 'reviews', 'pretentious', 'tal...</td>\n",
       "      <td>[man, lot, review, pretentious, talk, sort, hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin      reviewerID  overall  \\\n",
       "74438   0694520187  a37r9my02w1ekz      1.0   \n",
       "175542  b000kpf11s  a37r9my02w1ekz      1.0   \n",
       "185845  b0006al5rg  a37r9my02w1ekz      1.0   \n",
       "186436  b000j6dlbu  a37r9my02w1ekz      1.0   \n",
       "192208  b0006awvpg  a37r9my02w1ekz      1.0   \n",
       "\n",
       "                                                   review  \\\n",
       "74438   ['man', 'lots', 'reviews', 'pretentious', 'tal...   \n",
       "175542  ['man', 'lots', 'reviews', 'pretentious', 'tal...   \n",
       "185845  ['man', 'lots', 'reviews', 'pretentious', 'tal...   \n",
       "186436  ['man', 'lots', 'reviews', 'pretentious', 'tal...   \n",
       "192208  ['man', 'lots', 'reviews', 'pretentious', 'tal...   \n",
       "\n",
       "                                        review_lemmatized  \n",
       "74438   [man, lot, review, pretentious, talk, sort, hi...  \n",
       "175542  [man, lot, review, pretentious, talk, sort, hi...  \n",
       "185845  [man, lot, review, pretentious, talk, sort, hi...  \n",
       "186436  [man, lot, review, pretentious, talk, sort, hi...  \n",
       "192208  [man, lot, review, pretentious, talk, sort, hi...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_re.loc[df_re.review.str.contains('540somepages')]\n",
    "print('number of reviews: ', x.shape[0])\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of reviews:  57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>review</th>\n",
       "      <th>review_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28443</th>\n",
       "      <td>b000n6ddjq</td>\n",
       "      <td>atyss9yrsc6gx</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['critique', 'scarlet', 'letter', 'scarlet', '...</td>\n",
       "      <td>[critique, scarlet, letter, scarlet, letter, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167872</th>\n",
       "      <td>1590862899</td>\n",
       "      <td>atyss9yrsc6gx</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['critique', 'scarlet', 'letter', 'scarlet', '...</td>\n",
       "      <td>[critique, scarlet, letter, scarlet, letter, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189294</th>\n",
       "      <td>b000mzcjum</td>\n",
       "      <td>atyss9yrsc6gx</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['critique', 'scarlet', 'letter', 'scarlet', '...</td>\n",
       "      <td>[critique, scarlet, letter, scarlet, letter, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223424</th>\n",
       "      <td>076240552x</td>\n",
       "      <td>atyss9yrsc6gx</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['critique', 'scarlet', 'letter', 'scarlet', '...</td>\n",
       "      <td>[critique, scarlet, letter, scarlet, letter, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237184</th>\n",
       "      <td>1561035025</td>\n",
       "      <td>atyss9yrsc6gx</td>\n",
       "      <td>3.0</td>\n",
       "      <td>['critique', 'scarlet', 'letter', 'scarlet', '...</td>\n",
       "      <td>[critique, scarlet, letter, scarlet, letter, n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin     reviewerID  overall  \\\n",
       "28443   b000n6ddjq  atyss9yrsc6gx      3.0   \n",
       "167872  1590862899  atyss9yrsc6gx      3.0   \n",
       "189294  b000mzcjum  atyss9yrsc6gx      3.0   \n",
       "223424  076240552x  atyss9yrsc6gx      3.0   \n",
       "237184  1561035025  atyss9yrsc6gx      3.0   \n",
       "\n",
       "                                                   review  \\\n",
       "28443   ['critique', 'scarlet', 'letter', 'scarlet', '...   \n",
       "167872  ['critique', 'scarlet', 'letter', 'scarlet', '...   \n",
       "189294  ['critique', 'scarlet', 'letter', 'scarlet', '...   \n",
       "223424  ['critique', 'scarlet', 'letter', 'scarlet', '...   \n",
       "237184  ['critique', 'scarlet', 'letter', 'scarlet', '...   \n",
       "\n",
       "                                        review_lemmatized  \n",
       "28443   [critique, scarlet, letter, scarlet, letter, n...  \n",
       "167872  [critique, scarlet, letter, scarlet, letter, n...  \n",
       "189294  [critique, scarlet, letter, scarlet, letter, n...  \n",
       "223424  [critique, scarlet, letter, scarlet, letter, n...  \n",
       "237184  [critique, scarlet, letter, scarlet, letter, n...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_re.loc[df_re.review.str.contains('0844606863isbn')]\n",
    "print('number of reviews: ', x.shape[0])\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most alphanumeric tokens that were repeated enough for it to be picked up by CountVectorizer were spam reviews.<br> Although there may be actual alphanumeric tokens that are valid, none were found during the analysis. <br>Therefore, we will remove all alphanumeric tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokens contaning '_'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to above, most of the tokens containing _ character looks to be spam reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>review</th>\n",
       "      <th>review_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5333</th>\n",
       "      <td>b000ovug5y</td>\n",
       "      <td>a1o7omw58qwg5k</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['terminal', 'man', 'get', 'cha', 'harry', 'be...</td>\n",
       "      <td>[terminal, man, get, cha, harry, benson, one, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9403</th>\n",
       "      <td>0786119551</td>\n",
       "      <td>ak81wlvd5kgux</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['b', 'eware', 'judging', 'standpoint', 'perso...</td>\n",
       "      <td>[b, eware, judging, standpoint, personal, life...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14429</th>\n",
       "      <td>b000npgd58</td>\n",
       "      <td>a13ofob1394g31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['good', 'news', 'elvis', 'still', 'alive', 'f...</td>\n",
       "      <td>[good, news, elvis, still, alive, flip, burger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14693</th>\n",
       "      <td>b000pwncgm</td>\n",
       "      <td>a13ofob1394g31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['good', 'news', 'elvis', 'still', 'alive', 'f...</td>\n",
       "      <td>[good, news, elvis, still, alive, flip, burger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14993</th>\n",
       "      <td>b000jesvhg</td>\n",
       "      <td>a1o7omw58qwg5k</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['would', 'like', 'respond', 'friendly', 'way'...</td>\n",
       "      <td>[would, like, respond, friendly, way, barbara,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin      reviewerID  overall  \\\n",
       "5333   b000ovug5y  a1o7omw58qwg5k      5.0   \n",
       "9403   0786119551   ak81wlvd5kgux      4.0   \n",
       "14429  b000npgd58  a13ofob1394g31      5.0   \n",
       "14693  b000pwncgm  a13ofob1394g31      5.0   \n",
       "14993  b000jesvhg  a1o7omw58qwg5k      5.0   \n",
       "\n",
       "                                                  review  \\\n",
       "5333   ['terminal', 'man', 'get', 'cha', 'harry', 'be...   \n",
       "9403   ['b', 'eware', 'judging', 'standpoint', 'perso...   \n",
       "14429  ['good', 'news', 'elvis', 'still', 'alive', 'f...   \n",
       "14693  ['good', 'news', 'elvis', 'still', 'alive', 'f...   \n",
       "14993  ['would', 'like', 'respond', 'friendly', 'way'...   \n",
       "\n",
       "                                       review_lemmatized  \n",
       "5333   [terminal, man, get, cha, harry, benson, one, ...  \n",
       "9403   [b, eware, judging, standpoint, personal, life...  \n",
       "14429  [good, news, elvis, still, alive, flip, burger...  \n",
       "14693  [good, news, elvis, still, alive, flip, burger...  \n",
       "14993  [would, like, respond, friendly, way, barbara,...  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_re.loc[df_re.review.str.contains('_all')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>review</th>\n",
       "      <th>review_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132142</th>\n",
       "      <td>b000my6vhk</td>\n",
       "      <td>a1aaybkptl97je</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['simply', 'put', 'sun', 'also', 'rises', 'sto...</td>\n",
       "      <td>[simply, put, sun, also, rise, story, handful,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181165</th>\n",
       "      <td>b000pc53zk</td>\n",
       "      <td>a1aaybkptl97je</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['simply', 'put', 'sun', 'also', 'rises', 'sto...</td>\n",
       "      <td>[simply, put, sun, also, rise, story, handful,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214477</th>\n",
       "      <td>b0006dxw74</td>\n",
       "      <td>a1aaybkptl97je</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['simply', 'put', 'sun', 'also', 'rises', 'sto...</td>\n",
       "      <td>[simply, put, sun, also, rise, story, handful,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350898</th>\n",
       "      <td>b00086u8gw</td>\n",
       "      <td>a1aaybkptl97je</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['simply', 'put', 'sun', 'also', 'rises', 'sto...</td>\n",
       "      <td>[simply, put, sun, also, rise, story, handful,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468557</th>\n",
       "      <td>b0007hdo9k</td>\n",
       "      <td>a1aaybkptl97je</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['simply', 'put', 'sun', 'also', 'rises', 'sto...</td>\n",
       "      <td>[simply, put, sun, also, rise, story, handful,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin      reviewerID  overall  \\\n",
       "132142  b000my6vhk  a1aaybkptl97je      2.0   \n",
       "181165  b000pc53zk  a1aaybkptl97je      2.0   \n",
       "214477  b0006dxw74  a1aaybkptl97je      2.0   \n",
       "350898  b00086u8gw  a1aaybkptl97je      2.0   \n",
       "468557  b0007hdo9k  a1aaybkptl97je      2.0   \n",
       "\n",
       "                                                   review  \\\n",
       "132142  ['simply', 'put', 'sun', 'also', 'rises', 'sto...   \n",
       "181165  ['simply', 'put', 'sun', 'also', 'rises', 'sto...   \n",
       "214477  ['simply', 'put', 'sun', 'also', 'rises', 'sto...   \n",
       "350898  ['simply', 'put', 'sun', 'also', 'rises', 'sto...   \n",
       "468557  ['simply', 'put', 'sun', 'also', 'rises', 'sto...   \n",
       "\n",
       "                                        review_lemmatized  \n",
       "132142  [simply, put, sun, also, rise, story, handful,...  \n",
       "181165  [simply, put, sun, also, rise, story, handful,...  \n",
       "214477  [simply, put, sun, also, rise, story, handful,...  \n",
       "350898  [simply, put, sun, also, rise, story, handful,...  \n",
       "468557  [simply, put, sun, also, rise, story, handful,...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_re.loc[df_re.review.str.contains('_paris')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>review</th>\n",
       "      <th>review_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>b000mooajg</td>\n",
       "      <td>ak81wlvd5kgux</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['atlas', 'shrugged', 'undoubtedly', 'interest...</td>\n",
       "      <td>[atlas, shrug, undoubtedly, interest, thought,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>b000mwc3fq</td>\n",
       "      <td>ak81wlvd5kgux</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['quot', 'positive', 'uphold', 'defend', 'atta...</td>\n",
       "      <td>[quot, positive, uphold, defend, attack, oppos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4416</th>\n",
       "      <td>b000pgi7qi</td>\n",
       "      <td>ak81wlvd5kgux</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['quot', 'need', 'destroy', 'objectivism', 're...</td>\n",
       "      <td>[quot, need, destroy, objectivism, reasonable,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5031</th>\n",
       "      <td>b000pwmt1g</td>\n",
       "      <td>ak81wlvd5kgux</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['quot', 'need', 'destroy', 'objectivism', 're...</td>\n",
       "      <td>[quot, need, destroy, objectivism, reasonable,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7118</th>\n",
       "      <td>b0000cki8j</td>\n",
       "      <td>ak81wlvd5kgux</td>\n",
       "      <td>2.0</td>\n",
       "      <td>['quot', 'need', 'destroy', 'objectivism', 're...</td>\n",
       "      <td>[quot, need, destroy, objectivism, reasonable,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            asin     reviewerID  overall  \\\n",
       "1520  b000mooajg  ak81wlvd5kgux      2.0   \n",
       "4152  b000mwc3fq  ak81wlvd5kgux      2.0   \n",
       "4416  b000pgi7qi  ak81wlvd5kgux      2.0   \n",
       "5031  b000pwmt1g  ak81wlvd5kgux      2.0   \n",
       "7118  b0000cki8j  ak81wlvd5kgux      2.0   \n",
       "\n",
       "                                                 review  \\\n",
       "1520  ['atlas', 'shrugged', 'undoubtedly', 'interest...   \n",
       "4152  ['quot', 'positive', 'uphold', 'defend', 'atta...   \n",
       "4416  ['quot', 'need', 'destroy', 'objectivism', 're...   \n",
       "5031  ['quot', 'need', 'destroy', 'objectivism', 're...   \n",
       "7118  ['quot', 'need', 'destroy', 'objectivism', 're...   \n",
       "\n",
       "                                      review_lemmatized  \n",
       "1520  [atlas, shrug, undoubtedly, interest, thought,...  \n",
       "4152  [quot, positive, uphold, defend, attack, oppos...  \n",
       "4416  [quot, need, destroy, objectivism, reasonable,...  \n",
       "5031  [quot, need, destroy, objectivism, reasonable,...  \n",
       "7118  [quot, need, destroy, objectivism, reasonable,...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_re.loc[df_re.review.str.contains('_good')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>review</th>\n",
       "      <th>review_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92517</th>\n",
       "      <td>b000nowyr0</td>\n",
       "      <td>a2b0xo8btprx7r</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['love', 'loss', 'sacrifice', 'gain', 'tender'...</td>\n",
       "      <td>[love, loss, sacrifice, gain, tender, night, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301771</th>\n",
       "      <td>b000kaavli</td>\n",
       "      <td>a2b0xo8btprx7r</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['love', 'loss', 'sacrifice', 'gain', 'tender'...</td>\n",
       "      <td>[love, loss, sacrifice, gain, tender, night, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324066</th>\n",
       "      <td>b0006amffm</td>\n",
       "      <td>a2b0xo8btprx7r</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['love', 'loss', 'sacrifice', 'gain', 'tender'...</td>\n",
       "      <td>[love, loss, sacrifice, gain, tender, night, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368250</th>\n",
       "      <td>0808514601</td>\n",
       "      <td>a2b0xo8btprx7r</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['love', 'loss', 'sacrifice', 'gain', 'tender'...</td>\n",
       "      <td>[love, loss, sacrifice, gain, tender, night, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395465</th>\n",
       "      <td>b000pen42c</td>\n",
       "      <td>a2b0xo8btprx7r</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['love', 'loss', 'sacrifice', 'gain', 'tender'...</td>\n",
       "      <td>[love, loss, sacrifice, gain, tender, night, f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin      reviewerID  overall  \\\n",
       "92517   b000nowyr0  a2b0xo8btprx7r      5.0   \n",
       "301771  b000kaavli  a2b0xo8btprx7r      5.0   \n",
       "324066  b0006amffm  a2b0xo8btprx7r      5.0   \n",
       "368250  0808514601  a2b0xo8btprx7r      5.0   \n",
       "395465  b000pen42c  a2b0xo8btprx7r      5.0   \n",
       "\n",
       "                                                   review  \\\n",
       "92517   ['love', 'loss', 'sacrifice', 'gain', 'tender'...   \n",
       "301771  ['love', 'loss', 'sacrifice', 'gain', 'tender'...   \n",
       "324066  ['love', 'loss', 'sacrifice', 'gain', 'tender'...   \n",
       "368250  ['love', 'loss', 'sacrifice', 'gain', 'tender'...   \n",
       "395465  ['love', 'loss', 'sacrifice', 'gain', 'tender'...   \n",
       "\n",
       "                                        review_lemmatized  \n",
       "92517   [love, loss, sacrifice, gain, tender, night, f...  \n",
       "301771  [love, loss, sacrifice, gain, tender, night, f...  \n",
       "324066  [love, loss, sacrifice, gain, tender, night, f...  \n",
       "368250  [love, loss, sacrifice, gain, tender, night, f...  \n",
       "395465  [love, loss, sacrifice, gain, tender, night, f...  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_re.loc[df_re.review.str.contains('_weakness_')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numeric Tokens**\n",
    "\n",
    "For numeric tokens, it looks like there is a mixture of good reviews and spams. <br> Numbers under 100 show a lot of diversity whereas most numbers higher than that are spams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of reviews:  341909\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>review</th>\n",
       "      <th>review_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b000n6ddjq</td>\n",
       "      <td>a1d2c0wdcshuwz</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['people', 'think', 'scarlet', 'letter', 'imme...</td>\n",
       "      <td>[people, think, scarlet, letter, immediate, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b000n6ddjq</td>\n",
       "      <td>a1oxi0n58tmyy9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['review', 'novel', 'various', 'franklin', 'li...</td>\n",
       "      <td>[review, novel, various, franklin, library, ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b0006dg9om</td>\n",
       "      <td>az05jr3xqn9ip</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['question', 'often', 'appears', 'agony', 'aun...</td>\n",
       "      <td>[question, often, appear, agony, aunt, column,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b0000ckd7e</td>\n",
       "      <td>a21vr7m8o55ef6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['following', 'success', 'road', 'kerouac', 'p...</td>\n",
       "      <td>[follow, success, road, kerouac, publisher, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b0000ckd7e</td>\n",
       "      <td>a10b4uol0ib274</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['kerouac', 'may', 'best', 'known', 'road', 'f...</td>\n",
       "      <td>[kerouac, may, best, know, road, far, favorite...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin      reviewerID  overall  \\\n",
       "0  b000n6ddjq  a1d2c0wdcshuwz      5.0   \n",
       "2  b000n6ddjq  a1oxi0n58tmyy9      5.0   \n",
       "3  b0006dg9om   az05jr3xqn9ip      5.0   \n",
       "6  b0000ckd7e  a21vr7m8o55ef6      5.0   \n",
       "7  b0000ckd7e  a10b4uol0ib274      5.0   \n",
       "\n",
       "                                              review  \\\n",
       "0  ['people', 'think', 'scarlet', 'letter', 'imme...   \n",
       "2  ['review', 'novel', 'various', 'franklin', 'li...   \n",
       "3  ['question', 'often', 'appears', 'agony', 'aun...   \n",
       "6  ['following', 'success', 'road', 'kerouac', 'p...   \n",
       "7  ['kerouac', 'may', 'best', 'known', 'road', 'f...   \n",
       "\n",
       "                                   review_lemmatized  \n",
       "0  [people, think, scarlet, letter, immediate, th...  \n",
       "2  [review, novel, various, franklin, library, ed...  \n",
       "3  [question, often, appear, agony, aunt, column,...  \n",
       "6  [follow, success, road, kerouac, publisher, in...  \n",
       "7  [kerouac, may, best, know, road, far, favorite...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_re.loc[df_re.review.str.contains('0')]\n",
    "print('number of reviews: ', x.shape[0])\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of reviews:  26295\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>review</th>\n",
       "      <th>review_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>b000pbzh5m</td>\n",
       "      <td>a2itemel0dtx8a</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['foundation', 'consists', 'five', 'stories', ...</td>\n",
       "      <td>[foundation, consists, five, story, separate, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>b000pbzh5m</td>\n",
       "      <td>a2b2g75aqom0pi</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['second', 'foundation', 'novel', 'read', 'who...</td>\n",
       "      <td>[second, foundation, novel, read, whole, serie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>b000pbzh5m</td>\n",
       "      <td>ac3c00yw5k55b</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['second', 'original', 'trilogy', 'fourth', 'o...</td>\n",
       "      <td>[second, original, trilogy, fourth, overall, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>b000pbzh5m</td>\n",
       "      <td>awlfvct9128jv</td>\n",
       "      <td>3.5</td>\n",
       "      <td>['first', 'three', 'novels', 'original', 'foun...</td>\n",
       "      <td>[first, three, novel, original, foundation, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>b000pbzh5m</td>\n",
       "      <td>ag7r3mmf8qldt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['isaac', 'asimov', 'one', 'popular', 'science...</td>\n",
       "      <td>[isaac, asimov, one, popular, science, fiction...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          asin      reviewerID  overall  \\\n",
       "12  b000pbzh5m  a2itemel0dtx8a      4.5   \n",
       "22  b000pbzh5m  a2b2g75aqom0pi      5.0   \n",
       "25  b000pbzh5m   ac3c00yw5k55b      5.0   \n",
       "29  b000pbzh5m   awlfvct9128jv      3.5   \n",
       "33  b000pbzh5m   ag7r3mmf8qldt      4.0   \n",
       "\n",
       "                                               review  \\\n",
       "12  ['foundation', 'consists', 'five', 'stories', ...   \n",
       "22  ['second', 'foundation', 'novel', 'read', 'who...   \n",
       "25  ['second', 'original', 'trilogy', 'fourth', 'o...   \n",
       "29  ['first', 'three', 'novels', 'original', 'foun...   \n",
       "33  ['isaac', 'asimov', 'one', 'popular', 'science...   \n",
       "\n",
       "                                    review_lemmatized  \n",
       "12  [foundation, consists, five, story, separate, ...  \n",
       "22  [second, foundation, novel, read, whole, serie...  \n",
       "25  [second, original, trilogy, fourth, overall, f...  \n",
       "29  [first, three, novel, original, foundation, tr...  \n",
       "33  [isaac, asimov, one, popular, science, fiction...  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_re.loc[df_re.review.str.contains('000')]\n",
    "print('number of reviews: ', x.shape[0])\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of reviews:  11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>review</th>\n",
       "      <th>review_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211678</th>\n",
       "      <td>b000h01yyy</td>\n",
       "      <td>a3dwxvgoe2xziq</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['fascinating', 'written', 'lot', 'reviews', '...</td>\n",
       "      <td>[fascinate, write, lot, review, pagels, reader...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334264</th>\n",
       "      <td>b000fi4ryw</td>\n",
       "      <td>a3dwxvgoe2xziq</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['fascinating', 'written', 'lot', 'reviews', '...</td>\n",
       "      <td>[fascinate, write, lot, review, pagels, reader...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618871</th>\n",
       "      <td>b00023o1l4</td>\n",
       "      <td>a3dwxvgoe2xziq</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['course', 'prequel', 'da', 'vinci', 'code', '...</td>\n",
       "      <td>[course, prequel, da, vinci, code, two, togeth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662689</th>\n",
       "      <td>b000pggccy</td>\n",
       "      <td>a3dwxvgoe2xziq</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['fascinating', 'written', 'lot', 'reviews', '...</td>\n",
       "      <td>[fascinate, write, lot, review, pagels, reader...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693508</th>\n",
       "      <td>b0000d1bxo</td>\n",
       "      <td>a3dwxvgoe2xziq</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['course', 'prequel', 'da', 'vinci', 'code', '...</td>\n",
       "      <td>[course, prequel, da, vinci, code, two, togeth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin      reviewerID  overall  \\\n",
       "211678  b000h01yyy  a3dwxvgoe2xziq      4.0   \n",
       "334264  b000fi4ryw  a3dwxvgoe2xziq      4.0   \n",
       "618871  b00023o1l4  a3dwxvgoe2xziq      4.0   \n",
       "662689  b000pggccy  a3dwxvgoe2xziq      4.0   \n",
       "693508  b0000d1bxo  a3dwxvgoe2xziq      4.0   \n",
       "\n",
       "                                                   review  \\\n",
       "211678  ['fascinating', 'written', 'lot', 'reviews', '...   \n",
       "334264  ['fascinating', 'written', 'lot', 'reviews', '...   \n",
       "618871  ['course', 'prequel', 'da', 'vinci', 'code', '...   \n",
       "662689  ['fascinating', 'written', 'lot', 'reviews', '...   \n",
       "693508  ['course', 'prequel', 'da', 'vinci', 'code', '...   \n",
       "\n",
       "                                        review_lemmatized  \n",
       "211678  [fascinate, write, lot, review, pagels, reader...  \n",
       "334264  [fascinate, write, lot, review, pagels, reader...  \n",
       "618871  [course, prequel, da, vinci, code, two, togeth...  \n",
       "662689  [fascinate, write, lot, review, pagels, reader...  \n",
       "693508  [course, prequel, da, vinci, code, two, togeth...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_re.loc[df_re.review.str.contains('0140278079')]\n",
    "print('number of reviews: ', x.shape[0])\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of reviews:  145\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>review</th>\n",
       "      <th>review_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4345</th>\n",
       "      <td>b00007k45c</td>\n",
       "      <td>a1cqjzsi3lk1vs</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['enjoyable', 'eloquent', 'thoroughly', 'enjoy...</td>\n",
       "      <td>[enjoyable, eloquent, thoroughly, enjoyable, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12048</th>\n",
       "      <td>b0006iu7c2</td>\n",
       "      <td>a1cqjzsi3lk1vs</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['enjoyable', 'eloquent', 'thoroughly', 'enjoy...</td>\n",
       "      <td>[enjoyable, eloquent, thoroughly, enjoyable, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19441</th>\n",
       "      <td>0006513204</td>\n",
       "      <td>a1cqjzsi3lk1vs</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['enjoyable', 'eloquent', 'thoroughly', 'enjoy...</td>\n",
       "      <td>[enjoyable, eloquent, thoroughly, enjoyable, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54373</th>\n",
       "      <td>1565115430</td>\n",
       "      <td>a319kyeiaz3son</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['vivid', 'simple', 'poetic', 'girl', 'hyacint...</td>\n",
       "      <td>[vivid, simple, poetic, girl, hyacinth, blue, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63968</th>\n",
       "      <td>1417627530</td>\n",
       "      <td>a39abkrs1mkftw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['picked', 'year', 'wonders', 'geraldine', 'br...</td>\n",
       "      <td>[picked, year, wonder, geraldine, brook, two, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin      reviewerID  overall  \\\n",
       "4345   b00007k45c  a1cqjzsi3lk1vs      4.5   \n",
       "12048  b0006iu7c2  a1cqjzsi3lk1vs      4.5   \n",
       "19441  0006513204  a1cqjzsi3lk1vs      4.5   \n",
       "54373  1565115430  a319kyeiaz3son      5.0   \n",
       "63968  1417627530  a39abkrs1mkftw      5.0   \n",
       "\n",
       "                                                  review  \\\n",
       "4345   ['enjoyable', 'eloquent', 'thoroughly', 'enjoy...   \n",
       "12048  ['enjoyable', 'eloquent', 'thoroughly', 'enjoy...   \n",
       "19441  ['enjoyable', 'eloquent', 'thoroughly', 'enjoy...   \n",
       "54373  ['vivid', 'simple', 'poetic', 'girl', 'hyacint...   \n",
       "63968  ['picked', 'year', 'wonders', 'geraldine', 'br...   \n",
       "\n",
       "                                       review_lemmatized  \n",
       "4345   [enjoyable, eloquent, thoroughly, enjoyable, r...  \n",
       "12048  [enjoyable, eloquent, thoroughly, enjoyable, r...  \n",
       "19441  [enjoyable, eloquent, thoroughly, enjoyable, r...  \n",
       "54373  [vivid, simple, poetic, girl, hyacinth, blue, ...  \n",
       "63968  [picked, year, wonder, geraldine, brook, two, ...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_re.loc[df_re.review.str.contains('1660')]\n",
    "print('number of reviews: ', x.shape[0])\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of reviews:  5948\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>review</th>\n",
       "      <th>review_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>b0000ckd7e</td>\n",
       "      <td>auey946m1l939</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['commemorative', 'edition', 'add', 'much', 'n...</td>\n",
       "      <td>[commemorative, edition, add, much, new, pengu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0140860096</td>\n",
       "      <td>a2pns90bkgnm16</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['popular', 'high', 'school', 'college', 'requ...</td>\n",
       "      <td>[popular, high, school, college, require, read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0192839020</td>\n",
       "      <td>a1lmbm1n4exs5w</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['title', 'also', 'happens', 'plot', 'outline'...</td>\n",
       "      <td>[title, also, happens, plot, outline, element,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>b000ks34x2</td>\n",
       "      <td>a1lmbm1n4exs5w</td>\n",
       "      <td>4.5</td>\n",
       "      <td>['title', 'also', 'happens', 'plot', 'outline'...</td>\n",
       "      <td>[title, also, happens, plot, outline, element,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>b0007gqnj4</td>\n",
       "      <td>a1l43kwwr05pcs</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['second', 'published', 'work', 'writes', 'kne...</td>\n",
       "      <td>[second, publish, work, writes, knew, best, ea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           asin      reviewerID  overall  \\\n",
       "10   b0000ckd7e   auey946m1l939      4.0   \n",
       "186  0140860096  a2pns90bkgnm16      4.5   \n",
       "398  0192839020  a1lmbm1n4exs5w      4.5   \n",
       "724  b000ks34x2  a1lmbm1n4exs5w      4.5   \n",
       "834  b0007gqnj4  a1l43kwwr05pcs      4.0   \n",
       "\n",
       "                                                review  \\\n",
       "10   ['commemorative', 'edition', 'add', 'much', 'n...   \n",
       "186  ['popular', 'high', 'school', 'college', 'requ...   \n",
       "398  ['title', 'also', 'happens', 'plot', 'outline'...   \n",
       "724  ['title', 'also', 'happens', 'plot', 'outline'...   \n",
       "834  ['second', 'published', 'work', 'writes', 'kne...   \n",
       "\n",
       "                                     review_lemmatized  \n",
       "10   [commemorative, edition, add, much, new, pengu...  \n",
       "186  [popular, high, school, college, require, read...  \n",
       "398  [title, also, happens, plot, outline, element,...  \n",
       "724  [title, also, happens, plot, outline, element,...  \n",
       "834  [second, publish, work, writes, knew, best, ea...  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_re.loc[df_re.review.str.contains('83')]\n",
    "print('number of reviews: ', x.shape[0])\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of reviews:  28820\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>review</th>\n",
       "      <th>review_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b000n6ddjq</td>\n",
       "      <td>a1oxi0n58tmyy9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['review', 'novel', 'various', 'franklin', 'li...</td>\n",
       "      <td>[review, novel, various, franklin, library, ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>b000pbzh5m</td>\n",
       "      <td>ag7r3mmf8qldt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['isaac', 'asimov', 'one', 'popular', 'science...</td>\n",
       "      <td>[isaac, asimov, one, popular, science, fiction...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>b000pbzh6q</td>\n",
       "      <td>ag7r3mmf8qldt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['second', 'original', 'three', 'foundation', ...</td>\n",
       "      <td>[second, original, three, foundation, series, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>b000tz19tc</td>\n",
       "      <td>a2njo6ye954dbh</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['teaching', 'quot', 'fahrenheit', '451', 'quo...</td>\n",
       "      <td>[teach, quot, fahrenheit, 451, quot, example, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>b000phiim0</td>\n",
       "      <td>a2l7n2u5z316ze</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['one', 'greatest', 'pieces', 'work', 'heritag...</td>\n",
       "      <td>[one, great, piece, work, heritage, press, arg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           asin      reviewerID  overall  \\\n",
       "2    b000n6ddjq  a1oxi0n58tmyy9      5.0   \n",
       "33   b000pbzh5m   ag7r3mmf8qldt      4.0   \n",
       "81   b000pbzh6q   ag7r3mmf8qldt      4.0   \n",
       "135  b000tz19tc  a2njo6ye954dbh      5.0   \n",
       "154  b000phiim0  a2l7n2u5z316ze      5.0   \n",
       "\n",
       "                                                review  \\\n",
       "2    ['review', 'novel', 'various', 'franklin', 'li...   \n",
       "33   ['isaac', 'asimov', 'one', 'popular', 'science...   \n",
       "81   ['second', 'original', 'three', 'foundation', ...   \n",
       "135  ['teaching', 'quot', 'fahrenheit', '451', 'quo...   \n",
       "154  ['one', 'greatest', 'pieces', 'work', 'heritag...   \n",
       "\n",
       "                                     review_lemmatized  \n",
       "2    [review, novel, various, franklin, library, ed...  \n",
       "33   [isaac, asimov, one, popular, science, fiction...  \n",
       "81   [second, original, three, foundation, series, ...  \n",
       "135  [teach, quot, fahrenheit, 451, quot, example, ...  \n",
       "154  [one, great, piece, work, heritage, press, arg...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_re.loc[df_re.review.str.contains('93')]\n",
    "print('number of reviews: ', x.shape[0])\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of reviews:  70\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>review</th>\n",
       "      <th>review_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>b000n5hfqy</td>\n",
       "      <td>a2dktzmmg3jhn4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['rating', 'mein', 'kampf', '4', 'stars', 'due...</td>\n",
       "      <td>[rating, mein, kampf, 4, star, due, translatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4059</th>\n",
       "      <td>b000raiqs6</td>\n",
       "      <td>a2dktzmmg3jhn4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['rating', 'mein', 'kampf', '4', 'stars', 'due...</td>\n",
       "      <td>[rating, mein, kampf, 4, star, due, translatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>b000phn85c</td>\n",
       "      <td>a2dktzmmg3jhn4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['rating', 'mein', 'kampf', '4', 'stars', 'due...</td>\n",
       "      <td>[rating, mein, kampf, 4, star, due, translatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>b000mkid0w</td>\n",
       "      <td>a2dktzmmg3jhn4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['rating', 'mein', 'kampf', '4', 'stars', 'due...</td>\n",
       "      <td>[rating, mein, kampf, 4, star, due, translatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8622</th>\n",
       "      <td>b000p0ms7i</td>\n",
       "      <td>a2dktzmmg3jhn4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>['rating', 'mein', 'kampf', '4', 'stars', 'due...</td>\n",
       "      <td>[rating, mein, kampf, 4, star, due, translatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            asin      reviewerID  overall  \\\n",
       "1066  b000n5hfqy  a2dktzmmg3jhn4      4.0   \n",
       "4059  b000raiqs6  a2dktzmmg3jhn4      4.0   \n",
       "4855  b000phn85c  a2dktzmmg3jhn4      4.0   \n",
       "7032  b000mkid0w  a2dktzmmg3jhn4      4.0   \n",
       "8622  b000p0ms7i  a2dktzmmg3jhn4      4.0   \n",
       "\n",
       "                                                 review  \\\n",
       "1066  ['rating', 'mein', 'kampf', '4', 'stars', 'due...   \n",
       "4059  ['rating', 'mein', 'kampf', '4', 'stars', 'due...   \n",
       "4855  ['rating', 'mein', 'kampf', '4', 'stars', 'due...   \n",
       "7032  ['rating', 'mein', 'kampf', '4', 'stars', 'due...   \n",
       "8622  ['rating', 'mein', 'kampf', '4', 'stars', 'due...   \n",
       "\n",
       "                                      review_lemmatized  \n",
       "1066  [rating, mein, kampf, 4, star, due, translatio...  \n",
       "4059  [rating, mein, kampf, 4, star, due, translatio...  \n",
       "4855  [rating, mein, kampf, 4, star, due, translatio...  \n",
       "7032  [rating, mein, kampf, 4, star, due, translatio...  \n",
       "8622  [rating, mein, kampf, 4, star, due, translatio...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_re.loc[df_re.review.str.contains('535')]\n",
    "print('number of reviews: ', x.shape[0])\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of reviews:  55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>review</th>\n",
       "      <th>review_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74196</th>\n",
       "      <td>0694520187</td>\n",
       "      <td>a2fthcgh06o4y5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['unless', 'naval', 'historian', 'melville', '...</td>\n",
       "      <td>[unless, naval, historian, melville, scholar, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175708</th>\n",
       "      <td>b000kpf11s</td>\n",
       "      <td>a2fthcgh06o4y5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['unless', 'naval', 'historian', 'melville', '...</td>\n",
       "      <td>[unless, naval, historian, melville, scholar, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186007</th>\n",
       "      <td>b0006al5rg</td>\n",
       "      <td>a2fthcgh06o4y5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['unless', 'naval', 'historian', 'melville', '...</td>\n",
       "      <td>[unless, naval, historian, melville, scholar, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186330</th>\n",
       "      <td>b000j6dlbu</td>\n",
       "      <td>a2fthcgh06o4y5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['unless', 'naval', 'historian', 'melville', '...</td>\n",
       "      <td>[unless, naval, historian, melville, scholar, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192370</th>\n",
       "      <td>b0006awvpg</td>\n",
       "      <td>a2fthcgh06o4y5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['unless', 'naval', 'historian', 'melville', '...</td>\n",
       "      <td>[unless, naval, historian, melville, scholar, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin      reviewerID  overall  \\\n",
       "74196   0694520187  a2fthcgh06o4y5      5.0   \n",
       "175708  b000kpf11s  a2fthcgh06o4y5      5.0   \n",
       "186007  b0006al5rg  a2fthcgh06o4y5      5.0   \n",
       "186330  b000j6dlbu  a2fthcgh06o4y5      5.0   \n",
       "192370  b0006awvpg  a2fthcgh06o4y5      5.0   \n",
       "\n",
       "                                                   review  \\\n",
       "74196   ['unless', 'naval', 'historian', 'melville', '...   \n",
       "175708  ['unless', 'naval', 'historian', 'melville', '...   \n",
       "186007  ['unless', 'naval', 'historian', 'melville', '...   \n",
       "186330  ['unless', 'naval', 'historian', 'melville', '...   \n",
       "192370  ['unless', 'naval', 'historian', 'melville', '...   \n",
       "\n",
       "                                        review_lemmatized  \n",
       "74196   [unless, naval, historian, melville, scholar, ...  \n",
       "175708  [unless, naval, historian, melville, scholar, ...  \n",
       "186007  [unless, naval, historian, melville, scholar, ...  \n",
       "186330  [unless, naval, historian, melville, scholar, ...  \n",
       "192370  [unless, naval, historian, melville, scholar, ...  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df_re.loc[df_re.review.str.contains('3724')]\n",
    "print('number of reviews: ', x.shape[0])\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Noisy Text**\n",
    "\n",
    "Some of the other noisy texts found are repeating alphabets such as 'aaaaa' or 'zzzzz'. <br>While characters like a, e, z may repeat itself but no more than once.  <br>These entries will be removed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasNumbers(inputString):\n",
    "    #check if containing number\n",
    "    return bool(re.search(r'\\d', inputString))\n",
    "\n",
    "#including noisy texts found in next iteration of stopwords\n",
    "detailed_stopwords = [ 'aa', 'aaa', 'aaaa', 'aaaaaaaa', 'aaaaaaaaa', 'aaaaaaaaaa', 'aaaaaaaaaaa', \n",
    "                      'aaaaaaaaaaaaaaa', 'aaaaaaaaaaaaaahhhhhhhhhhhhhhh', 'aaaaaahhh', 'aaaah', 'aaah', \n",
    "                      'aaarrrggghhh', 'aaarrrrgghhh', 'aabout', 'aaccidental', 'aachen', 'aacute', 'aad', \n",
    "                      'aaf', 'aah', 'aahh', 'aaw','zz', 'zzboring', 'zzz', 'zzzzs', 'zzzzz', 'zzzzzz', \n",
    "                      'zzzzzzz', 'zzzzzzzz', 'zzzzzzzzben', 'zzzzzzzzz', 'zzzzzzzzzz', 'zzzzzzzzzzz', \n",
    "                      'zzzzzzzzzzzz', 'zzzzzzzzzzzzzzz', 'zzzzzzzzzzzzzzzz', 'zzzzzzzzzzzzzzzzz', \n",
    "                      'zzzzzzzzzzzzzzzzzz', 'zzzzzzzzzzzzzzzzzzz', 'zzzzzzzzzzzzzzzzzzzz', \n",
    "                      'zzzzzzzzzzzzzzzzzzzzzz', 'zzzzzzzzzzzzzzzzzzzzzzzzzz', 'zzzzzzzzzzzzzzzzzzzzzzzzzzzzz']\n",
    "\n",
    "'''\n",
    "Takes in list of words\n",
    "\n",
    "Outputs processed list of words\n",
    "'''\n",
    "def processText(t):\n",
    "    \n",
    "    out = []\n",
    "    \n",
    "    #loop through list of words\n",
    "    for w in t:\n",
    "        \n",
    "        #only keep words without any numbers or _ or not part of noisy text and having between 3~20 characters in length\n",
    "        if (not hasNumbers(w)) and ('_' not in w) and (w not in detailed_stopwords) and (len(w) > 3 and len(w) < 20):\n",
    "            out.append(w)\n",
    "        \n",
    "    return out\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "def findSpam(srs):\n",
    "    \n",
    "    spam_ind = []\n",
    "    \n",
    "    #iterate through all documents\n",
    "    for index, row in srs.items():\n",
    "        \n",
    "        #iterate through all words\n",
    "        for w in row:\n",
    "\n",
    "            # if word contains number higher than 2000 (calendar year) or _ or part of detailed_stopwords or more than 20 char in length\n",
    "            if (hasNumbers(w) and (int(re.sub(r'\\D','',w))>2000)) or ('_' in w) or (w in detailed_stopwords) or (len(w) > 20):\n",
    "                \n",
    "                #multiple append to the list is find at the moment, we can use the unique values \n",
    "                spam_ind.append(index)\n",
    "    \n",
    "    \n",
    "    return spam_ind\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've found a number of spam considered reviews.  <br> Reviews corresponding to these indices will be removed from both the original dataset df_re as well as the tf-idf vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find spam index\n",
    "spam = findSpam(df_re.review_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make it into index list\n",
    "spam_ind = list(set(spam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove spam\n",
    "df_re = df_re.loc[~df_re.index.isin(spam_ind)]\n",
    "\n",
    "#reset index\n",
    "df_re.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_re.drop(columns='index',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>review</th>\n",
       "      <th>review_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b000n6ddjq</td>\n",
       "      <td>a1d2c0wdcshuwz</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['people', 'think', 'scarlet', 'letter', 'imme...</td>\n",
       "      <td>[people, think, scarlet, letter, immediate, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b000n6ddjq</td>\n",
       "      <td>a2m3nctfugi4sr</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['hawthorne', 'best', 'work', 'central', 'unde...</td>\n",
       "      <td>[hawthorne, best, work, central, understand, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b0006dg9om</td>\n",
       "      <td>az05jr3xqn9ip</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['question', 'often', 'appears', 'agony', 'aun...</td>\n",
       "      <td>[question, often, appear, agony, aunt, column,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b0006dg9om</td>\n",
       "      <td>a1r77go77fblmj</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['truly', 'excellently', 'written', 'beginning...</td>\n",
       "      <td>[truly, excellently, write, begin, te, come, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b0000ckd7e</td>\n",
       "      <td>a10b4uol0ib274</td>\n",
       "      <td>5.0</td>\n",
       "      <td>['kerouac', 'may', 'best', 'known', 'road', 'f...</td>\n",
       "      <td>[kerouac, may, best, know, road, far, favorite...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin      reviewerID  overall  \\\n",
       "0  b000n6ddjq  a1d2c0wdcshuwz      5.0   \n",
       "1  b000n6ddjq  a2m3nctfugi4sr      5.0   \n",
       "2  b0006dg9om   az05jr3xqn9ip      5.0   \n",
       "3  b0006dg9om  a1r77go77fblmj      5.0   \n",
       "4  b0000ckd7e  a10b4uol0ib274      5.0   \n",
       "\n",
       "                                              review  \\\n",
       "0  ['people', 'think', 'scarlet', 'letter', 'imme...   \n",
       "1  ['hawthorne', 'best', 'work', 'central', 'unde...   \n",
       "2  ['question', 'often', 'appears', 'agony', 'aun...   \n",
       "3  ['truly', 'excellently', 'written', 'beginning...   \n",
       "4  ['kerouac', 'may', 'best', 'known', 'road', 'f...   \n",
       "\n",
       "                                   review_lemmatized  \n",
       "0  [people, think, scarlet, letter, immediate, th...  \n",
       "1  [hawthorne, best, work, central, understand, t...  \n",
       "2  [question, often, appear, agony, aunt, column,...  \n",
       "3  [truly, excellently, write, begin, te, come, a...  \n",
       "4  [kerouac, may, best, know, road, far, favorite...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_re.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1806240 entries, 0 to 1806239\n",
      "Data columns (total 5 columns):\n",
      "asin                 object\n",
      "reviewerID           object\n",
      "overall              float64\n",
      "review               object\n",
      "review_lemmatized    object\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 68.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_re.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process text again\n",
    "df_re['review_lemmatized'] = df_re['review_lemmatized'].apply(lambda x: processText(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_re.to_csv('data/spam_processed.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when reading in our word list again, pandas parses it as string instead of list of words.\n",
    "#using literal_eval to fix this\n",
    "df_re = pd.read_csv('data/spam_processed.csv',converters={'review_lemmatized': literal_eval})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 Tf-Idf Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate review_lemmatized\n",
    "lemmatized_text = df_re.review_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate CountVectorizer with default settings: no lower casing, preprocessing or tokenizing.\n",
    "vectorizer_5 = CountVectorizer(lowercase=False,preprocessor=dummy, tokenizer=dummy, min_df=5, max_df=0.5, max_features=10000)\n",
    "\n",
    "#tokenize and build vocab fitting the corpora then tranform to make count vector\n",
    "count_vector_updated = vectorizer_5.fit_transform(lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer_5.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vocab=vectorizer_5.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaron', 'abagnale', 'abandon', 'abandonment', 'abbey', 'abbott', 'abduct', 'abduction', 'abel', 'abhor', 'abide', 'abigail', 'ability', 'abject', 'able', 'abnormal', 'aboard', 'abolish', 'abolition', 'abolitionist', 'abortion', 'abound', 'abounds', 'abraham', 'abridge', 'abridgement', 'abroad', 'abrupt', 'abruptly', 'absalom', 'absence', 'absent', 'absolute', 'absolutely', 'absolutly', 'absorb', 'absorbed', 'absorption', 'abstract', 'abstraction', 'absurd', 'absurdist', 'absurdity', 'absurdly', 'abundance', 'abundant', 'abuse', 'abusive', 'abyss', 'academia', 'academic', 'academy', 'accelerate', 'accent', 'accept', 'acceptable', 'acceptance', 'accepted', 'accepts', 'access', 'accessible', 'accident', 'accidental', 'accidentally', 'acclaim', 'accolade', 'accommodate', 'accompanies', 'accompany', 'accomplish', 'accomplishes', 'accomplishment', 'accord', 'accordance', 'accordingly', 'account', 'accounting', 'accumulate', 'accumulation', 'accuracy', 'accurate', 'accurately', 'accusation', 'accuse', 'accuses', 'accustom', 'ache', 'achebe', 'achieve', 'achievement', 'achieves', 'acid', 'acknowledge', 'acknowledges', 'ackroyd', 'acquaint', 'acquaintance', 'acquire', 'acquires', 'acquisition', 'across', 'action', 'active', 'actively', 'activist', 'activity', 'actor', 'actress', 'actual', 'actuality', 'actually', 'acute', 'adage', 'adam', 'adapt', 'adaptation', 'adaption', 'addict', 'addiction', 'addictive', 'addition', 'additional', 'additionally', 'address', 'adele', 'adept', 'adequate', 'adequately', 'adhere', 'adjective', 'adjust', 'adjustment', 'administration', 'admirable', 'admirably', 'admiral', 'admiration', 'admire', 'admirer', 'admires', 'admission', 'admit', 'admits', 'admittedly', 'adolescence', 'adolescent', 'adopt', 'adoption', 'adopts', 'adorable', 'adoration', 'adore', 'adores', 'adult', 'adulterous', 'adultery', 'adulthood', 'advance', 'advanced', 'advancement', 'advantage', 'advent', 'adventure', 'adventurer', 'adventurous', 'adversary', 'adversity', 'advertised', 'advertisement', 'advertising', 'advice', 'advise', 'advisor', 'advocate', 'aesthetic', 'aestheticism', 'affair', 'affect', 'affected', 'affection', 'affectionate', 'affinity', 'affirm', 'affirmation', 'afflict', 'affluent', 'afford', 'affordable', 'afghanistan', 'aficionado', 'aforementioned', 'afraid', 'africa', 'african', 'afterlife', 'aftermath', 'afternoon', 'afterthought', 'afterward', 'afterwards', 'afterword', 'agatha', 'ageless', 'agency', 'agenda', 'agent', 'aggravate', 'aggressive', 'agnes', 'agnostic', 'agonize', 'agony', 'agree', 'agreeable', 'agreement', 'agrees', 'agricultural', 'agriculture', 'ahab', 'ahead', 'aide', 'aimless', 'aimlessly', 'airplane', 'airport', 'akin', 'alabama', 'alan', 'alarm', 'alaska', 'albeit', 'albert', 'albom', 'alchemist', 'alcohol', 'alcoholic', 'alcoholism', 'alcott', 'aldous', 'alec', 'alert', 'alessandra', 'alex', 'alexander', 'alexandra', 'alexandre', 'alfred', 'algernon', 'alice', 'alien', 'alienate', 'alienation', 'align', 'alike', 'alison', 'alive', 'allan', 'allege', 'allegedly', 'allegiance', 'allegorical', 'allegory', 'allen', 'allende', 'alley', 'alliance', 'allie', 'allied', 'allon', 'allow', 'allows', 'allude', 'alludes', 'allure', 'allusion', 'ally', 'almighty', 'almost', 'alone', 'along', 'alongside', 'aloof', 'alot', 'aloud', 'alpha', 'alphabet', 'already', 'alright', 'also', 'altar', 'alter', 'alternate', 'alternately', 'alternative', 'although', 'altogether', 'altruism', 'always', 'amanda', 'amateur', 'amaze', 'amazement', 'amazes', 'amazingly', 'amazon', 'amber', 'ambiguity', 'ambiguous', 'ambition', 'ambitious', 'ambivalence', 'ambivalent', 'ambrose', 'ambulance', 'amelia', 'amends', 'america', 'american', 'americana', 'ames', 'amiable', 'amid', 'amidst', 'amir', 'among', 'amongst', 'amoral', 'amory', 'amount', 'ample', 'amsterdam', 'amuse', 'amusement', 'anachronistic', 'analogy', 'analysis', 'analytical', 'analyze', 'analyzes', 'anarchist', 'anarchy', 'anatomy', 'ancestor', 'ancestral', 'anchor', 'ancient', 'anderson', 'andrea', 'andrew', 'android', 'andromeda', 'andy', 'anecdote', 'anew', 'angel', 'angela', 'angeles', 'angelic', 'anger', 'angle', 'anglican', 'anglo', 'angry', 'angst', 'angstrom', 'anguish', 'animal', 'animate', 'anita', 'ankh', 'anna', 'anne', 'annex', 'annie', 'anniversary', 'annotate', 'annotation', 'announce', 'annoy', 'annoyance', 'annoyed', 'annoyingly', 'annual', 'anonymous', 'another', 'answer', 'antagonist', 'antebellum', 'anthem', 'anthology', 'anthony', 'anthropologist', 'anti', 'antic', 'anticipate', 'anticipation', 'anticlimactic', 'antidote', 'antiquate', 'antique', 'antithesis', 'antonia', 'anxiety', 'anxious', 'anxiously', 'anybody', 'anyhow', 'anymore', 'anyone', 'anything', 'anytime', 'anyway', 'anyways', 'anywhere', 'apart', 'apartheid', 'apartment', 'apathetic', 'apathy', 'aphorism', 'apocalypse', 'apocalyptic', 'apologetic', 'apologetics', 'apologist', 'apologize', 'apology', 'appal', 'appalachian', 'appalled', 'apparent', 'apparently', 'appeal', 'appear', 'appearance', 'appendix', 'appetite', 'applaud', 'apple', 'applicable', 'application', 'applies', 'apply', 'appoint', 'appreciate', 'appreciates', 'appreciation', 'appreciative', 'apprehension', 'apprentice', 'approach', 'approachable', 'appropriate', 'appropriately', 'approval', 'approve', 'approximately', 'april', 'aptly', 'arab', 'arabella', 'aragorn', 'arbitrary', 'arcane', 'arch', 'archaic', 'archbishop', 'archer', 'archetypal', 'archetype', 'architect', 'architecture', 'arctic', 'ardent', 'arduous', 'area', 'arena', 'arguably', 'argue', 'argues', 'argument', 'arise', 'arises', 'aristocracy', 'aristocrat', 'aristocratic', 'aristotle', 'arizona', 'arkansas', 'armand', 'armchair', 'armor', 'armstrong', 'army', 'aron', 'aronnax', 'arose', 'around', 'arouse', 'arrakis', 'arrange', 'arrangement', 'array', 'arrest', 'arrival', 'arrive', 'arrives', 'arrogance', 'arrogant', 'arronax', 'arrow', 'artemis', 'artful', 'artfully', 'arthur', 'arthurian', 'article', 'articulate', 'artifact', 'artificial', 'artificially', 'artist', 'artistic', 'artistically', 'artistry', 'artwork', 'arya', 'ashamed', 'ashley', 'asia', 'asian', 'aside', 'asimov', 'asks', 'aslan', 'asleep', 'aspect', 'aspiration', 'aspire', 'assassin', 'assassinate', 'assassination', 'assault', 'assemble', 'assembly', 'assert', 'assertion', 'asserts', 'assessment', 'asset', 'assign', 'assignment', 'assist', 'assistance', 'assistant', 'associate', 'association', 'assort', 'assortment', 'assume', 'assumes', 'assumption', 'assurance', 'assure', 'astonish', 'astonishingly', 'astound', 'astray', 'astrid', 'astronaut', 'astute', 'asylum', 'atheism', 'atheist', 'athlete', 'athletic', 'atkinson', 'atlanta', 'atlantic', 'atlantis', 'atlas', 'atmosphere', 'atmospheric', 'atom', 'atomic', 'atonement', 'atop', 'atreides', 'atrocious', 'atrocity', 'attach', 'attachment', 'attack', 'attain', 'attempt', 'attend', 'attendant', 'attends', 'attention', 'attentive', 'attest', 'attic', 'atticus', 'attitude', 'attorney', 'attract', 'attraction', 'attractive', 'attracts', 'attribute', 'atwood', 'atypical', 'aubrey', 'auction', 'audacity', 'audible', 'audience', 'audio', 'audiobook', 'audiobooks', 'auel', 'august', 'augusten', 'augustine', 'aunt', 'aura', 'auschwitz', 'austen', 'austere', 'austin', 'australia', 'australian', 'austrian', 'authentic', 'authenticity', 'author', 'authoress', 'authoritarian', 'authoritative', 'authority', 'autistic', 'auto', 'autobiographical', 'autobiography', 'automatically', 'automobile', 'autumn', 'available', 'avarice', 'avenge', 'avenue', 'average', 'aversion', 'avid', 'avoid', 'avoids', 'await', 'awaits', 'awake', 'awaken', 'awakens', 'award', 'aware', 'awareness', 'away', 'awed', 'awesome', 'awful', 'awfully', 'awhile', 'awkward', 'awry', 'awsome', 'axel', 'axis', 'ayla', 'aziz', 'azkaban', 'babble', 'baby', 'babylon', 'bach', 'bachelor', 'back', 'backbone', 'backdrop', 'background', 'backstory', 'backward', 'backwards', 'bacon', 'badge', 'badger', 'badly', 'baffle', 'baffling', 'baggage', 'baggins', 'bail', 'bait', 'bake', 'baker', 'balance', 'baldacci', 'ball', 'balloon', 'baloo', 'balzac', 'banal', 'band', 'bang', 'banish', 'bank', 'banker', 'banking', 'bankrupt', 'bankruptcy', 'banner', 'bantam', 'banter', 'baptist', 'baratheon', 'barbara', 'barbarian', 'barbaric', 'barbarism', 'bard', 'bare', 'barely', 'bargain', 'barn', 'barnes', 'baron', 'baronet', 'barrel', 'barren', 'barrier', 'barry', 'bart', 'barton', 'base', 'baseball', 'basement', 'bash', 'bashing', 'basic', 'basically', 'basil', 'basis', 'baskerville', 'baskervilles', 'basketball', 'bastard', 'bates', 'bath', 'bathroom', 'batman', 'batter', 'battle', 'battlefield', 'battling', 'baudelaire', 'baum', 'beach', 'beam', 'bean', 'bear', 'bearable', 'beard', 'bearer', 'bearing', 'beast', 'beat', 'beaten', 'beating', 'beatty', 'beau', 'beautiful', 'beautifully', 'beauty', 'beaver', 'beck', 'becky', 'become', 'becomes', 'becuase', 'bedroom', 'bedtime', 'beecher', 'beef', 'beer', 'beforehand', 'befriend', 'befriends', 'beggar', 'begin', 'begining', 'beginner', 'beginning', 'begs', 'behalf', 'behave', 'behaves', 'behaving', 'behavior', 'behavioral', 'behaviour', 'behind', 'behold', 'being', 'belgian', 'belgium', 'belief', 'believability', 'believable', 'believe', 'believeable', 'believer', 'belive', 'bell', 'bella', 'belle', 'belly', 'belong', 'belonging', 'belongs', 'beloved', 'belt', 'bend', 'bending', 'bendrix', 'bene', 'beneath', 'benefactor', 'beneficial', 'benefit', 'benevolence', 'benevolent', 'benign', 'benjamin', 'benjy', 'bennet', 'bennett', 'bent', 'benton', 'beorn', 'beowulf', 'berendt', 'berlin', 'bernard', 'berry', 'bertha', 'bertram', 'beset', 'beside', 'besides', 'best', 'bestow', 'bestseller', 'bestselling', 'beta', 'beth', 'bethany', 'betray', 'betrayal', 'betrayed', 'betrays', 'betty', 'beware', 'bewilder', 'beyond', 'bias', 'bible', 'biblical', 'bibliography', 'bickering', 'biddy', 'biff', 'bigotry', 'bike', 'bilbo', 'bildungsroman', 'bill', 'billion', 'billy', 'bind', 'binding', 'bingley', 'binx', 'biographer', 'biographical', 'biography', 'biological', 'biologist', 'biology', 'bird', 'birth', 'birthday', 'bishop', 'bite', 'biting', 'bitten', 'bitter', 'bitterly', 'bitterness', 'bittersweet', 'bizarre', 'black', 'blackmail', 'blacksmith', 'blade', 'blah', 'blaine', 'blair', 'blake', 'blame', 'blanche', 'bland', 'blank', 'blanket', 'blasphemy', 'blast', 'blatant', 'blatantly', 'blazing', 'bleak', 'blend', 'blending', 'bless', 'blessing', 'blew', 'blight', 'blind', 'blindly', 'blindness', 'blink', 'bliss', 'bloat', 'block', 'blockbuster', 'blog', 'blogspot', 'blond', 'blonde', 'blood', 'bloodshed', 'bloody', 'bloom', 'blossom', 'blow', 'blowing', 'blown', 'bltc', 'blue', 'blueprint', 'blunder', 'blunt', 'blur', 'blurb', 'blush', 'board', 'boarding', 'boast', 'boat', 'bobby', 'bobos', 'bodily', 'body', 'bogart', 'bogged', 'boggling', 'bohemian', 'boil', 'bokononism', 'bold', 'boldly', 'boleyn', 'bolitar', 'bolshevik', 'bolt', 'bomb', 'bombadil', 'bombardier', 'bombed', 'bomber', 'bombing', 'bond', 'bondage', 'bone', 'bonfire', 'bonus', 'booker', 'bookish', 'bookmark', 'bookshelf', 'bookstore', 'bookworm', 'boom', 'boone', 'boost', 'boot', 'booth', 'booze', 'border', 'bordering', 'borderline', 'bore', 'boredom', 'boring', 'boris', 'born', 'borne', 'boromir', 'borrow', 'borrowing', 'bosch', 'bosom', 'boss', 'boston', 'bother', 'botswana', 'bottle', 'bottom', 'bought', 'bounce', 'bound', 'boundary', 'bounderby', 'boundless', 'bounty', 'bourgeois', 'bourgh', 'bourne', 'bout', 'bovary', 'bowl', 'boxed', 'boxer', 'boyfriend', 'boyhood', 'boyish', 'bradbury', 'bradley', 'brag', 'brain', 'brainwash', 'brainwashing', 'bram', 'bran', 'branch', 'brand', 'brandon', 'brash', 'brat', 'brave', 'bravely', 'bravery', 'bravo', 'brazil', 'bread', 'breadth', 'break', 'breakdown', 'breaker', 'breakfast', 'breakneck', 'breakthrough', 'breast', 'breath', 'breathe', 'breathes', 'breathing', 'breathless', 'breathtaking', 'breed', 'breeding', 'breeze', 'breezy', 'brett', 'brevity', 'brian', 'brick', 'bride', 'brideshead', 'bridge', 'bridget', 'brief', 'briefly', 'brien', 'brigade', 'bright', 'brighter', 'brightest', 'brightly', 'brilliance', 'brilliant', 'brilliantly', 'bring', 'brings', 'brink', 'briony', 'brisk', 'brit', 'britain', 'british', 'broad', 'broadcast', 'broaden', 'broader', 'broadview', 'broadway', 'brocklehurst', 'brodie', 'brokaw', 'broke', 'broken', 'broker', 'brom', 'bromden', 'bront', 'bronte', 'brood', 'brooding', 'brook', 'brooke', 'brooklyn', 'brother', 'brotherhood', 'brought', 'brow', 'brown', 'bruce', 'brush', 'brutal', 'brutality', 'brutally', 'brute', 'brutish', 'bryson', 'bubble', 'buchanan', 'buck', 'bucket', 'buddha', 'buddhism', 'buddhist', 'budding', 'buddy', 'budget', 'buff', 'buffalo', 'buick', 'build', 'builder', 'building', 'buildup', 'built', 'bulk', 'bull', 'bullet', 'bullfight', 'bullfighting', 'bully', 'bullying', 'bulstrode', 'bumble', 'bumbling', 'bump', 'bunch', 'bundle', 'bundy', 'bunny', 'burden', 'bureaucracy', 'bureaucrat', 'bureaucratic', 'burgess', 'burglar', 'burial', 'burn', 'burnham', 'burning', 'burnt', 'burroughs', 'burst', 'bursting', 'burton', 'bury', 'bush', 'business', 'businessman', 'businessmen', 'bust', 'busy', 'butcher', 'butler', 'butt', 'butter', 'butterfly', 'button', 'buyer', 'buying', 'buzz', 'bygone', 'bypass', 'byronic', 'cabin', 'cabinet', 'cable', 'caddy', 'cadence', 'caesar', 'cafe', 'cage', 'cahill', 'cain', 'cake', 'calamity', 'calculate', 'caleb', 'caliber', 'california', 'call', 'callie', 'calliope', 'callous', 'calm', 'calmly', 'calvin', 'camaraderie', 'cambridge', 'camel', 'camelot', 'cameo', 'camera', 'camille', 'camp', 'campaign', 'campbell', 'camper', 'campus', 'camus', 'canada', 'canadian', 'canal', 'cancel', 'cancer', 'candid', 'candidate', 'candide', 'candle', 'candy', 'cannery', 'cannibal', 'cannibalism', 'cannon', 'canon', 'cant', 'canterbury', 'canticle', 'canvas', 'capability', 'capable', 'capacity', 'cape', 'capital', 'capitalism', 'capitalist', 'capitalistic', 'capote', 'captain', 'captivate', 'captivates', 'captive', 'captivity', 'captor', 'capture', 'carbon', 'card', 'cardboard', 'cardinal', 'care', 'career', 'carefree', 'careful', 'carefully', 'careless', 'carelessness', 'caretaker', 'carey', 'caribbean', 'caricature', 'carl', 'carmen', 'carnage', 'carnegie', 'carnival', 'carol', 'carolina', 'caroline', 'caroll', 'carpenter', 'carr', 'carraway', 'carre', 'carriage', 'carrie', 'carrol', 'carroll', 'carry', 'carson', 'cart', 'carter', 'carton', 'cartoon', 'cartoonish', 'carve', 'casaubon', 'case', 'cash', 'casino', 'caspian', 'cassandra', 'cassette', 'cast', 'caste', 'casterbridge', 'castle', 'casual', 'casually', 'casualty', 'catalog', 'catalogue', 'catalyst', 'catastrophe', 'catastrophic', 'catch', 'catcher', 'categorize', 'category', 'caterpillar', 'cathcart', 'cathedral', 'cather', 'catherine', 'catholic', 'catholicism', 'cathy', 'cattle', 'caufield', 'caught', 'caulfield', 'cause', 'caustic', 'caution', 'cautionary', 'cautious', 'cave', 'caveat', 'cavern', 'cease', 'cecil', 'celebrate', 'celebrates', 'celebration', 'celebrity', 'cell', 'cement', 'cemetery', 'censor', 'censorship', 'cent', 'center', 'central', 'centre', 'century', 'cerebral', 'ceremony', 'cersei', 'certain', 'certainly', 'certainty', 'cervantes', 'chabon', 'chagrin', 'chain', 'chair', 'chairman', 'challenge', 'challenged', 'challenger', 'chamber', 'chamberlain', 'champion', 'chance', 'chandler', 'change', 'channel', 'chaos', 'chaotic', 'chap', 'chapel', 'chaplain', 'chapter', 'character', 'characterisation', 'characteristic', 'characterization', 'characterize', 'characterizes', 'charactors', 'charecters', 'charge', 'charisma', 'charismatic', 'charitable', 'charity', 'charles', 'charley', 'charlie', 'charlotte', 'charm', 'chart', 'charter', 'chase', 'chat', 'chatter', 'chatterley', 'chatterly', 'chaucer', 'cheap', 'cheaper', 'cheat', 'check', 'checked', 'cheek', 'cheer', 'cheerful', 'cheese', 'cheesy', 'chemical', 'chemistry', 'cherish', 'cherished', 'cheshire', 'chess', 'chest', 'chesterton', 'chevalier', 'chew', 'chicago', 'chick', 'chicken', 'chief', 'child', 'childbirth', 'childhood', 'childish', 'childlike', 'childrens', 'chill', 'chillingsworth', 'chillingworth', 'china', 'chinese', 'ching', 'chingachgook', 'chip', 'chivalry', 'chiyo', 'chock', 'chocolate', 'choice', 'choke', 'cholera', 'choose', 'chooses', 'chop', 'chopin', 'choppy', 'chord', 'chore', 'chose', 'chosen', 'chris', 'christ', 'christian', 'christianity', 'christie', 'christine', 'christmas', 'christopher', 'chronicle', 'chronological', 'chronologically', 'chronology', 'chuck', 'chuckle', 'chunk', 'church', 'churchill', 'churn', 'cicero', 'cigarette', 'cinderella', 'cinema', 'cinematic', 'circa', 'circle', 'circular', 'circumstance', 'circus', 'cite', 'citizen', 'city', 'civil', 'civilian', 'civilisation', 'civility', 'civilization', 'civilize', 'clad', 'claim', 'claimed', 'claire', 'clan', 'clancy', 'clandestine', 'clara', 'clare', 'clarence', 'clarendon', 'clarice', 'clarify', 'clarissa', 'clarisse', 'clarity', 'clark', 'clarke', 'clash', 'class', 'classic', 'classical', 'classification', 'classify', 'classmate', 'classroom', 'classy', 'claude', 'claudia', 'claudius', 'clause', 'claustrophobic', 'claw', 'clay', 'clean', 'cleaning', 'cleanse', 'clear', 'clearer', 'clearly', 'clemens', 'clergy', 'clergyman', 'clerk', 'clever', 'cleverly', 'cleverness', 'clich', 'cliche', 'cliched', 'click', 'client', 'cliff', 'cliffhanger', 'clifford', 'climactic', 'climate', 'climatic', 'climax', 'climb', 'climber', 'cling', 'clinic', 'clinical', 'clinton', 'clip', 'clive', 'cloak', 'clock', 'clockwork', 'clone', 'close', 'closely', 'closeness', 'closer', 'closest', 'closet', 'closing', 'closure', 'cloth', 'clothbound', 'clothes', 'clothing', 'cloud', 'clown', 'club', 'clue', 'clueless', 'clumsy', 'clunky', 'clutch', 'clutter', 'clyde', 'coach', 'coal', 'coarse', 'coast', 'coaster', 'coat', 'coben', 'code', 'coetzee', 'coffee', 'coffin', 'cognitive', 'coherent', 'cohesive', 'cohn', 'cohort', 'coin', 'coincidence', 'coincidental', 'cold', 'cole', 'colin', 'collapse', 'collar', 'colleague', 'collect', 'collection', 'collective', 'collectively', 'collectivism', 'collector', 'college', 'collide', 'collins', 'collision', 'colloquial', 'colonel', 'colonial', 'colonialism', 'colonist', 'colonization', 'colonize', 'colony', 'color', 'colorado', 'colorful', 'colossal', 'colour', 'colourful', 'columbus', 'column', 'coma', 'combat', 'combination', 'combine', 'come', 'comedian', 'comedic', 'comedy', 'comet', 'comfort', 'comfortable', 'comfortably', 'comic', 'comical', 'comically', 'comma', 'command', 'commander', 'commandment', 'commend', 'commendable', 'comment', 'commentary', 'commentator', 'commerce', 'commercial', 'commission', 'commit', 'commitment', 'commits', 'committee', 'commodity', 'common', 'commoner', 'commonly', 'commonplace', 'communal', 'communicate', 'communication', 'communism', 'communist', 'community', 'commute', 'compact', 'companion', 'companionship', 'company', 'comparable', 'comparative', 'compare', 'comparison', 'compass', 'compassion', 'compassionate', 'compel', 'compelling', 'compensate', 'compete', 'competent', 'competition', 'competitive', 'competitor', 'compilation', 'compile', 'complacency', 'complacent', 'complain', 'complains', 'complaint', 'complement', 'complete', 'completely', 'completes', 'completion', 'complex', 'complexity', 'complicate', 'complication', 'compliment', 'component', 'compose', 'composition', 'compound', 'comprehend', 'comprehensible', 'comprehension', 'comprehensive', 'comprise', 'compromise', 'compson', 'compulsive', 'computer', 'comrade', 'conan', 'conceal', 'concede', 'conceit', 'conceited', 'conceive', 'concentrate', 'concentration', 'concept', 'conception', 'conceptual', 'concern', 'concerned', 'concert', 'concise', 'conclude', 'concludes', 'conclusion', 'concoct', 'concord', 'concrete', 'concubine', 'condemn', 'condemnation', 'condemns', 'condense', 'condescend', 'condescension', 'condition', 'conditioning', 'condone', 'conduct', 'confederacy', 'confederate', 'conference', 'confess', 'confesses', 'confession', 'confidant', 'confidence', 'confident', 'confine', 'confines', 'confirm', 'confirms', 'conflict', 'conform', 'conformity', 'confront', 'confrontation', 'confronts', 'confuse', 'confusion', 'congo', 'congress', 'conjecture', 'conjunction', 'conjure', 'conjures', 'connect', 'connecticut', 'connection', 'connects', 'connelly', 'connie', 'connive', 'connotation', 'conquer', 'conquers', 'conquest', 'conrad', 'conroy', 'conscience', 'conscious', 'consciously', 'consciousness', 'conseil', 'consensus', 'consent', 'consequence', 'consequently', 'conservative', 'consider', 'considerable', 'considerably', 'consideration', 'considers', 'consist', 'consistency', 'consistent', 'consistently', 'consists', 'conspiracy', 'conspire', 'constance', 'constant', 'constantly', 'constitute', 'constitutes', 'constitution', 'constitutional', 'constraint', 'construct', 'construction', 'consult', 'consume', 'consumer', 'consumerism', 'consumes', 'consummate', 'consumption', 'contact', 'contain', 'contains', 'contemplate', 'contemplation', 'contemporary', 'contempt', 'contend', 'content', 'contention', 'contentment', 'contest', 'context', 'contextual', 'continent', 'continental', 'continual', 'continually', 'continuation', 'continue', 'continued', 'continuity', 'continuous', 'continuously', 'contract', 'contradict', 'contradiction', 'contradictory', 'contradicts', 'contrary', 'contrast', 'contribute', 'contributes', 'contribution', 'contrivance', 'contrive', 'control', 'controller', 'controversial', 'controversy', 'conundrum', 'convenience', 'convenient', 'conveniently', 'convention', 'conventional', 'converge', 'conversation', 'conversational', 'converse', 'conversely', 'conversion', 'convert', 'convey', 'conveyed', 'conveys', 'convict', 'conviction', 'convince', 'convinces', 'convincing', 'convincingly', 'convolute', 'conway', 'cook', 'cooked', 'cookie', 'cooking', 'cool', 'cooper', 'cope', 'copious', 'copper', 'copperfield', 'copy', 'copyright', 'cora', 'core', 'corey', 'corleone', 'cormac', 'corn', 'corner', 'cornerstone', 'cornwell', 'corny', 'corp', 'corporate', 'corporation', 'corps', 'corpse', 'correct', 'correction', 'correctly', 'correctness', 'correspond', 'correspondence', 'corrupt', 'corruption', 'corrupts', 'cosmic', 'cosmos', 'cost', 'costume', 'cottage', 'cotton', 'couch', 'could', 'couldnt', 'coulter', 'council', 'counsel', 'count', 'countenance', 'counter', 'counterpart', 'counterpoint', 'countess', 'counting', 'countless', 'country', 'countryman', 'countryside', 'county', 'coup', 'couple', 'courage', 'courageous', 'course', 'court', 'courtesy', 'courtroom', 'courtship', 'cousin', 'cover', 'coverage', 'covert', 'covet', 'covey', 'coward', 'cowardice', 'cowardly', 'cowboy', 'cozy', 'crab', 'crack', 'cradle', 'craft', 'craftsman', 'craftsmanship', 'crafty', 'crais', 'crake', 'crammed', 'crane', 'crap', 'crash', 'crashed', 'cratchit', 'crave', 'crawford', 'crawl', 'craze', 'craziness', 'crazy', 'cream', 'create', 'creates', 'creation', 'creative', 'creatively', 'creativity', 'creator', 'creature', 'credential', 'credibility', 'credible', 'credit', 'creed', 'creek', 'creep', 'creepy', 'crew', 'crichton', 'crime', 'criminal', 'cringe', 'cripple', 'crisis', 'crisp', 'cristo', 'criterion', 'critic', 'critical', 'critically', 'criticise', 'criticism', 'criticize', 'criticizes', 'critique', 'croft', 'crook', 'crooked', 'crop', 'croquet', 'cross', 'crow', 'crowd', 'crown', 'crucial', 'crucible', 'crude', 'cruel', 'cruelly', 'cruelty', 'cruise', 'crumble', 'crusade', 'crush', 'crusie', 'crusoe', 'crust', 'crux', 'cryptic', 'crystal', 'cuba', 'cuban', 'cuckoo', 'culminate', 'culminates', 'culmination', 'culprit', 'cult', 'cultivate', 'cultural', 'culturally', 'culture', 'cumbersome', 'cunning', 'cunningham', 'cure', 'curiosity', 'curious', 'curiouser', 'curiously', 'curl', 'curley', 'curly', 'currency', 'current', 'currently', 'curriculum', 'curry', 'curse', 'curtain', 'curve', 'cussler', 'custody', 'custom', 'customer', 'cute', 'cutter', 'cycle', 'cynic', 'cynical', 'cynicism', 'daddy', 'daenerys', 'dagger', 'dagny', 'dahl', 'daily', 'daisy', 'dale', 'dalloway', 'damage', 'dame', 'damn', 'damnation', 'damsel', 'dana', 'dance', 'dandelion', 'dandy', 'daneeka', 'danger', 'dangerous', 'dangerously', 'dangle', 'daniel', 'danny', 'dante', 'darcy', 'dare', 'dark', 'darken', 'darker', 'darkest', 'darkly', 'darkness', 'darling', 'darn', 'darnay', 'darwin', 'darwinism', 'dash', 'dashiell', 'dashwood', 'data', 'date', 'daughter', 'daunt', 'dave', 'davenport', 'david', 'davinci', 'davis', 'davy', 'dawkins', 'dawn', 'daydream', 'daylight', 'dazzle', 'dead', 'deadline', 'deadly', 'deaf', 'deal', 'dealer', 'dealing', 'dealt', 'dean', 'dear', 'dearest', 'dearly', 'death', 'deathbed', 'deaver', 'debase', 'debatable', 'debate', 'debauchery', 'debt', 'debut', 'decade', 'decadence', 'decadent', 'decay', 'decease', 'deceit', 'deceitful', 'deceive', 'december', 'decency', 'decent', 'deception', 'deceptive', 'deceptively', 'decide', 'decidedly', 'decides', 'decipher', 'decision', 'decisive', 'deck', 'deckard', 'declaration', 'declare', 'declares', 'decline', 'decorate', 'decrease', 'dedalus', 'dedicate', 'dedication', 'deduce', 'deduction', 'deed', 'deem', 'deep', 'deepen', 'deeper', 'deepest', 'deeply', 'defarge', 'defeat', 'defect', 'defence', 'defend', 'defender', 'defends', 'defense', 'defiance', 'defiant', 'defiantly', 'deficiency', 'defies', 'definately', 'definatly', 'define', 'defines', 'definetly', 'definite', 'definitely', 'definition', 'definitive', 'defoe', 'deform', 'deft', 'deftly', 'defy', 'degenerate', 'degradation', 'degrade', 'degree', 'dehumanize', 'deism', 'deist', 'deity', 'delay', 'delayed', 'delete', 'delf', 'deliberate', 'deliberately', 'delicate', 'delicately', 'delicious', 'deliciously', 'delight', 'delighted', 'delightful', 'delightfully', 'delillo', 'delineate', 'deliver', 'delivers', 'delivery', 'delta', 'delude', 'delusion', 'delusional', 'deluxe', 'delve', 'demand', 'demean', 'demeanor', 'demented', 'demille', 'demise', 'democracy', 'democrat', 'democratic', 'demolish', 'demon', 'demonic', 'demonstrate', 'demonstrates', 'demonstration', 'denial', 'denies', 'denizen', 'dennis', 'denomination', 'denouement', 'denounce', 'dense', 'density', 'dent', 'deny', 'depart', 'department', 'departs', 'departure', 'depend', 'dependence', 'dependent', 'depends', 'depict', 'depiction', 'depicts', 'deplorable', 'deprave', 'depravity', 'deprecate', 'depress', 'depressed', 'depression', 'deprivation', 'deprive', 'depth', 'deputy', 'derange', 'derivative', 'derive', 'derives', 'descend', 'descendant', 'descends', 'descent', 'describe', 'described', 'describes', 'description', 'descriptive', 'desert', 'deserve', 'deservedly', 'deserves', 'design', 'designer', 'desirable', 'desire', 'desk', 'desolate', 'desolation', 'despair', 'desperate', 'desperately', 'desperation', 'despicable', 'despise', 'despises', 'despite', 'dessert', 'destination', 'destine', 'destiny', 'destitute', 'destroy', 'destroyed', 'destroys', 'destruction', 'destructive', 'detach', 'detachment', 'detail', 'detailed', 'detect', 'detection', 'detective', 'deter', 'deteriorate', 'deterioration', 'determination', 'determine', 'determines', 'detest', 'detour', 'detract', 'detractor', 'detracts', 'detriment', 'detrimental', 'detroit', 'deus', 'devastate', 'devastation', 'develop', 'developed', 'development', 'develops', 'deviate', 'device', 'devil', 'devilish', 'devious', 'devise', 'devoid', 'devon', 'devote', 'devotee', 'devotes', 'devotion', 'devour', 'devout', 'dexter', 'diabolical', 'diagnose', 'diagram', 'dialect', 'dialog', 'dialogue', 'diamant', 'diamond', 'diana', 'diary', 'diatribe', 'dichotomy', 'dick', 'dicken', 'dickens', 'dickensian', 'dictate', 'dictator', 'dictatorship', 'diction', 'dictionary', 'didactic', 'didnt', 'diet', 'differ', 'difference', 'different', 'differentiate', 'differently', 'differs', 'difficult', 'difficulty', 'digest', 'digital', 'dignify', 'dignity', 'digory', 'digress', 'digression', 'dilemma', 'dill', 'dilute', 'dime', 'dimension', 'dimensional', 'diminish', 'dimmesdale', 'dimmsdale', 'dina', 'dinah', 'diner', 'dinner', 'dinosaur', 'diplomat', 'diplomatic', 'dire', 'direct', 'direction', 'directly', 'director', 'dirk', 'dirt', 'dirty', 'disability', 'disabled', 'disadvantage', 'disagree', 'disagreeable', 'disagreement', 'disagrees', 'disappear', 'disappearance', 'disappears', 'disappoint', 'disappointed', 'disappointment', 'disappoints', 'disapprove', 'disaster', 'disastrous', 'disbelief', 'disc', 'discard', 'discern', 'disciple', 'discipline', 'disclaimer', 'disclose', 'disclosure', 'discomfort', 'disconcert', 'disconnect', 'discontent', 'discount', 'discourage', 'discourse', 'discover', 'discovers', 'discovery', 'discredit', 'discrimination', 'discus', 'discuss', 'discussion', 'discworld', 'disdain', 'disease', 'disfigure', 'disgrace', 'disgruntle', 'disguise', 'disgust', 'dish', 'dishonest', 'disillusion', 'disillusionment', 'disintegration', 'disjoint', 'disk', 'dislike', 'disliked', 'dismal', 'dismay', 'dismiss', 'disney', 'disorder', 'disorient', 'disparage', 'disparate', 'dispatch', 'dispense', 'displace', 'display', 'displayed', 'dispose', 'disposition', 'disprove', 'dispute', 'disregard', 'disrupt', 'dissapointed', 'dissatisfied', 'dissect', 'dissent', 'dissertation', 'disservice', 'dissolve', 'distance', 'distant', 'distaste', 'distasteful', 'distinct', 'distinction', 'distinctive', 'distinctly', 'distinguish', 'distinguishes', 'distort', 'distract', 'distraction', 'distraught', 'distress', 'distribute', 'distribution', 'district', 'distrust', 'disturb', 'disturbed', 'disturbingly', 'ditch', 'dive', 'diver', 'diverse', 'diversion', 'diversity', 'divert', 'divide', 'divine', 'division', 'divorce', 'divulge', 'dizzy', 'dock', 'doctor', 'doctrine', 'document', 'documentary', 'documentation', 'dodge', 'dodgson', 'doesnt', 'dogma', 'dogmatic', 'doings', 'doll', 'dollar', 'dolly', 'dolores', 'domain', 'domestic', 'dominance', 'dominant', 'dominate', 'dominates', 'domination', 'dominique', 'donald', 'donate', 'dont', 'doom', 'door', 'doorstep', 'dorian', 'dorothea', 'dorothy', 'dose', 'dostoevsky', 'dostoyevsky', 'double', 'doublethink', 'doubt', 'doubtful', 'doubtless', 'douglas', 'dove', 'dover', 'down', 'downer', 'downfall', 'downhill', 'download', 'downright', 'downside', 'downtrodden', 'downward', 'doyle', 'dozen', 'drab', 'dracula', 'draft', 'drag', 'dragon', 'drain', 'drama', 'dramatic', 'dramatically', 'dramatization', 'dramatize', 'drank', 'drastic', 'drastically', 'draw', 'drawback', 'drawing', 'drawn', 'dread', 'dreadful', 'dream', 'dreamcatcher', 'dreamer', 'dreamlike', 'dreamy', 'dreary', 'dreiser', 'dresden', 'dress', 'drew', 'drift', 'drifter', 'drink', 'drinking', 'drip', 'drive', 'drivel', 'driven', 'driver', 'droll', 'drone', 'drop', 'drouet', 'drove', 'drown', 'drudgery', 'drug', 'drum', 'drunk', 'drunkard', 'drunken', 'dual', 'duality', 'dubbed', 'dubious', 'dublin', 'dubliner', 'dubois', 'duchess', 'duck', 'dude', 'duel', 'duke', 'dull', 'duma', 'dumb', 'dump', 'dumped', 'dumpty', 'duncan', 'dune', 'dungeon', 'dunstan', 'duplicate', 'durable', 'durant', 'duration', 'durbeyfield', 'dust', 'dusty', 'dutch', 'duty', 'dwarf', 'dwell', 'dweller', 'dwells', 'dylan', 'dynamic', 'dynasty', 'dysfunction', 'dysfunctional', 'dystopia', 'dystopian', 'eachother', 'eacute', 'eager', 'eagerly', 'eagle', 'earl', 'earlier', 'early', 'earn', 'earnest', 'earns', 'earnshaw', 'earnshaws', 'earring', 'earth', 'earthling', 'earthly', 'earthquake', 'earthsea', 'earthy', 'ease', 'easily', 'east', 'easter', 'eastern', 'easton', 'easy', 'eats', 'ebenezer', 'ebook', 'ebooks', 'eccentric', 'eccentricity', 'echo', 'eclectic', 'eclipse', 'economic', 'economical', 'economically', 'economics', 'economist', 'economy', 'eddie', 'eden', 'edgar', 'edge', 'edgy', 'edit', 'edith', 'edition', 'editor', 'editorial', 'edmond', 'edmund', 'edna', 'educate', 'education', 'educational', 'educator', 'edward', 'edwardian', 'edwin', 'eerie', 'eerily', 'effect', 'effective', 'effectively', 'effectiveness', 'efficiency', 'efficient', 'effort', 'effortless', 'effortlessly', 'egotistical', 'egrave', 'egwene', 'egypt', 'egyptian', 'ehrenreich', 'eight', 'eighteen', 'eighteenth', 'eighth', 'eighty', 'einstein', 'either', 'elaborate', 'elayne', 'elder', 'elderly', 'eldest', 'eleanor', 'elect', 'election', 'electric', 'electricity', 'electronic', 'elegance', 'elegant', 'elegantly', 'element', 'elemental', 'elementary', 'elephant', 'elevate', 'elevates', 'eleven', 'elicit', 'elie', 'eligible', 'eliminate', 'elinor', 'eliot', 'elite', 'elitist', 'eliza', 'elizabeth', 'ella', 'ellen', 'elli', 'elliot', 'elliott', 'ellison', 'eloi', 'eloquence', 'eloquent', 'eloquently', 'elphaba', 'elrond', 'else', 'elsewhere', 'elton', 'elude', 'elusive', 'elven', 'elvis', 'email', 'emancipation', 'embark', 'embarks', 'embarrass', 'embarrassment', 'embed', 'embellish', 'embitter', 'emblem', 'embodies', 'embodiment', 'embody', 'embrace', 'embroider', 'embryo', 'emerge', 'emergence', 'emergency', 'emerges', 'emerson', 'emily', 'eminently', 'emma', 'emotion', 'emotional', 'emotionally', 'empathize', 'empathy', 'emperor', 'emphasis', 'emphasize', 'emphasizes', 'empire', 'employ', 'employee', 'employer', 'employment', 'empower', 'emptiness', 'empty', 'emulate', 'enable', 'enables', 'enamor', 'encapsulate', 'enchant', 'enchantment', 'encompass', 'encompasses', 'encounter', 'encourage', 'encouragement', 'encourages', 'encyclopedia', 'endanger', 'endear', 'endeavor', 'endeavour', 'ender', 'ending', 'endless', 'endlessly', 'endnotes', 'endorse', 'endorsement', 'endow', 'endurance', 'endure', 'endures', 'enemy', 'energetic', 'energy', 'enforce', 'enforcement', 'engage', 'engagement', 'engages', 'engender', 'engine', 'engineer', 'engineering', 'england', 'engle', 'english', 'englishman', 'engross', 'enhance', 'enhances', 'enigma', 'enigmatic', 'enjoy', 'enjoyable', 'enjoyment', 'enjoys', 'enlarge', 'enlighten', 'enlightenment', 'enlist', 'enlists', 'enormous', 'enormously', 'enough', 'enrage', 'enrapture', 'enrich', 'enslave', 'ensue', 'ensues', 'ensure', 'entail', 'entangle', 'entanglement', 'enter', 'enterprise', 'enters', 'entertain', 'entertainment', 'entertains', 'enthral', 'enthusiasm', 'enthusiast', 'enthusiastic', 'enthusiastically', 'entice', 'entire', 'entirely', 'entirety', 'entitle', 'entity', 'entrance', 'entrench', 'entrepreneur', 'entry', 'ents', 'entwine', 'envelop', 'envelope', 'envious', 'environment', 'environmental', 'environmentalist', 'envision', 'envy', 'epic', 'epidemic', 'epigram', 'epilogue', 'epiphany', 'episode', 'episodic', 'epitome', 'epitomizes', 'epoch', 'eponymous', 'eppie', 'epsilon', 'equal', 'equality', 'equally', 'equate', 'equation', 'equilibrium', 'equip', 'equipment', 'equivalent', 'eragon', 'erase', 'eric', 'erik', 'ernest', 'eros', 'erotic', 'erratic', 'error', 'erudite', 'eruption', 'escalate', 'escapade', 'escape', 'escapism', 'escapist', 'escort', 'esoteric', 'especially', 'espionage', 'espouse', 'esque', 'essay', 'essence', 'essential', 'essentially', 'essex', 'establish', 'establishes', 'establishment', 'estate', 'esteem', 'estella', 'esther', 'estimate', 'estimation', 'estrange', 'etch', 'eternal', 'eternally', 'eternity', 'ethan', 'ethereal', 'ethic', 'ethical', 'ethnic', 'etiquette', 'eugenics', 'eugenides', 'eurasia', 'europe', 'european', 'eustace', 'evade', 'evaluate', 'evaluation', 'evangelical', 'evanovich', 'evans', 'evelyn', 'even', 'evening', 'event', 'eventful', 'eventual', 'eventually', 'ever', 'everest', 'everlasting', 'every', 'everybody', 'everyday', 'everyman', 'everyone', 'everything', 'everytime', 'everywhere', 'evidence', 'evident', 'evidently', 'evil', 'evocation', 'evocative', 'evoke', 'evokes', 'evolution', 'evolutionary', 'evolve', 'evolves', 'ewell', 'exact', 'exactly', 'exaggerate', 'exaggerated', 'exaggeration', 'exalt', 'exam', 'examination', 'examine', 'examines', 'example', 'exasperate', 'exceed', 'exceedingly', 'exceeds', 'excel', 'excellence', 'excellent', 'excellently', 'excels', 'except', 'exception', 'exceptional', 'exceptionally', 'excerpt', 'excess', 'excessive', 'excessively', 'exchange', 'excite', 'excitement', 'exclaim', 'exclude', 'exclusion', 'exclusive', 'exclusively', 'excruciate', 'excruciatingly', 'excursion', 'excuse', 'execute', 'execution', 'executive', 'exemplary', 'exemplifies', 'exemplify', 'exercise', 'exert', 'exhaust', 'exhaustion', 'exhaustive', 'exhibit', 'exhilarate', 'exile', 'exist', 'existance', 'existence', 'existent', 'existential', 'existentialism', 'existentialist', 'exists', 'exit', 'exotic', 'expand', 'expands', 'expansion', 'expansive', 'expatriate', 'expect', 'expectation', 'expedition', 'expel', 'expense', 'expensive', 'experience', 'experienced', 'experiment', 'experimental', 'experimentation', 'expert', 'expertise', 'expertly', 'explain', 'explains', 'explanation', 'explanatory', 'explicit', 'explicitly', 'explode', 'exploit', 'exploitation', 'exploration', 'explore', 'explorer', 'explores', 'explosion', 'explosive', 'expose', 'exposition', 'exposure', 'expound', 'express', 'expression', 'expressive', 'exquisite', 'exquisitely', 'extend', 'extends', 'extension', 'extensive', 'extensively', 'extent', 'exterior', 'exterminate', 'external', 'extinct', 'extinction', 'extra', 'extract', 'extraneous', 'extraordinarily', 'extraordinary', 'extravagant', 'extreme', 'extremely', 'extremist', 'exuberance', 'eyebrow', 'eyed', 'eyre', 'ezra', 'faber', 'fable', 'fabric', 'fabricate', 'fabulous', 'fabulously', 'facade', 'face', 'faceless', 'facet', 'faceted', 'facility', 'facinating', 'fact', 'faction', 'factor', 'factory', 'factual', 'faculty', 'fade', 'fading', 'faerie', 'fagin', 'fahrenheit', 'fail', 'failing', 'fails', 'failure', 'faint', 'fair', 'faire', 'fairfax', 'fairly', 'fairness', 'fairy', 'fairytale', 'faith', 'faithful', 'faithfully', 'fake', 'falcon', 'fall', 'fallacy', 'fallible', 'false', 'falsely', 'falter', 'fame', 'famed', 'familial', 'familiar', 'familiarity', 'family', 'famine', 'famous', 'famously', 'fanatic', 'fanatical', 'fanaticism', 'fanciful', 'fancy', 'fang', 'fanny', 'fantastic', 'fantastical', 'fantastically', 'fantasy', 'faramir', 'farce', 'farcical', 'fare', 'farewell', 'farfrae', 'farm', 'farmer', 'farther', 'fascinate', 'fascination', 'fascism', 'fascist', 'fashion', 'fashionable', 'fast', 'faster', 'fatal', 'fatalistic', 'fate', 'fateful', 'father', 'fathom', 'faulkner', 'fault', 'fauna', 'faust', 'faustian', 'faux', 'fave', 'favor', 'favorable', 'favorite', 'favour', 'favourite', 'fawn', 'fear', 'fearful', 'fearless', 'fearsome', 'feast', 'feat', 'feather', 'feature', 'federal', 'feeble', 'feed', 'feedback', 'feel', 'feeling', 'feisty', 'felix', 'fell', 'fellow', 'fellowship', 'felt', 'female', 'feminine', 'feminism', 'feminist', 'fence', 'fend', 'fenimore', 'fermina', 'fern', 'ferocious', 'ferrars', 'fertile', 'fervent', 'fervor', 'festival', 'fetch', 'feud', 'feudal', 'fever', 'fforde', 'fianc', 'fiance', 'fiancee', 'fickle', 'fiction', 'fictional', 'fictionalize', 'fictitious', 'fidelity', 'field', 'fielding', 'fiend', 'fierce', 'fiercely', 'fiery', 'fiesta', 'fifteen', 'fifth', 'fifty', 'fight', 'fighter', 'figurative', 'figuratively', 'figure', 'file', 'fill', 'filler', 'film', 'filter', 'filth', 'filthy', 'final', 'finale', 'finally', 'finance', 'financial', 'financially', 'finch', 'find', 'finding', 'fine', 'finely', 'finer', 'finger', 'finish', 'finn', 'finnegan', 'finnegans', 'finny', 'fire', 'firebomb', 'fireman', 'fireplace', 'firm', 'firmly', 'first', 'firsthand', 'firstly', 'firth', 'fish', 'fisherman', 'fishing', 'fist', 'fitting', 'fitz', 'fitzgerald', 'fitzwilliam', 'five', 'flag', 'flagg', 'flair', 'flamboyant', 'flame', 'flamingo', 'flap', 'flash', 'flashback', 'flat', 'flatland', 'flatter', 'flaubert', 'flavor', 'flaw', 'flawless', 'flawlessly', 'flee', 'flees', 'fleet', 'fleeting', 'fleming', 'flesh', 'flew', 'flick', 'flight', 'flighty', 'flimsy', 'flint', 'flip', 'flirt', 'flirtation', 'flirtatious', 'flit', 'float', 'flock', 'flood', 'floor', 'flop', 'flora', 'florence', 'florentino', 'florid', 'florida', 'flourish', 'flow', 'flower', 'flowery', 'fluent', 'fluff', 'fluffy', 'fluid', 'focal', 'focus', 'fodder', 'foggy', 'foible', 'foil', 'fold', 'folk', 'folklore', 'follett', 'follow', 'follower', 'folly', 'fond', 'fondly', 'fondness', 'font', 'food', 'fool', 'foolish', 'foolishly', 'foolishness', 'foot', 'football', 'footnote', 'footstep', 'foray', 'forbid', 'forbidden', 'force', 'forceful', 'forcefully', 'ford', 'fore', 'forebode', 'forefront', 'forehead', 'foreign', 'foreigner', 'foremost', 'forensic', 'foresee', 'foreshadow', 'foreshadows', 'foresight', 'forest', 'forever', 'foreward', 'forewarn', 'foreword', 'forge', 'forget', 'forgets', 'forgettable', 'forgive', 'forgiven', 'forgiveness', 'forgot', 'forgotten', 'fork', 'form', 'formal', 'formality', 'format', 'formation', 'former', 'formerly', 'formidable', 'formula', 'formulaic', 'formulate', 'forsaken', 'forster', 'forsyth', 'fort', 'forth', 'forthcoming', 'fortitude', 'fortress', 'fortunate', 'fortunately', 'fortune', 'forty', 'forum', 'forward', 'fossil', 'foster', 'fought', 'foul', 'found', 'foundation', 'founder', 'fountain', 'fountainhead', 'four', 'fourteen', 'fourth', 'fowl', 'fowler', 'fraction', 'fracture', 'fragile', 'fragility', 'fragment', 'frail', 'frailty', 'frame', 'framework', 'france', 'franchise', 'francie', 'francis', 'francisco', 'franco', 'frank', 'franken', 'frankenstein', 'frankl', 'franklin', 'frankly', 'franny', 'frantic', 'franzen', 'fraud', 'fraught', 'frazier', 'freak', 'fred', 'frederick', 'free', 'freebie', 'freed', 'freedom', 'freely', 'freeze', 'french', 'frenzy', 'frequent', 'frequently', 'fresh', 'freshman', 'freshness', 'freud', 'freudian', 'friar', 'friday', 'friedman', 'friend', 'friendly', 'friendship', 'frighten', 'frighteningly', 'fringe', 'frivolous', 'frodo', 'frog', 'frome', 'front', 'frontier', 'frost', 'frown', 'frozen', 'fruit', 'fruition', 'frustrate', 'frustration', 'fuel', 'fugitive', 'fulfil', 'fulfill', 'fulfillment', 'full', 'fuller', 'fully', 'function', 'functional', 'fund', 'fundamental', 'fundamentalism', 'fundamentalist', 'fundamentally', 'funeral', 'funnier', 'funniest', 'funny', 'furious', 'furniture', 'furthermore', 'fury', 'fuse', 'fuss', 'futile', 'futility', 'future', 'futuristic', 'fuzzy', 'gable', 'gabriel', 'gadget', 'gail', 'gaiman', 'gain', 'galactic', 'galaxy', 'galileo', 'galore', 'galt', 'gamble', 'game', 'gamekeeper', 'gamma', 'gamut', 'gandalf', 'gandolf', 'gang', 'gangster', 'garage', 'garbage', 'garcia', 'garden', 'gardener', 'gardner', 'gargery', 'garner', 'garp', 'garth', 'gary', 'gaskell', 'gasp', 'gate', 'gateshead', 'gather', 'gathering', 'gatsby', 'gaunt', 'gaze', 'gear', 'geek', 'geisha', 'gender', 'gene', 'general', 'generally', 'generate', 'generation', 'generational', 'generic', 'generosity', 'generous', 'genesis', 'genetic', 'genetically', 'genetics', 'genious', 'genius', 'genocide', 'genre', 'genteel', 'gentle', 'gentleman', 'gently', 'gentry', 'genuine', 'genuinely', 'geoffrey', 'geographic', 'geographical', 'geography', 'geology', 'george', 'georgia', 'gerald', 'germ', 'german', 'germany', 'gerritsen', 'gertrude', 'gesture', 'gettysburg', 'ghastly', 'ghost', 'ghostly', 'giant', 'gibson', 'gift', 'gigantic', 'giggle', 'gilbert', 'gild', 'gilead', 'gillian', 'gimli', 'gimmick', 'girl', 'girlfriend', 'girly', 'gist', 'give', 'giver', 'glad', 'gladly', 'gladwell', 'glamorous', 'glamour', 'glance', 'glare', 'glass', 'glean', 'glimmer', 'glimpse', 'glitter', 'global', 'globalization', 'globe', 'gloom', 'gloomy', 'gloria', 'glorify', 'glorious', 'gloriously', 'glory', 'gloss', 'glossary', 'glossy', 'glove', 'glow', 'glue', 'gnostic', 'goal', 'goat', 'goblin', 'goddess', 'godfather', 'godfrey', 'godly', 'going', 'gold', 'goldberg', 'golden', 'golding', 'goldman', 'goleman', 'golf', 'gollum', 'gondor', 'good', 'goodbye', 'goodkind', 'goodness', 'goodnight', 'goodwill', 'goody', 'goofy', 'google', 'goose', 'gordon', 'gore', 'gorgeous', 'gorilla', 'gory', 'gosh', 'gospel', 'gossip', 'gothic', 'gotten', 'govern', 'governess', 'government', 'governmental', 'governor', 'gown', 'grab', 'grabbed', 'grace', 'graceful', 'gracefully', 'grade', 'grader', 'gradgrind', 'gradual', 'gradually', 'graduate', 'graf', 'grafton', 'graham', 'grahame', 'grail', 'grain', 'grammar', 'grammatical', 'grand', 'grandchild', 'granddaughter', 'grander', 'grandeur', 'grandfather', 'grandiose', 'grandma', 'grandmother', 'grandparent', 'grandson', 'grange', 'granny', 'grant', 'grape', 'graphic', 'graphically', 'grapple', 'grasp', 'grasped', 'grass', 'grate', 'grateful', 'gratification', 'gratify', 'gratitude', 'gratuitous', 'grave', 'graveyard', 'gravity', 'gray', 'greaser', 'great', 'greatly', 'greatness', 'greece', 'greed', 'greedy', 'greek', 'green', 'greene', 'greet', 'greg', 'gregory', 'grey', 'grief', 'griet', 'grieve', 'griffin', 'grim', 'grin', 'grind', 'grip', 'gripe', 'gripped', 'grisham', 'grisly', 'grit', 'gritty', 'groan', 'grocery', 'grok', 'groom', 'gross', 'grotesque', 'ground', 'groundbreaking', 'groundwork', 'group', 'grow', 'grown', 'grownup', 'grows', 'growth', 'grrm', 'grudge', 'grueling', 'gruesome', 'grumpy', 'grunt', 'gryphon', 'guarantee', 'guaranteed', 'guard', 'guardian', 'guerilla', 'guess', 'guest', 'guidance', 'guide', 'guideline', 'guilt', 'guilty', 'guin', 'guise', 'gulag', 'gulf', 'gullible', 'gulliver', 'gunslinger', 'guru', 'gush', 'gutenberg', 'gwtw', 'gypsy', 'habit', 'hack', 'hackneyed', 'haddon', 'hadley', 'haggard', 'hail', 'hair', 'haired', 'hairy', 'hale', 'haley', 'half', 'halfway', 'hall', 'hallmark', 'halloween', 'hallucination', 'hallward', 'hallway', 'halt', 'hamilton', 'hamlet', 'hammer', 'hammett', 'hamper', 'hampton', 'hand', 'handful', 'handicapped', 'handle', 'handmaid', 'handsome', 'handy', 'hang', 'hanger', 'hank', 'hannah', 'hannay', 'hannibal', 'hannity', 'hapless', 'happen', 'happening', 'happens', 'happier', 'happily', 'happiness', 'happy', 'hara', 'harbor', 'hard', 'hardback', 'hardcore', 'hardcover', 'harden', 'harder', 'hardest', 'hardly', 'hardship', 'hardwigg', 'hardworking', 'hardy', 'hare', 'hareton', 'hari', 'harker', 'harlan', 'harlequin', 'harm', 'harmful', 'harmless', 'harmony', 'harness', 'harold', 'harper', 'harpoon', 'harpooner', 'harriet', 'harris', 'harrison', 'harrow', 'harry', 'harsh', 'harshaw', 'harshly', 'harshness', 'hart', 'harvard', 'harvest', 'hastily', 'hastings', 'hatch', 'hatchery', 'hate', 'hateful', 'hatred', 'hatter', 'haughty', 'haul', 'haunt', 'hauntingly', 'havent', 'havisham', 'havoc', 'hawk', 'hawkeye', 'hawkins', 'hawley', 'hawthorne', 'hayek', 'hazard', 'haze', 'hazel', 'hazlitt', 'head', 'headache', 'headless', 'headline', 'headstrong', 'heal', 'health', 'healthy', 'heap', 'heaped', 'hear', 'heard', 'hearing', 'hears', 'heart', 'heartache', 'heartbreak', 'heartbreaking', 'heartbroken', 'hearted', 'heartedly', 'heartfelt', 'heartily', 'heartless', 'heartwarming', 'heartwrenching', 'hearty', 'heat', 'heathcliff', 'heathcliffe', 'heaven', 'heavenly', 'heavier', 'heavily', 'heavy', 'hebrew', 'heck', 'hedgehog', 'hedonism', 'hedonistic', 'heed', 'heel', 'heep', 'hefty', 'height', 'heighten', 'heinlein', 'heinous', 'heir', 'heiress', 'held', 'helen', 'helicopter', 'hell', 'heller', 'hellish', 'hello', 'helm', 'help', 'helpful', 'helpless', 'helplessness', 'helsing', 'hemingway', 'hemmingway', 'hence', 'henchard', 'henry', 'hepzibah', 'herald', 'herbert', 'hercule', 'herd', 'herein', 'heresy', 'heretic', 'heritage', 'herman', 'hermaphrodite', 'hermione', 'hero', 'heroic', 'heroine', 'heroism', 'herring', 'hersey', 'hesitant', 'hesitate', 'hesitation', 'hester', 'heyerdahl', 'hiaasen', 'hickock', 'hidden', 'hide', 'hideous', 'hiding', 'hierarchy', 'high', 'highbury', 'highlight', 'highly', 'highschool', 'highway', 'hike', 'hilarious', 'hilariously', 'hilarity', 'hill', 'hilton', 'hinder', 'hindley', 'hindsight', 'hindu', 'hinge', 'hint', 'hippie', 'hippy', 'hire', 'hiroshima', 'historian', 'historic', 'historical', 'historically', 'history', 'hitchhiker', 'hitler', 'hmmm', 'hoard', 'hobb', 'hobbit', 'hobbiton', 'hobbitt', 'hobby', 'hobo', 'hoenikker', 'hoffer', 'hoffman', 'hogwarts', 'hokey', 'hold', 'holden', 'holder', 'hole', 'holiday', 'holland', 'hollow', 'holly', 'hollywood', 'holmes', 'holocaust', 'holy', 'homage', 'home', 'homeland', 'homeless', 'homely', 'homer', 'hometown', 'homework', 'homicide', 'homoerotic', 'homosexual', 'homosexuality', 'hone', 'honest', 'honestly', 'honesty', 'honey', 'honeymoon', 'honor', 'honorable', 'honour', 'hood', 'hook', 'hookah', 'hooked', 'hoot', 'hope', 'hopeful', 'hopefully', 'hopeless', 'hopelessly', 'hopelessness', 'horde', 'horizon', 'horn', 'hornby', 'horrendous', 'horrible', 'horribly', 'horrid', 'horrific', 'horrify', 'horror', 'horse', 'horseman', 'hospital', 'host', 'hostage', 'hostile', 'hostility', 'hotel', 'hound', 'hour', 'house', 'household', 'housekeeper', 'housewife', 'housing', 'hover', 'howard', 'however', 'howl', 'hubris', 'huck', 'huckleberry', 'huge', 'hugely', 'hugh', 'hugo', 'human', 'humane', 'humanistic', 'humanity', 'humanize', 'humankind', 'humbert', 'humble', 'humbug', 'humiliate', 'humiliation', 'humility', 'humor', 'humorous', 'humorously', 'humour', 'hump', 'humphrey', 'humpty', 'hundred', 'hung', 'hunger', 'hungry', 'hunt', 'hunter', 'hurdle', 'hurl', 'huron', 'hurricane', 'hurry', 'hurston', 'hurstwood', 'hurt', 'husband', 'hush', 'huxley', 'hybrid', 'hyde', 'hype', 'hyped', 'hyper', 'hyperbole', 'hyperion', 'hypnotic', 'hypochondriac', 'hypocrisy', 'hypocrite', 'hypocritical', 'hypothesis', 'hypothetical', 'hysteria', 'hysterical', 'hysterically', 'iceberg', 'iceland', 'ichabod', 'icon', 'iconic', 'idea', 'ideal', 'idealism', 'idealist', 'idealistic', 'idealize', 'identical', 'identification', 'identifies', 'identify', 'identity', 'ideological', 'ideology', 'idiom', 'idiosyncrasy', 'idiosyncratic', 'idiot', 'idiotic', 'idle', 'idol', 'idolize', 'idyllic', 'iexcl', 'ignatius', 'ignite', 'ignorance', 'ignorant', 'ignore', 'ignores', 'iles', 'iliad', 'illegal', 'illegitimate', 'illicit', 'illiterate', 'illness', 'illogical', 'illuminate', 'illuminates', 'illuminati', 'illusion', 'illustrate', 'illustrates', 'illustration', 'illustrator', 'illustrious', 'image', 'imagery', 'imaginable', 'imaginary', 'imagination', 'imaginative', 'imagine', 'imago', 'imbue', 'imho', 'imitate', 'imitation', 'imitator', 'immature', 'immediacy', 'immediate', 'immediately', 'immense', 'immensely', 'immerse', 'immersion', 'immigrant', 'immigration', 'imminent', 'immoral', 'immorality', 'immortal', 'immortality', 'immune', 'impact', 'impart', 'impassioned', 'impatient', 'impeccable', 'impend', 'impenetrable', 'imperative', 'imperfect', 'imperfection', 'imperial', 'imperialism', 'imperialist', 'impersonal', 'implant', 'implausible', 'implement', 'implication', 'implicit', 'implies', 'imply', 'import', 'importance', 'important', 'importantly', 'impose', 'impossibility', 'impossible', 'impossibly', 'impotent', 'impoverish', 'impress', 'impressed', 'impression', 'impressionable', 'impressive', 'impressively', 'imprint', 'imprison', 'imprisonment', 'improbable', 'improve', 'improvement', 'improves', 'impulse', 'impulsive', 'inability', 'inaccuracy', 'inaccurate', 'inadequate', 'inadvertently', 'inane', 'inappropriate', 'incapable', 'incarnate', 'incarnation', 'incentive', 'incessant', 'incest', 'inch', 'incident', 'incidental', 'incidentally', 'incisive', 'inclination', 'inclined', 'include', 'inclusion', 'incoherent', 'income', 'incomparable', 'incompetent', 'incomplete', 'incomprehensible', 'inconsequential', 'inconsistency', 'inconsistent', 'incorporate', 'incorporates', 'incorrect', 'increase', 'increasingly', 'incredible', 'incredibly', 'indeed', 'indelible', 'independence', 'independent', 'independently', 'index', 'india', 'indian', 'indiana', 'indicate', 'indicates', 'indication', 'indicative', 'indictment', 'indifference', 'indifferent', 'indirect', 'indirectly', 'indiscretion', 'indispensable', 'individual', 'individualism', 'individuality', 'individually', 'indomitable', 'induce', 'induced', 'indulge', 'indulgence', 'indulgent', 'indulges', 'industrial', 'industrialist', 'industrialize', 'industry', 'ineffective', 'inept', 'inequality', 'inescapable', 'inevitability', 'inevitable', 'inevitably', 'inexorable', 'inexpensive', 'inexperienced', 'inexplicable', 'inexplicably', 'infamous', 'infancy', 'infant', 'infatuate', 'infatuation', 'infect', 'infectious', 'infer', 'inferior', 'inferiority', 'inferno', 'infidelity', 'infinite', 'infinitely', 'inflict', 'influence', 'influential', 'info', 'inform', 'information', 'informative', 'informs', 'infuriate', 'infuse', 'ingenious', 'ingeniously', 'ingenuity', 'inglis', 'ingrain', 'ingredient', 'inhabit', 'inhabitant', 'inhabits', 'inherent', 'inherently', 'inherit', 'inheritance', 'inhuman', 'inhumane', 'inhumanity', 'inimitable', 'initial', 'initially', 'initiate', 'initiative', 'inject', 'injured', 'injury', 'injustice', 'inkling', 'inman', 'inmate', 'innate', 'inner', 'innocence', 'innocent', 'innovation', 'innovative', 'innuendo', 'innumerable', 'inquiry', 'inquisitive', 'insane', 'insanely', 'insanity', 'inscrutable', 'insect', 'insecure', 'insecurity', 'insensitive', 'inseparable', 'insert', 'inside', 'insider', 'insidious', 'insight', 'insightful', 'insignificant', 'insipid', 'insist', 'insistence', 'insists', 'insomnia', 'inspector', 'inspiration', 'inspirational', 'inspire', 'inspires', 'instability', 'installment', 'instance', 'instant', 'instantly', 'instead', 'instill', 'instinct', 'institute', 'institution', 'instruct', 'instruction', 'instructive', 'instructor', 'instrument', 'instrumental', 'insufferable', 'insufficient', 'insult', 'insurance', 'insurmountable', 'intact', 'integral', 'integrate', 'integrity', 'intellect', 'intellectual', 'intellectually', 'intelligence', 'intelligent', 'intelligently', 'intend', 'intense', 'intensely', 'intensity', 'intent', 'intention', 'intentional', 'intentionally', 'intentioned', 'inter', 'interact', 'interaction', 'interconnect', 'interest', 'interested', 'interestingly', 'interfere', 'interference', 'interior', 'interlude', 'interminable', 'intermingle', 'internal', 'international', 'internet', 'interpersonal', 'interplay', 'interpret', 'interpretation', 'interrupt', 'intersect', 'intersperse', 'intersting', 'intertwine', 'interval', 'intervene', 'intervention', 'interview', 'interviewed', 'interweave', 'interwoven', 'intimacy', 'intimate', 'intimately', 'intimidate', 'intolerable', 'intolerance', 'intoxicate', 'intrepid', 'intricacy', 'intricate', 'intricately', 'intrigue', 'intrinsic', 'intro', 'introduce', 'introduces', 'introduction', 'introductory', 'introspection', 'introspective', 'intrusion', 'intuition', 'intuitive', 'invade', 'invader', 'invalid', 'invaluable', 'invariably', 'invasion', 'invent', 'invention', 'inventive', 'inventor', 'invents', 'invest', 'investigate', 'investigates', 'investigation', 'investigative', 'investigator', 'investment', 'investor', 'invigorate', 'invisibility', 'invisible', 'invitation', 'invite', 'invoke', 'invokes', 'involve', 'involvement', 'involves', 'inward', 'ipad', 'iphone', 'ipod', 'iran', 'iranian', 'iraq', 'ireland', 'iris', 'irish', 'iron', 'ironic', 'ironically', 'irony', 'irrational', 'irrelevant', 'irresistible', 'irresponsible', 'irreverent', 'irritate', 'irritated', 'irving', 'isaac', 'isaacson', 'isabel', 'isabella', 'ishmael', 'islam', 'islamic', 'island', 'isle', 'isnt', 'isolated', 'isolation', 'israel', 'israeli', 'issue', 'italian', 'italic', 'italy', 'item', 'ivan', 'ivory', 'jabberwocky', 'jack', 'jackal', 'jacket', 'jackson', 'jacob', 'jacques', 'jade', 'jagger', 'jail', 'jake', 'james', 'jamie', 'jane', 'janet', 'janie', 'january', 'japan', 'japanese', 'jargon', 'jarndyce', 'jarring', 'jarvis', 'jason', 'jasper', 'jazz', 'jealous', 'jealousy', 'jean', 'jeff', 'jefferson', 'jeffrey', 'jekyll', 'jemima', 'jenkins', 'jennifer', 'jennings', 'jeremy', 'jerk', 'jerry', 'jersey', 'jesse', 'jessica', 'jessie', 'jesus', 'jewel', 'jewish', 'jill', 'jilt', 'jimmy', 'joad', 'joads', 'joan', 'jodi', 'joey', 'john', 'johnny', 'johnson', 'join', 'joint', 'joke', 'jolly', 'jonah', 'jonas', 'jonathan', 'jondalar', 'jones', 'jordan', 'joseph', 'josephine', 'joshua', 'journal', 'journalism', 'journalist', 'journalistic', 'journey', 'joyce', 'joyful', 'joyous', 'jubal', 'judaism', 'jude', 'judge', 'judged', 'judgement', 'judging', 'judgment', 'judgmental', 'juice', 'juicy', 'jules', 'julia', 'julian', 'julie', 'juliet', 'july', 'jump', 'jumped', 'jumping', 'june', 'jungle', 'junior', 'junk', 'jurassic', 'juror', 'jury', 'justice', 'justifiably', 'justification', 'justified', 'justifies', 'justify', 'justly', 'juvenile', 'juxtapose', 'juxtaposition', 'kafka', 'kahlan', 'kampf', 'kane', 'kansa', 'kant', 'karamazov', 'karen', 'karenina', 'karl', 'karloff', 'kate', 'katherine', 'kathryn', 'kathy', 'katie', 'katrina', 'katz', 'kavalier', 'keating', 'keen', 'keenly', 'keep', 'keeper', 'keepsake', 'kelly', 'kellynch', 'kennedy', 'kenneth', 'kent', 'kentucky', 'kept', 'kerouac', 'kesey', 'kevin', 'keyes', 'khan', 'kick', 'kidd', 'kidnap', 'kidnapping', 'kill', 'killer', 'killing', 'kind', 'kinda', 'kindle', 'kindly', 'kindness', 'king', 'kingdom', 'kingsolver', 'kino', 'kinsella', 'kinsey', 'kipling', 'kira', 'kiss', 'kitchen', 'kite', 'kitten', 'kitty', 'knack', 'knee', 'knew', 'knife', 'knight', 'knightley', 'knightly', 'knit', 'knock', 'knot', 'know', 'knowledge', 'knowledgeable', 'knowles', 'koontz', 'korea', 'korean', 'krakauer', 'kubrick', 'kudos', 'kumalo', 'kurt', 'kurtz', 'label', 'labor', 'laboratory', 'laborer', 'laborious', 'labour', 'labyrinth', 'lace', 'lack', 'lackluster', 'ladder', 'laden', 'ladislaw', 'lady', 'lahiri', 'laid', 'lair', 'laissez', 'lake', 'lama', 'lamb', 'lame', 'lament', 'lampoon', 'lance', 'lancelot', 'land', 'landlord', 'landmark', 'landowner', 'landscape', 'lane', 'langdon', 'language', 'languid', 'lannister', 'lantern', 'lapd', 'lapse', 'large', 'largely', 'larry', 'larsen', 'larson', 'lash', 'last', 'lastly', 'late', 'lately', 'later', 'latin', 'latour', 'latter', 'laud', 'laugh', 'laughable', 'laughter', 'launch', 'laundry', 'laura', 'laurence', 'laurie', 'lavish', 'lawrence', 'lawsuit', 'lawyer', 'layer', 'layman', 'layout', 'laziness', 'lazy', 'lead', 'leader', 'leadership', 'leaf', 'league', 'leah', 'leamas', 'lean', 'leap', 'lear', 'learn', 'learns', 'learnt', 'lease', 'least', 'leather', 'leatherette', 'leave', 'lecarre', 'lecter', 'lecture', 'left', 'leftist', 'legacy', 'legal', 'legally', 'legend', 'legendary', 'legged', 'legion', 'legitimate', 'legolas', 'legree', 'leguin', 'lehane', 'leibowitz', 'leigh', 'leisure', 'leisurely', 'lend', 'lending', 'lends', 'length', 'lengthy', 'lenin', 'lenina', 'lennie', 'lenny', 'lens', 'lent', 'leonard', 'leopold', 'leper', 'leroux', 'lesbian', 'less', 'lessen', 'lesser', 'lesson', 'lestat', 'letdown', 'lethal', 'leto', 'letter', 'level', 'levin', 'levitt', 'lewis', 'lexicon', 'liar', 'liberal', 'liberalism', 'liberally', 'liberate', 'liberation', 'libertarian', 'liberty', 'librarian', 'library', 'license', 'liddell', 'lieutenant', 'life', 'lifeless', 'lifelike', 'lifelong', 'lifestyle', 'lifetime', 'lift', 'light', 'lighten', 'lighter', 'lighthearted', 'lighthouse', 'lightly', 'lightning', 'lightweight', 'likable', 'like', 'likeable', 'likely', 'liken', 'likewise', 'lilliput', 'lily', 'limb', 'limit', 'limitation', 'limited', 'limitless', 'lincoln', 'linda', 'lindbergh', 'lindsay', 'line', 'lineage', 'linear', 'liner', 'linger', 'lingers', 'lingo', 'linguistic', 'link', 'linton', 'lintons', 'lion', 'liquor', 'lisa', 'list', 'listen', 'listener', 'listens', 'listing', 'literacy', 'literal', 'literally', 'literary', 'literate', 'literature', 'litter', 'little', 'live', 'lively', 'living', 'livingston', 'lizard', 'lizzie', 'lizzy', 'lloyd', 'load', 'loan', 'loathe', 'loathsome', 'lobster', 'local', 'locale', 'locate', 'location', 'lock', 'lockwood', 'lodge', 'loewen', 'lofty', 'logic', 'logical', 'logically', 'logotherapy', 'lolita', 'london', 'lone', 'loneliness', 'lonely', 'loner', 'lonesome', 'long', 'longbourn', 'longer', 'longing', 'longitude', 'longs', 'look', 'loom', 'loop', 'loose', 'loosely', 'loot', 'lord', 'lore', 'lorry', 'lose', 'loser', 'loses', 'loss', 'lotr', 'loud', 'loudly', 'louis', 'louisa', 'louise', 'louisiana', 'lousy', 'lovable', 'love', 'loveable', 'loveless', 'lovely', 'lover', 'lovingly', 'lower', 'lowly', 'lowood', 'lowry', 'loyal', 'loyalty', 'lucas', 'lucid', 'lucie', 'lucifer', 'luck', 'luckily', 'lucky', 'lucy', 'ludicrous', 'ludlum', 'luis', 'luke', 'lula', 'lull', 'luminous', 'lump', 'lunacy', 'lunatic', 'lunch', 'lung', 'lure', 'lurie', 'lurk', 'lurks', 'lush', 'lust', 'luther', 'luxurious', 'luxury', 'lydgate', 'lydia', 'lyme', 'lynch', 'lyra', 'lyric', 'lyrical', 'lyricism', 'macabre', 'macbeth', 'macdonald', 'machina', 'machination', 'machine', 'machinery', 'macho', 'madame', 'madden', 'madison', 'madly', 'madman', 'madness', 'mafia', 'magazine', 'magic', 'magical', 'magically', 'magician', 'magnetic', 'magnificent', 'magnificently', 'magnify', 'magnitude', 'magnum', 'magua', 'maguire', 'magwitch', 'maid', 'maiden', 'mail', 'main', 'maine', 'mainly', 'mainstream', 'maintain', 'maintains', 'maintenance', 'majestic', 'majesty', 'major', 'majority', 'make', 'maker', 'malady', 'malcolm', 'male', 'malevolent', 'malice', 'malicious', 'malign', 'mallory', 'maltese', 'mama', 'mammoth', 'manage', 'management', 'manager', 'manages', 'mandatory', 'manette', 'maneuver', 'manhattan', 'manhood', 'maniac', 'maniacal', 'manic', 'manifest', 'manifestation', 'manifesto', 'manipulate', 'manipulates', 'manipulation', 'manipulative', 'mankind', 'manly', 'mann', 'manna', 'manner', 'mannered', 'mannerism', 'manor', 'mansfield', 'mansion', 'manson', 'manual', 'manufacture', 'manufacturing', 'manuscript', 'many', 'marble', 'march', 'marcus', 'margaret', 'margin', 'marginal', 'maria', 'marian', 'marianne', 'marie', 'marine', 'mario', 'marital', 'marius', 'mark', 'marked', 'marker', 'market', 'marketing', 'marley', 'marlin', 'marlow', 'marlowe', 'marmee', 'marner', 'maroon', 'marple', 'marquez', 'marriage', 'married', 'marries', 'marry', 'marsh', 'marshall', 'mart', 'martha', 'martian', 'martin', 'martyr', 'marvel', 'marvellous', 'marvelous', 'marvelously', 'marx', 'marxism', 'marxist', 'mary', 'masculine', 'mash', 'mask', 'mason', 'mass', 'massachusetts', 'massacre', 'massive', 'mast', 'master', 'masterful', 'masterfully', 'masterly', 'mastermind', 'masterpiece', 'masterwork', 'mastery', 'match', 'matchmaker', 'matchmaking', 'mate', 'material', 'materialism', 'materialist', 'materialistic', 'materialize', 'maternal', 'math', 'mathematical', 'mathematician', 'mathematics', 'matheson', 'matrix', 'matt', 'matter', 'matthew', 'mattie', 'maturation', 'mature', 'matures', 'maturity', 'maud', 'maudlin', 'maugham', 'maule', 'maurice', 'maxim', 'maximize', 'maximum', 'maya', 'maybe', 'maycomb', 'mayfair', 'mayhem', 'mayor', 'maze', 'mazur', 'mccaleb', 'mccandless', 'mccarthy', 'mccourt', 'mccullers', 'mccullough', 'mcewan', 'mcmurphy', 'meadow', 'meager', 'meal', 'mean', 'meander', 'meaning', 'meaningful', 'meaningless', 'meant', 'meantime', 'meanwhile', 'meany', 'measure', 'meat', 'mechanic', 'mechanical', 'mechanism', 'medal', 'meddling', 'medical', 'medicine', 'medieval', 'mediocre', 'mediocrity', 'meditation', 'mediterranean', 'medium', 'meek', 'meet', 'meeting', 'mega', 'mein', 'melancholy', 'melanie', 'meld', 'mellors', 'mellow', 'melodrama', 'melodramatic', 'melt', 'melville', 'member', 'memnoch', 'memoir', 'memorable', 'memorably', 'memorize', 'memory', 'menace', 'mend', 'menial', 'mental', 'mentality', 'mentally', 'mention', 'mentor', 'mercedes', 'mercenary', 'merchant', 'merciless', 'mercilessly', 'mercy', 'mere', 'merely', 'merge', 'merit', 'merlin', 'merrick', 'merry', 'mersault', 'mesh', 'mesmerize', 'mess', 'message', 'messenger', 'messiah', 'messy', 'metal', 'metamorphosis', 'metaphor', 'metaphorical', 'metaphysical', 'metaphysics', 'meter', 'method', 'methodical', 'methodically', 'meticulous', 'meticulously', 'meursault', 'mexican', 'mexico', 'meyer', 'micawber', 'michael', 'michener', 'michigan', 'mick', 'mickey', 'microcosm', 'middle', 'middlemarch', 'middlesex', 'midnight', 'midst', 'midway', 'midwest', 'might', 'mighty', 'migrant', 'mike', 'mild', 'mildly', 'mildred', 'mile', 'milestone', 'milieu', 'military', 'militia', 'milk', 'mill', 'millennium', 'miller', 'millhone', 'million', 'millionaire', 'milo', 'milton', 'mimic', 'mina', 'mind', 'mindedness', 'mindless', 'mindset', 'mine', 'mingle', 'mini', 'minimal', 'minimum', 'mining', 'minion', 'miniseries', 'minister', 'ministry', 'minnesota', 'minor', 'minority', 'mint', 'minus', 'minute', 'minutia', 'miracle', 'miraculous', 'miraculously', 'miranda', 'miraz', 'mire', 'mirkwood', 'mirror', 'mirth', 'misadventure', 'mischief', 'mischievous', 'misconception', 'misdeed', 'miser', 'miserable', 'miserables', 'miserably', 'miserly', 'misery', 'misfit', 'misfortune', 'misgiving', 'misguide', 'mishap', 'mislead', 'misplace', 'miss', 'missile', 'mission', 'missionary', 'mississippi', 'missouri', 'mist', 'mistake', 'mistaken', 'mistakenly', 'mistreat', 'mistreatment', 'mistress', 'mistrust', 'mistry', 'misty', 'misunderstand', 'misunderstanding', 'misunderstood', 'misuse', 'mitch', 'mitchell', 'mixed', 'mixture', 'moan', 'mobile', 'moby', 'mock', 'mockery', 'mockingbird', 'mode', 'model', 'moderate', 'moderately', 'moderation', 'modern', 'modernism', 'modernist', 'modernity', 'modernize', 'modest', 'modesty', 'modify', 'mohican', 'mold', 'mole', 'molly', 'moment', 'momentum', 'mona', 'monarchy', 'monastery', 'mond', 'monetary', 'money', 'monitor', 'monk', 'monkey', 'monologue', 'monopoly', 'monotonous', 'monotony', 'monster', 'monstrous', 'montag', 'montana', 'monte', 'montgomery', 'month', 'monthly', 'monty', 'monument', 'monumental', 'mood', 'moody', 'moon', 'moonstone', 'moor', 'moore', 'moral', 'morale', 'moralistic', 'morality', 'moralize', 'morally', 'morbid', 'mordor', 'more', 'moreau', 'morel', 'morelli', 'moreover', 'moreso', 'morgan', 'moriarty', 'morland', 'morlocks', 'mormon', 'mormonism', 'morning', 'moron', 'morose', 'morpork', 'morrie', 'morris', 'morrison', 'mort', 'mortal', 'mortality', 'moses', 'mostly', 'mother', 'motherhood', 'motif', 'motion', 'motivate', 'motivates', 'motivation', 'motivational', 'motive', 'motley', 'motor', 'motorcycle', 'motto', 'mount', 'mountain', 'mourn', 'mouse', 'mouth', 'mouthpiece', 'move', 'moveable', 'movement', 'mover', 'movie', 'mowgli', 'much', 'muddle', 'muddy', 'mule', 'muller', 'multi', 'multifaceted', 'multiple', 'multiply', 'multitude', 'mundane', 'munro', 'murakami', 'murder', 'murderer', 'murderous', 'murray', 'muscle', 'muse', 'museum', 'musgrove', 'mushroom', 'music', 'musical', 'musician', 'musing', 'musketeer', 'muslim', 'must', 'mustapha', 'muster', 'mutant', 'mute', 'mutilate', 'mutiny', 'mutual', 'mutually', 'myriad', 'myron', 'myrtle', 'mysterious', 'mysteriously', 'mystery', 'mystic', 'mystical', 'mysticism', 'mystify', 'myth', 'mythic', 'mythical', 'mythological', 'mythology', 'mythos', 'nabokov', 'nafisi', 'nagaina', 'nail', 'naive', 'naivete', 'naked', 'name', 'nameless', 'namely', 'nancy', 'nanny', 'nantucket', 'napoleon', 'napoleonic', 'narcissism', 'narcissistic', 'narnia', 'narnian', 'narnians', 'narrate', 'narrates', 'narration', 'narrative', 'narrator', 'narrow', 'narrowly', 'nasa', 'nash', 'nasty', 'nate', 'nately', 'nathan', 'nathaniel', 'nation', 'national', 'nationalism', 'nationality', 'native', 'natural', 'naturalist', 'naturalistic', 'naturally', 'nature', 'natured', 'naughty', 'nauseate', 'nautical', 'nautilus', 'naval', 'nave', 'navigate', 'navigation', 'navy', 'nazi', 'nazism', 'nazneen', 'neal', 'neanderthal', 'near', 'nearby', 'nearly', 'neat', 'neatly', 'nebraska', 'necessarily', 'necessary', 'necessity', 'neck', 'need', 'needful', 'needle', 'needlessly', 'nefarious', 'negative', 'negatively', 'neglect', 'negotiate', 'negotiation', 'negro', 'neighbor', 'neighborhood', 'neighbour', 'neil', 'neither', 'nell', 'nelly', 'nelson', 'nemesis', 'nemo', 'nephew', 'nerd', 'nerve', 'nervous', 'ness', 'nest', 'netherfield', 'network', 'neurotic', 'neutral', 'never', 'nevertheless', 'neville', 'newborn', 'newcomer', 'newer', 'newfound', 'newland', 'newly', 'newman', 'news', 'newspaper', 'newspeak', 'newton', 'next', 'nice', 'nicely', 'nicer', 'niche', 'nicholas', 'nick', 'nickname', 'nicole', 'niece', 'nietzsche', 'night', 'nightmare', 'nightmarish', 'nihilism', 'nihilistic', 'nile', 'nine', 'nineteen', 'nineteenth', 'ninety', 'ninth', 'noah', 'nobel', 'nobility', 'noble', 'nobleman', 'nobody', 'noir', 'noise', 'nolan', 'none', 'nonetheless', 'nonfiction', 'nonsense', 'nonsensical', 'nonstop', 'noon', 'nope', 'nora', 'norm', 'normal', 'normally', 'norman', 'norrell', 'norris', 'norse', 'north', 'northanger', 'northern', 'northerner', 'norton', 'nose', 'nostalgia', 'nostalgic', 'notable', 'notably', 'notation', 'notch', 'note', 'notebook', 'noteworthy', 'nothing', 'nothingness', 'notice', 'noticeable', 'notion', 'notorious', 'notwithstanding', 'novel', 'novelette', 'novelist', 'novelistic', 'novella', 'novelty', 'november', 'novice', 'nowadays', 'nowhere', 'nuance', 'nuanced', 'nuclear', 'nugget', 'numb', 'number', 'numerous', 'nurse', 'nursery', 'nursing', 'nurture', 'nutshell', 'nynaeve', 'oacute', 'oakenshield', 'oath', 'obama', 'obedience', 'obedient', 'obey', 'object', 'objection', 'objective', 'objectively', 'objectivism', 'objectivist', 'objectivity', 'obligate', 'obligation', 'obligatory', 'oblige', 'oblivion', 'oblivious', 'obnoxious', 'obscene', 'obscenity', 'obscure', 'obscurity', 'observant', 'observation', 'observe', 'observer', 'observes', 'obsess', 'obsession', 'obsessive', 'obsolete', 'obstacle', 'obtain', 'obtuse', 'obvious', 'obviously', 'occasion', 'occasional', 'occasionally', 'occupation', 'occupy', 'occur', 'occurrence', 'occurs', 'ocean', 'oceania', 'october', 'oddity', 'oddly', 'odds', 'odious', 'odysseus', 'odyssey', 'offend', 'offense', 'offensive', 'offer', 'offering', 'office', 'officer', 'official', 'officially', 'offred', 'offspring', 'often', 'oftentimes', 'ofthe', 'ograve', 'ogre', 'ohio', 'okay', 'oklahoma', 'okonkwo', 'olaf', 'olde', 'oldie', 'oliver', 'olivier', 'omen', 'ominous', 'omission', 'omit', 'omnipotent', 'omnipresent', 'omniscient', 'oneself', 'ongoing', 'onion', 'online', 'onset', 'onto', 'onward', 'open', 'opener', 'opening', 'openly', 'opera', 'operate', 'operates', 'operating', 'operation', 'operative', 'ophelia', 'opinion', 'opinionated', 'opium', 'opponent', 'opportunity', 'oppose', 'opposite', 'opposition', 'oppress', 'oppression', 'oppressive', 'oppressor', 'oprah', 'optimism', 'optimistic', 'option', 'opus', 'oral', 'orange', 'orcs', 'ordeal', 'order', 'orderly', 'ordinary', 'organ', 'organic', 'organism', 'organization', 'organize', 'orient', 'orientation', 'origin', 'original', 'originality', 'originally', 'originate', 'orleans', 'ornate', 'orphan', 'orphanage', 'orson', 'orthodox', 'orthodoxy', 'orual', 'orwell', 'orwellian', 'oscar', 'ostensibly', 'ostracize', 'others', 'otherwise', 'ought', 'ounce', 'outbreak', 'outcast', 'outcome', 'outdated', 'outer', 'outfit', 'outlander', 'outlandish', 'outlaw', 'outlet', 'outline', 'outlook', 'outrage', 'outrageous', 'outright', 'outset', 'outside', 'outsider', 'outspoken', 'outstanding', 'outward', 'outwardly', 'outweigh', 'outwit', 'overall', 'overarch', 'overbear', 'overblown', 'overboard', 'overcame', 'overcome', 'overcomes', 'overdone', 'overflow', 'overhears', 'overlap', 'overload', 'overlong', 'overlook', 'overly', 'overnight', 'overpower', 'overrate', 'override', 'overseas', 'overshadow', 'overt', 'overthrow', 'overtly', 'overtone', 'overturn', 'overuse', 'overview', 'overweight', 'overwhelm', 'overwhelmed', 'overwhelmingly', 'overwritten', 'overwrought', 'owen', 'owes', 'owner', 'ownership', 'oxford', 'oxygen', 'pablo', 'pace', 'pacific', 'pack', 'package', 'packaging', 'packed', 'pact', 'pagan', 'page', 'pagels', 'paid', 'pain', 'paine', 'painful', 'painfully', 'painstaking', 'painstakingly', 'paint', 'painter', 'painting', 'pair', 'palace', 'palahniuk', 'palatable', 'pale', 'palestinian', 'palm', 'palpable', 'pamper', 'pamphlet', 'pamplona', 'panel', 'pang', 'panic', 'pant', 'pantheon', 'panther', 'paolini', 'papa', 'paper', 'paperback', 'parable', 'parade', 'paradigm', 'paradise', 'paradox', 'paradoxical', 'paragon', 'paragraph', 'parallel', 'paralyze', 'paramount', 'paranoia', 'paranoid', 'paranormal', 'paraphrase', 'pardon', 'parent', 'parental', 'paris', 'park', 'parker', 'parlor', 'parody', 'parrot', 'parson', 'part', 'partake', 'partial', 'partially', 'participant', 'participate', 'participation', 'particle', 'particular', 'particularly', 'partisan', 'partly', 'partner', 'party', 'pass', 'passage', 'passenger', 'passing', 'passion', 'passionate', 'passionately', 'passive', 'past', 'paste', 'pastor', 'pastoral', 'patch', 'path', 'pathetic', 'pathos', 'patience', 'patient', 'patiently', 'paton', 'patriarch', 'patriarchal', 'patricia', 'patrick', 'patriot', 'patriotic', 'patriotism', 'patron', 'pattern', 'patterson', 'paul', 'pauline', 'pauper', 'pause', 'pave', 'pawn', 'payoff', 'peace', 'peaceful', 'peach', 'peak', 'pearl', 'peasant', 'peck', 'peculiar', 'pedantic', 'pedestrian', 'pedro', 'peek', 'peel', 'peer', 'penalty', 'penchant', 'pencil', 'pendergast', 'pendulum', 'penelope', 'penetrate', 'penguin', 'penn', 'penniless', 'pennsylvania', 'penny', 'people', 'pepper', 'pequod', 'perceive', 'perceives', 'percent', 'percentage', 'perception', 'perceptive', 'percy', 'perelandra', 'perennial', 'perfect', 'perfection', 'perfectly', 'perform', 'performance', 'performer', 'performs', 'perfume', 'perhaps', 'peril', 'perilous', 'period', 'periodically', 'peripheral', 'perish', 'permanent', 'permanently', 'permeate', 'permeates', 'permit', 'perpetrate', 'perpetrator', 'perpetual', 'perpetually', 'perpetuate', 'perplex', 'perrin', 'perry', 'persecute', 'persecution', 'perseverance', 'persevere', 'persist', 'persistence', 'persistent', 'person', 'persona', 'personage', 'personal', 'personality', 'personally', 'personification', 'personify', 'perspective', 'persuade', 'persuasion', 'persuasive', 'pertain', 'pertinent', 'peru', 'peruse', 'pervade', 'pervades', 'pervasive', 'perverse', 'perversion', 'pervert', 'pessimism', 'pessimistic', 'pete', 'peter', 'petersburg', 'petty', 'pevensie', 'phaedrus', 'phantom', 'phase', 'phenomenal', 'phenomenon', 'philadelphia', 'philbrick', 'philip', 'phillip', 'philosopher', 'philosophic', 'philosophical', 'philosophically', 'philosophize', 'philosophy', 'phineas', 'phoebe', 'phoenix', 'phone', 'phony', 'photo', 'photograph', 'phrase', 'phrasing', 'phuong', 'physic', 'physical', 'physically', 'physician', 'physicist', 'piano', 'pick', 'picked', 'pickwick', 'picky', 'picnic', 'picoult', 'picture', 'picturesque', 'piece', 'pierce', 'pierre', 'piety', 'piggy', 'pike', 'pilar', 'pile', 'pilgrim', 'pilgrimage', 'pill', 'pillar', 'pilot', 'pinch', 'pine', 'pink', 'pinnacle', 'pioneer', 'pious', 'pipe', 'pippin', 'pique', 'pirate', 'pirsig', 'piss', 'pitch', 'pitfall', 'pithy', 'pitiful', 'pitt', 'pity', 'pivotal', 'place', 'plague', 'plain', 'plainly', 'plan', 'plane', 'planet', 'planning', 'plant', 'plantation', 'plastic', 'plate', 'platform', 'plath', 'plato', 'platonic', 'plausibility', 'plausible', 'play', 'played', 'player', 'playful', 'playwright', 'plea', 'plead', 'pleasant', 'pleasantly', 'please', 'pleased', 'pleasurable', 'pleasure', 'pledge', 'plenty', 'plethora', 'plight', 'plod', 'plot', 'plotline', 'plotlines', 'plow', 'plug', 'plum', 'plunge', 'plus', 'pocket', 'poem', 'poet', 'poetic', 'poetically', 'poetry', 'poignancy', 'poignant', 'poignantly', 'point', 'pointless', 'poirot', 'poison', 'poisonous', 'poke', 'poland', 'polar', 'pole', 'polemic', 'police', 'policeman', 'policy', 'polish', 'polished', 'polite', 'political', 'politically', 'politician', 'politics', 'poll', 'polly', 'pompeii', 'pompous', 'pond', 'ponder', 'ponderous', 'ponders', 'pontellier', 'pony', 'ponyboy', 'pool', 'poor', 'poorer', 'poorly', 'pope', 'popped', 'populace', 'popular', 'popularity', 'populate', 'population', 'porch', 'porn', 'pornography', 'port', 'portable', 'portal', 'portion', 'portrait', 'portray', 'portrayal', 'portrayed', 'portrays', 'pose', 'posit', 'position', 'positive', 'positively', 'posse', 'possess', 'possession', 'possibility', 'possible', 'possibly', 'post', 'poster', 'posthumously', 'postman', 'postmodern', 'potato', 'potboiler', 'potent', 'potential', 'potentially', 'potion', 'potter', 'pound', 'pour', 'poverty', 'power', 'powerful', 'powerfully', 'powerless', 'practical', 'practicality', 'practically', 'practice', 'pragmatic', 'prairie', 'praise', 'prankster', 'pratchett', 'pray', 'prayer', 'preach', 'preacher', 'preaches', 'preachy', 'precede', 'precedes', 'precious', 'precise', 'precisely', 'precision', 'precocious', 'preconceive', 'preconception', 'precursor', 'predator', 'predecessor', 'predicament', 'predict', 'predictable', 'predictably', 'prediction', 'predicts', 'predjudice', 'preface', 'prefect', 'prefer', 'preferable', 'preferably', 'preference', 'prefers', 'pregnancy', 'pregnant', 'prehistoric', 'prejudice', 'prelude', 'premier', 'premise', 'prendick', 'preoccupation', 'preoccupy', 'prep', 'preparation', 'prepare', 'prepared', 'prepares', 'preposterous', 'prequel', 'prescient', 'presence', 'present', 'presentation', 'presently', 'preservation', 'preserve', 'presidency', 'president', 'presidential', 'press', 'pressure', 'prestige', 'prestigious', 'preston', 'presumably', 'presume', 'pretend', 'pretense', 'pretension', 'pretentious', 'pretty', 'prevail', 'prevails', 'prevalent', 'prevent', 'prevents', 'preview', 'previous', 'previously', 'prey', 'price', 'priceless', 'pride', 'prideful', 'priest', 'prim', 'primal', 'primarily', 'primary', 'prime', 'primer', 'primitive', 'primordial', 'prince', 'princess', 'princeton', 'principal', 'principle', 'print', 'printer', 'printing', 'prior', 'priority', 'prison', 'prisoner', 'pristine', 'privacy', 'private', 'privilege', 'privileged', 'privy', 'prize', 'probability', 'probable', 'probably', 'probe', 'problem', 'problematic', 'procedural', 'procedure', 'proceed', 'proceeding', 'proceeds', 'process', 'proclaim', 'proclaims', 'prodigious', 'produce', 'producer', 'product', 'production', 'productive', 'productivity', 'prof', 'profanity', 'profess', 'profession', 'professional', 'professor', 'profile', 'profit', 'profitable', 'profound', 'profoundly', 'profundity', 'program', 'programmed', 'progress', 'progression', 'progressive', 'progressively', 'prohibition', 'project', 'projection', 'prole', 'proletariat', 'prolific', 'prologue', 'prolong', 'prominence', 'prominent', 'prominently', 'promiscuity', 'promise', 'promising', 'promote', 'promotes', 'promotion', 'prompt', 'promptly', 'prone', 'pronounce', 'proof', 'prop', 'propaganda', 'propel', 'propensity', 'proper', 'properly', 'property', 'prophecy', 'prophet', 'prophetic', 'proponent', 'proportion', 'proposal', 'propose', 'proposes', 'proposition', 'propriety', 'prosaic', 'prose', 'prosecutor', 'prospect', 'prospective', 'prosper', 'prosperity', 'prosperous', 'prostitute', 'prostitution', 'protaganist', 'protagonist', 'protect', 'protection', 'protective', 'protector', 'protects', 'protest', 'protestant', 'proto', 'prototype', 'proud', 'proudly', 'proust', 'prove', 'proven', 'proverbial', 'provide', 'providence', 'provincial', 'provision', 'provocative', 'provoke', 'provokes', 'prowess', 'prozac', 'prynne', 'pseudo', 'pseudonym', 'psyche', 'psychiatric', 'psychiatrist', 'psychic', 'psycho', 'psychohistory', 'psychological', 'psychologically', 'psychologist', 'psychology', 'psychopath', 'psychotic', 'public', 'publication', 'publicity', 'publicly', 'publish', 'publisher', 'publishing', 'puffin', 'pulitzer', 'pull', 'pullman', 'pulp', 'pulse', 'pump', 'punch', 'punctuate', 'punctuation', 'punish', 'punishment', 'pupil', 'puppet', 'puppy', 'purchase', 'purchasing', 'pure', 'purely', 'purest', 'purgatory', 'purge', 'puritan', 'puritanical', 'puritanism', 'purity', 'purple', 'purport', 'purpose', 'purposeful', 'purposefully', 'purposely', 'purse', 'pursue', 'pursues', 'pursuit', 'push', 'puzo', 'puzzle', 'pyle', 'pyncheon', 'pynchon', 'python', 'quaint', 'quaker', 'qualifies', 'qualify', 'quality', 'qualm', 'quantity', 'quantum', 'quarrel', 'quarter', 'quasi', 'queen', 'queequeg', 'quentin', 'quest', 'question', 'questionable', 'quibble', 'quick', 'quicker', 'quickly', 'quiet', 'quietly', 'quinn', 'quintessential', 'quip', 'quirk', 'quirky', 'quit', 'quite', 'quixote', 'quot', 'quotable', 'quotation', 'quote', 'rabbit', 'rabid', 'race', 'rachel', 'racial', 'racism', 'racist', 'rack', 'rackham', 'radiation', 'radical', 'radically', 'radio', 'radley', 'raft', 'rage', 'raid', 'rail', 'railroad', 'rain', 'rainbow', 'rainy', 'raise', 'rake', 'rally', 'ralph', 'ramble', 'ramblings', 'rambunctious', 'ramification', 'ramotswe', 'rampant', 'ramsay', 'ranch', 'rand', 'randall', 'random', 'randomly', 'randomness', 'rang', 'range', 'ranger', 'rank', 'ranked', 'ransom', 'rant', 'rape', 'rapid', 'rapidly', 'rapist', 'rapture', 'rare', 'rarely', 'rarity', 'rash', 'raskolnikov', 'ratched', 'rate', 'rather', 'rating', 'ration', 'rational', 'rationale', 'rationalist', 'rationality', 'rationalization', 'rationalize', 'rattle', 'ravage', 'rave', 'raveloe', 'raven', 'raymond', 'razor', 'reach', 'reacher', 'react', 'reaction', 'reactionary', 'reacts', 'readability', 'readable', 'reader', 'readership', 'readily', 'reading', 'ready', 'reagan', 'real', 'realise', 'realises', 'realism', 'realist', 'realistic', 'realistically', 'reality', 'realization', 'realize', 'realizes', 'really', 'realm', 'reappear', 'rear', 'rearden', 'reason', 'reasonable', 'reasonably', 'reassure', 'rebecca', 'rebel', 'rebellion', 'rebellious', 'rebirth', 'reborn', 'rebuild', 'rebuke', 'recall', 'recap', 'recapture', 'reccomend', 'reccommend', 'receive', 'receives', 'recent', 'recently', 'reception', 'recess', 'recieved', 'recipe', 'recipient', 'recite', 'reckless', 'reckon', 'reclaim', 'recluse', 'reclusive', 'recognise', 'recognition', 'recognizable', 'recognize', 'recognizes', 'recollection', 'recomend', 'recommend', 'recommendation', 'recommends', 'reconcile', 'reconciliation', 'reconsider', 'reconstruction', 'record', 'recount', 'recover', 'recovers', 'recovery', 'recreate', 'recreation', 'recreational', 'recruit', 'recur', 'recycle', 'redeem', 'redeems', 'redemption', 'redemptive', 'rediscover', 'reduce', 'redundant', 'reed', 'reef', 'reek', 'reel', 'refer', 'reference', 'refers', 'refine', 'reflect', 'reflection', 'reflective', 'reform', 'refrain', 'refresh', 'refreshingly', 'refuge', 'refugee', 'refund', 'refusal', 'refuse', 'refute', 'regain', 'regard', 'regardless', 'regency', 'regime', 'regiment', 'region', 'register', 'regret', 'regular', 'regularly', 'regulate', 'regulation', 'rehash', 'reich', 'reign', 'reilly', 'rein', 'reinforce', 'reinforces', 'reiterate', 'reject', 'rejection', 'rejoice', 'rekindle', 'relatable', 'relate', 'related', 'relates', 'relation', 'relationship', 'relative', 'relatively', 'relativism', 'relativity', 'relax', 'relaxed', 'relay', 'release', 'relegate', 'relentless', 'relentlessly', 'relevance', 'relevant', 'reliable', 'reliance', 'relic', 'relief', 'relies', 'relieve', 'religion', 'religious', 'relish', 'relive', 'reluctance', 'reluctant', 'reluctantly', 'rely', 'remain', 'remainder', 'remains', 'remake', 'remark', 'remarkable', 'remarkably', 'remarque', 'remedy', 'remember', 'remembers', 'remembrance', 'remind', 'reminder', 'reminds', 'reminiscence', 'reminiscent', 'remnant', 'remorse', 'remote', 'remotely', 'remove', 'renaissance', 'rename', 'rend', 'render', 'rendition', 'renew', 'renounce', 'renowned', 'rent', 'repair', 'repeat', 'repeatedly', 'repel', 'repent', 'repentance', 'repercussion', 'repetition', 'repetitious', 'repetitive', 'replace', 'replacement', 'replete', 'replicate', 'reply', 'report', 'reporter', 'reporting', 'represent', 'representation', 'representative', 'repress', 'repression', 'repressive', 'reprint', 'reproduce', 'reproduction', 'republic', 'republican', 'repulse', 'repulsive', 'reputation', 'repute', 'request', 'require', 'requirement', 'requisite', 'reread', 'rescue', 'research', 'researcher', 'resemblance', 'resemble', 'resembles', 'resent', 'resentment', 'reservation', 'reserve', 'reside', 'residence', 'resident', 'resides', 'resign', 'resilience', 'resist', 'resistance', 'resists', 'resolution', 'resolve', 'resonance', 'resonant', 'resonate', 'resonates', 'resort', 'resound', 'resource', 'resourceful', 'resourcefulness', 'respect', 'respectability', 'respectable', 'respectful', 'respective', 'respectively', 'respond', 'responds', 'response', 'responsibility', 'responsible', 'rest', 'restaurant', 'restless', 'restoration', 'restore', 'restrain', 'restraint', 'restrict', 'restriction', 'result', 'resume', 'resurrect', 'resurrection', 'retail', 'retain', 'retains', 'retard', 'retell', 'rethink', 'retire', 'retirement', 'retold', 'retreat', 'retribution', 'retrieve', 'retrospect', 'return', 'reunion', 'reunite', 'reuven', 'reveal', 'reveals', 'revel', 'revelation', 'revenge', 'revere', 'reverence', 'reverend', 'reversal', 'reverse', 'review', 'reviewer', 'revise', 'revision', 'revisit', 'revival', 'revive', 'revolt', 'revolution', 'revolutionary', 'revolve', 'revolves', 'reward', 'rewrite', 'rhetoric', 'rhetorical', 'rhett', 'rhyme', 'rhythm', 'ribbon', 'rice', 'rich', 'richard', 'richer', 'richest', 'richly', 'richness', 'rick', 'ridden', 'riddle', 'ride', 'rider', 'ridicule', 'ridiculous', 'ridiculously', 'ridiculousness', 'rife', 'rifle', 'right', 'righteous', 'righteousness', 'rightful', 'rightfully', 'rightly', 'rigid', 'rikki', 'rincewind', 'ring', 'riot', 'ripe', 'ripley', 'ripped', 'ripper', 'ripple', 'rise', 'risen', 'risk', 'risky', 'rite', 'ritual', 'rival', 'rivalry', 'rivendell', 'river', 'riverboat', 'rivet', 'rizzoli', 'roach', 'road', 'roam', 'roar', 'roark', 'roarke', 'robb', 'robbed', 'robber', 'robbery', 'robbie', 'robbins', 'robert', 'robin', 'robinson', 'robot', 'robotics', 'robust', 'rochester', 'rock', 'rocket', 'rocky', 'roger', 'rogue', 'rohan', 'roland', 'role', 'roll', 'roller', 'rollick', 'roman', 'romance', 'romantic', 'romantically', 'romanticism', 'romanticize', 'rome', 'romeo', 'romero', 'romp', 'ronald', 'roof', 'room', 'roommate', 'roosevelt', 'root', 'rope', 'rosa', 'rose', 'rosemary', 'ross', 'roth', 'rotten', 'rough', 'roughly', 'round', 'rouse', 'route', 'routine', 'routinely', 'rowling', 'royal', 'royale', 'royalty', 'rubbish', 'ruby', 'rude', 'rudy', 'rudyard', 'rugged', 'ruin', 'rule', 'ruler', 'ruling', 'rumination', 'rumor', 'runaway', 'runner', 'rural', 'rush', 'rushdie', 'russell', 'russia', 'russian', 'russo', 'rustic', 'rusty', 'ruth', 'ruthless', 'ryan', 'ryder', 'sabotage', 'sack', 'sacred', 'sacrifice', 'saddam', 'sadden', 'saddest', 'sadistic', 'sadly', 'sadness', 'safe', 'safely', 'safety', 'saga', 'sagan', 'sage', 'sail', 'sailor', 'saint', 'saintly', 'sake', 'salary', 'sale', 'salem', 'salesman', 'salina', 'salinger', 'sally', 'salmon', 'salt', 'salvation', 'sample', 'samuel', 'samwise', 'sancho', 'sand', 'sandford', 'sandwich', 'sandy', 'sane', 'sanity', 'sansa', 'santa', 'santiago', 'sappy', 'sara', 'sarah', 'sarcasm', 'sarcastic', 'sardonic', 'saruman', 'satan', 'satanic', 'satellite', 'satire', 'satiric', 'satirical', 'satirist', 'satirize', 'satisfaction', 'satisfactorily', 'satisfactory', 'satisfied', 'satisfies', 'satisfy', 'saturate', 'saturday', 'sauron', 'savage', 'savagery', 'savannah', 'save', 'saving', 'savior', 'savor', 'savour', 'savvy', 'sawyer', 'saxon', 'saying', 'sayuri', 'scaffold', 'scale', 'scam', 'scan', 'scandal', 'scandalous', 'scar', 'scarcely', 'scare', 'scarier', 'scariest', 'scarlet', 'scarlett', 'scarpetta', 'scary', 'scathing', 'scatter', 'scenario', 'scene', 'scenery', 'scent', 'schedule', 'scheme', 'schindler', 'schizophrenic', 'schlosser', 'scholar', 'scholarly', 'scholarship', 'school', 'schoolboy', 'schooler', 'schoolers', 'schwartz', 'science', 'scientific', 'scientifically', 'scientist', 'scifi', 'scissors', 'scobie', 'scoff', 'scold', 'scoop', 'scope', 'score', 'scorn', 'scotland', 'scott', 'scottish', 'scoundrel', 'scout', 'scramble', 'scrap', 'scrape', 'scratch', 'scream', 'screen', 'screenplay', 'screenwriter', 'screw', 'screwtape', 'scribble', 'script', 'scripture', 'scroll', 'scrooge', 'scrutiny', 'seabiscuit', 'seagull', 'seal', 'seaman', 'seamless', 'seamlessly', 'seamstress', 'sean', 'sear', 'search', 'season', 'seat', 'sebastian', 'sebold', 'seclude', 'second', 'secondary', 'secondly', 'secrecy', 'secret', 'secretary', 'secretive', 'secretly', 'sect', 'section', 'sector', 'secular', 'secure', 'security', 'sedai', 'sedaris', 'seduce', 'seduction', 'seductive', 'seed', 'seedy', 'seek', 'seeker', 'seem', 'seemingly', 'segment', 'segregate', 'segregation', 'seize', 'seldom', 'seldon', 'select', 'selection', 'self', 'selfish', 'selfishness', 'selfless', 'sell', 'seller', 'semblance', 'semester', 'semi', 'seminal', 'seminar', 'semitic', 'semitism', 'senate', 'senator', 'send', 'sends', 'senior', 'sens', 'sensation', 'sensational', 'sense', 'senseless', 'sensibility', 'sensible', 'sensitive', 'sensitivity', 'sensory', 'sensual', 'sensuality', 'sent', 'sentence', 'sentient', 'sentiment', 'sentimental', 'sentimentality', 'separate', 'separately', 'separation', 'seperate', 'september', 'septimus', 'sequel', 'sequence', 'serf', 'serfdom', 'sergeant', 'serial', 'serialize', 'series', 'serious', 'seriously', 'seriousness', 'sermon', 'servant', 'serve', 'service', 'session', 'setback', 'setting', 'settle', 'settlement', 'settler', 'setup', 'seven', 'seventeen', 'seventeenth', 'seventh', 'seventy', 'several', 'severe', 'severely', 'seward', 'sewell', 'sewn', 'sexism', 'sexist', 'sexual', 'sexuality', 'sexually', 'sexy', 'seymour', 'shaara', 'shabby', 'shackle', 'shackleton', 'shade', 'shadow', 'shadowy', 'shady', 'shake', 'shaken', 'shakespeare', 'shakespearean', 'shaky', 'shall', 'shallow', 'shallowness', 'sham', 'shame', 'shameful', 'shangri', 'shannara', 'shape', 'share', 'shark', 'sharp', 'sharply', 'shatter', 'shaw', 'shed', 'sheep', 'sheer', 'sheet', 'shelby', 'shelf', 'shell', 'shelley', 'shelly', 'shelter', 'shepherd', 'sheppard', 'shere', 'sheriff', 'sherlock', 'sherman', 'shield', 'shift', 'shin', 'shine', 'shiny', 'ship', 'shipping', 'shipwreck', 'shire', 'shirer', 'shirley', 'shirt', 'shiver', 'shock', 'shocker', 'shockingly', 'shoe', 'shook', 'shoot', 'shop', 'shopaholic', 'shopping', 'shore', 'short', 'shortage', 'shortcoming', 'shorten', 'shorter', 'shortest', 'shortly', 'shot', 'shoulder', 'shout', 'shove', 'show', 'showcase', 'showdown', 'shower', 'shred', 'shreve', 'shrewd', 'shrink', 'shroud', 'shrug', 'shudder', 'shun', 'shut', 'siberia', 'sibling', 'sibyl', 'sick', 'sicken', 'sickert', 'sickly', 'sickness', 'siddhartha', 'side', 'sidekick', 'sidney', 'siege', 'sift', 'sigh', 'sight', 'sign', 'signal', 'signature', 'signet', 'significance', 'significant', 'significantly', 'signify', 'signing', 'sikes', 'silas', 'silence', 'silent', 'silently', 'silk', 'silliness', 'silly', 'silmarillion', 'silva', 'silver', 'similar', 'similarity', 'similarly', 'simile', 'simmons', 'simon', 'simple', 'simpler', 'simplest', 'simplicity', 'simplify', 'simplistic', 'simply', 'simpson', 'simultaneously', 'since', 'sincere', 'sincerely', 'sincerity', 'sinclair', 'sinful', 'sing', 'singer', 'single', 'sings', 'singular', 'sinise', 'sinister', 'sink', 'sinking', 'sinner', 'siren', 'sissy', 'sister', 'sisterhood', 'sitcom', 'site', 'sits', 'sitting', 'situation', 'sixteen', 'sixth', 'sixty', 'size', 'skeleton', 'skeptic', 'skeptical', 'skepticism', 'sketch', 'skewed', 'skewer', 'skill', 'skilled', 'skillful', 'skillfully', 'skim', 'skin', 'skinny', 'skip', 'skirt', 'skull', 'slack', 'slain', 'slam', 'slander', 'slang', 'slant', 'slap', 'slapstick', 'slate', 'slaughter', 'slaughterhouse', 'slave', 'slavery', 'slay', 'sleazy', 'sled', 'sleep', 'sleepy', 'sleeve', 'slept', 'sleuth', 'slew', 'slice', 'slide', 'slight', 'slightest', 'slightly', 'slim', 'slimy', 'slip', 'slipcase', 'slippery', 'slog', 'slogan', 'sloppy', 'slow', 'slowly', 'slows', 'slum', 'smack', 'small', 'smart', 'smarter', 'smartest', 'smash', 'smaug', 'smell', 'smersh', 'smile', 'smiley', 'smith', 'smitten', 'smoke', 'smoking', 'smooth', 'smoothly', 'smother', 'smug', 'smuggle', 'snake', 'snap', 'snappy', 'snapshot', 'snatch', 'sneak', 'snippet', 'snob', 'snobbery', 'snobbish', 'snobby', 'snotty', 'snow', 'snowball', 'snowden', 'snowy', 'soak', 'soap', 'soar', 'sober', 'social', 'socialism', 'socialist', 'socialite', 'socially', 'societal', 'society', 'socio', 'sociological', 'sociology', 'sociopath', 'sock', 'socrates', 'soft', 'soften', 'software', 'soil', 'solace', 'solar', 'soldier', 'sole', 'soledad', 'solely', 'solid', 'solidify', 'soliloquy', 'solitary', 'solitude', 'solo', 'solomon', 'solution', 'solve', 'solves', 'solzhenitsyn', 'soma', 'somber', 'somebody', 'someday', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhat', 'somewhere', 'song', 'sookie', 'soon', 'sooner', 'sooo', 'soooo', 'soothe', 'sophie', 'sophisticated', 'sophistication', 'sophomore', 'sorcerer', 'sorcery', 'sordid', 'sorely', 'sorrow', 'sorry', 'sort', 'sought', 'soul', 'soulless', 'soulmate', 'sound', 'soup', 'sour', 'source', 'south', 'southern', 'southerner', 'southwest', 'soviet', 'space', 'spaceship', 'spade', 'spain', 'span', 'spanish', 'spar', 'spare', 'spark', 'sparkle', 'sparse', 'spartan', 'spawn', 'speak', 'speaker', 'speaks', 'spear', 'special', 'specially', 'specie', 'specific', 'specifically', 'speckle', 'spectacle', 'spectacular', 'spectator', 'spectrum', 'speculate', 'speculation', 'speculative', 'speech', 'speechless', 'speed', 'spell', 'spellbind', 'spellbound', 'spencer', 'spend', 'spending', 'spends', 'spenser', 'spent', 'sperm', 'spew', 'sphere', 'spice', 'spider', 'spill', 'spin', 'spine', 'spinster', 'spiral', 'spirit', 'spiritual', 'spirituality', 'spiritually', 'spit', 'spite', 'spiteful', 'splash', 'splendid', 'splendidly', 'splendor', 'split', 'spoil', 'spoiler', 'spoke', 'spoken', 'sponsor', 'spontaneous', 'spoof', 'spooky', 'spoon', 'sport', 'spot', 'spotlight', 'spouse', 'spout', 'sprawl', 'spread', 'spree', 'spring', 'springboard', 'sprinkle', 'spun', 'spunky', 'spur', 'squabble', 'squad', 'squadron', 'squalor', 'square', 'squarely', 'squeamish', 'squeeze', 'squid', 'squire', 'stab', 'stabbed', 'stability', 'stable', 'stack', 'staff', 'stag', 'stage', 'stagger', 'stagnant', 'staid', 'stain', 'stair', 'stake', 'stale', 'stalin', 'stalinist', 'stalk', 'stall', 'stamp', 'stance', 'stand', 'standard', 'standpoint', 'stanley', 'stannis', 'staple', 'star', 'starbuck', 'stare', 'stark', 'starks', 'starling', 'starship', 'start', 'starter', 'startle', 'startlingly', 'starvation', 'starve', 'state', 'stately', 'statement', 'statesman', 'static', 'station', 'statistic', 'statue', 'stature', 'status', 'staunch', 'stay', 'stayed', 'steadfast', 'steadily', 'steady', 'steal', 'steam', 'steamboat', 'steel', 'steele', 'steep', 'steer', 'stein', 'steinbeck', 'stellar', 'stem', 'step', 'stephanie', 'stephen', 'stephenson', 'stepmother', 'stereotype', 'stereotypical', 'sterile', 'sterling', 'stern', 'sternwood', 'steve', 'steven', 'stevenson', 'steward', 'stewart', 'stick', 'sticker', 'sticky', 'stiff', 'stifle', 'stigma', 'still', 'stilted', 'stimulate', 'sting', 'stink', 'stint', 'stir', 'stitch', 'stock', 'stodgy', 'stoic', 'stoker', 'stole', 'stomach', 'stone', 'stood', 'stoop', 'stop', 'store', 'storm', 'stormy', 'story', 'storyline', 'storyteller', 'storytelling', 'stove', 'stowe', 'straight', 'straightforward', 'strain', 'strand', 'strange', 'strangely', 'strangeness', 'stranger', 'strangest', 'strap', 'strategic', 'strategy', 'stratum', 'straw', 'stray', 'streak', 'stream', 'street', 'strength', 'strengthen', 'stress', 'stretch', 'stricken', 'strict', 'strictly', 'stricture', 'stride', 'strife', 'strike', 'strikingly', 'string', 'strip', 'strive', 'strives', 'strobel', 'stroke', 'stroll', 'strong', 'strongly', 'struck', 'structural', 'structure', 'struggle', 'strung', 'stuart', 'stubborn', 'stubbornness', 'stuck', 'student', 'studio', 'study', 'stuff', 'stuffed', 'stuffy', 'stumble', 'stump', 'stun', 'stunningly', 'stunt', 'stupid', 'stupidity', 'sturdy', 'style', 'stylist', 'stylistic', 'stylistically', 'subconscious', 'subdue', 'subject', 'subjective', 'sublime', 'submarine', 'submerge', 'submission', 'submissive', 'submit', 'subordinate', 'subplot', 'subplots', 'subsequent', 'subsequently', 'subservient', 'substance', 'substantial', 'substantially', 'substitute', 'subtext', 'subtitle', 'subtle', 'subtlety', 'subtly', 'suburb', 'suburban', 'subversive', 'subway', 'succeed', 'success', 'successful', 'successfully', 'succession', 'successive', 'successor', 'succinct', 'succinctly', 'succumb', 'succumbs', 'suck', 'sucker', 'sudden', 'suddenly', 'suffer', 'suffering', 'suffers', 'suffice', 'sufficient', 'sufficiently', 'suffocate', 'sugar', 'suggest', 'suggestion', 'suggests', 'suicidal', 'suicide', 'suit', 'suitable', 'suitor', 'sullivan', 'summarize', 'summarizes', 'summary', 'summer', 'summit', 'summon', 'sunday', 'sunk', 'sunlight', 'sunny', 'sunset', 'sunshine', 'super', 'superb', 'superbly', 'superficial', 'superficiality', 'superficially', 'superfluous', 'superhuman', 'superior', 'superiority', 'superlative', 'superman', 'supernatural', 'superstition', 'superstitious', 'supper', 'supplement', 'supplemental', 'supplementary', 'supply', 'support', 'supporter', 'suppose', 'supposedly', 'suppress', 'supremacy', 'supreme', 'supremely', 'suprised', 'sure', 'surely', 'surface', 'surge', 'surgeon', 'surgery', 'surmise', 'surpass', 'surpasses', 'surplus', 'surprise', 'surprised', 'surprising', 'surprisingly', 'surreal', 'surrender', 'surrogate', 'surround', 'surroundings', 'surveillance', 'survey', 'survival', 'survive', 'survives', 'survivor', 'susan', 'susannah', 'susie', 'suspect', 'suspence', 'suspend', 'suspense', 'suspenseful', 'suspensful', 'suspension', 'suspicion', 'suspicious', 'sustain', 'suzanne', 'swallow', 'swamp', 'swan', 'swarm', 'swashbuckling', 'sway', 'swayed', 'swear', 'swears', 'sweat', 'swede', 'sweden', 'sweep', 'sweet', 'sweetheart', 'sweetness', 'swell', 'swept', 'swift', 'swiftly', 'swim', 'swing', 'swirl', 'swiss', 'switch', 'switzerland', 'swoon', 'sword', 'sworn', 'sybil', 'sydney', 'sylvia', 'symbol', 'symbolic', 'symbolically', 'symbolism', 'symbolize', 'symbolizes', 'sympathetic', 'sympathize', 'sympathy', 'symphony', 'symptom', 'syndrome', 'synonymous', 'synopsis', 'syntax', 'system', 'systematically', 'table', 'tablet', 'taboo', 'tackle', 'tactic', 'taggart', 'tail', 'tailor', 'taint', 'take', 'tale', 'talent', 'talented', 'taliban', 'talk', 'tall', 'tame', 'tamper', 'tangent', 'tangible', 'tangle', 'tank', 'tantalize', 'tape', 'tapestry', 'tara', 'target', 'tarzan', 'task', 'taste', 'tattered', 'taught', 'taunt', 'taut', 'tavi', 'taylor', 'teach', 'teacher', 'teaching', 'team', 'tear', 'tease', 'tech', 'technical', 'technically', 'technique', 'techno', 'technological', 'technology', 'teddy', 'tedious', 'tedium', 'teen', 'teenage', 'teenaged', 'teenager', 'teeth', 'telegraph', 'telephone', 'telescreens', 'television', 'tell', 'teller', 'tempe', 'temper', 'temperament', 'temperance', 'temperature', 'templar', 'template', 'temple', 'temporal', 'temporarily', 'temporary', 'tempt', 'temptation', 'tenacity', 'tenant', 'tend', 'tendency', 'tender', 'tenderness', 'tends', 'tenet', 'tenniel', 'tense', 'tension', 'tent', 'tenth', 'tenuous', 'term', 'terminal', 'terminology', 'terrain', 'terrible', 'terribly', 'terrific', 'terrify', 'territory', 'terror', 'terrorism', 'terrorist', 'terrorize', 'terry', 'terse', 'test', 'testament', 'testify', 'testimony', 'texas', 'text', 'textbook', 'textual', 'texture', 'textured', 'thackeray', 'thank', 'thankful', 'thankfully', 'thanks', 'thats', 'theater', 'theatre', 'theatrical', 'thee', 'theft', 'thematic', 'thematically', 'theme', 'theoden', 'theodore', 'theologian', 'theological', 'theology', 'theoretical', 'theorist', 'theory', 'therapist', 'therapy', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'thereof', 'thesis', 'thick', 'thickens', 'thicker', 'thief', 'thier', 'thin', 'thing', 'think', 'thinker', 'thinly', 'third', 'thirst', 'thirsty', 'thirteen', 'thirty', 'thomas', 'thompson', 'thor', 'thoreau', 'thorin', 'thorn', 'thornfield', 'thornton', 'thorough', 'thoroughly', 'thorpe', 'thou', 'though', 'thought', 'thoughtful', 'thoughtless', 'thousand', 'thread', 'threat', 'threaten', 'threatens', 'three', 'threw', 'thrift', 'thrill', 'thriller', 'thrive', 'thrives', 'throat', 'throne', 'throughly', 'throughout', 'throw', 'thrown', 'thru', 'thrushcross', 'thrust', 'thug', 'thumb', 'thunder', 'thursday', 'thus', 'thwart', 'tick', 'ticket', 'tickle', 'tidbit', 'tide', 'tidy', 'tiger', 'tight', 'tightly', 'tiki', 'tikki', 'till', 'tilney', 'time', 'timeless', 'timelessness', 'timeline', 'timely', 'timid', 'timing', 'tinker', 'tiny', 'tirade', 'tire', 'tiresome', 'tirith', 'tissue', 'tita', 'titan', 'titanic', 'title', 'titular', 'toad', 'toast', 'tobacco', 'today', 'toddler', 'together', 'toil', 'toilet', 'token', 'told', 'tolerable', 'tolerance', 'tolerant', 'tolerate', 'tolkein', 'tolkien', 'toll', 'tolstoy', 'tomb', 'tomboy', 'tome', 'tommy', 'tomorrow', 'tone', 'tongue', 'toni', 'tonight', 'tony', 'toohey', 'tool', 'toole', 'tooth', 'topic', 'topped', 'torch', 'torment', 'torn', 'torture', 'torturous', 'tory', 'toss', 'total', 'totalitarian', 'totalitarianism', 'totally', 'touch', 'tough', 'tougher', 'tour', 'tourist', 'tout', 'toward', 'towards', 'tower', 'town', 'townsfolk', 'townspeople', 'trace', 'track', 'tract', 'tracy', 'trade', 'trademark', 'trader', 'trading', 'tradition', 'traditional', 'traditionally', 'traffic', 'tragedy', 'tragic', 'tragically', 'trail', 'trailer', 'train', 'training', 'trait', 'traitor', 'tralfamadore', 'tralfamadorians', 'tramp', 'transaction', 'transcend', 'transcendent', 'transcends', 'transfer', 'transform', 'transformation', 'transforms', 'transgression', 'transition', 'translate', 'translates', 'translation', 'translator', 'transparent', 'transpire', 'transplant', 'transport', 'transportation', 'transylvania', 'trap', 'trapping', 'trash', 'trashy', 'trask', 'trauma', 'traumatic', 'travail', 'travel', 'traveler', 'traveller', 'travelogue', 'traverse', 'travesty', 'treacherous', 'treachery', 'tread', 'treader', 'treason', 'treasure', 'treat', 'treatise', 'treatment', 'treaty', 'tree', 'trek', 'tremain', 'tremble', 'tremendous', 'tremendously', 'trench', 'trend', 'trenton', 'trepidation', 'trial', 'triangle', 'tribal', 'tribe', 'tribulation', 'tribute', 'trick', 'tricked', 'tricky', 'triffids', 'trifle', 'trigger', 'trilogy', 'trim', 'trinity', 'trio', 'trip', 'tripe', 'trite', 'triumph', 'triumphant', 'trivia', 'trivial', 'troll', 'troop', 'trooper', 'trope', 'tropic', 'tropical', 'trotsky', 'trouble', 'troubled', 'troublesome', 'trout', 'truck', 'trudge', 'true', 'truely', 'truer', 'truest', 'truly', 'truman', 'trump', 'trunk', 'trust', 'truth', 'truthful', 'truthfully', 'tube', 'tuchman', 'tuck', 'tudor', 'tuesday', 'tumble', 'tumultuous', 'tune', 'tunnel', 'turbulent', 'turgid', 'turkey', 'turkish', 'turmoil', 'turn', 'turner', 'turow', 'turtle', 'tuskegee', 'tutor', 'twain', 'tweedledee', 'tweedledum', 'twelve', 'twentieth', 'twenty', 'twice', 'twilight', 'twin', 'twist', 'twit', 'twoflower', 'tyler', 'type', 'typeset', 'typewriter', 'typical', 'typically', 'typo', 'typography', 'tyrannical', 'tyranny', 'tyrant', 'tyrion', 'ubiquitous', 'ugliness', 'ugly', 'ultimate', 'ultimately', 'ultra', 'ulysses', 'unabashed', 'unable', 'unabridged', 'unacceptable', 'unanswered', 'unappealing', 'unassuming', 'unattainable', 'unattractive', 'unavoidable', 'unaware', 'unbalanced', 'unbearable', 'unbearably', 'unbeknownst', 'unbelievable', 'unbelievably', 'unbiased', 'unbridled', 'uncanny', 'uncaring', 'uncas', 'uncertain', 'uncertainty', 'unchanged', 'unchecked', 'uncle', 'unclear', 'uncomfortable', 'uncommon', 'uncompromising', 'unconditional', 'unconscious', 'unconsciously', 'uncontrollable', 'unconventional', 'unconvincing', 'uncover', 'uncovered', 'uncovers', 'undead', 'undeniable', 'undeniably', 'undercover', 'undercurrent', 'underdeveloped', 'underdog', 'undergo', 'undergoes', 'undergraduate', 'underground', 'underlie', 'underline', 'undermine', 'underneath', 'underrated', 'underscore', 'undersea', 'understand', 'understandable', 'understandably', 'understands', 'understated', 'understatement', 'understood', 'undertake', 'undertaken', 'undertaking', 'undertone', 'underwater', 'underworld', 'undo', 'undone', 'undoubtedly', 'undying', 'uneasy', 'uneducated', 'unending', 'uneven', 'uneventful', 'unexpected', 'unexpectedly', 'unexplained', 'unfair', 'unfairly', 'unfamiliar', 'unfathomable', 'unfeeling', 'unfinished', 'unfit', 'unflinching', 'unfold', 'unfolded', 'unfolds', 'unforgettable', 'unforgivable', 'unforgiving', 'unfortunate', 'unfortunately', 'unfulfilled', 'unhappiness', 'unhappy', 'unhealthy', 'unheard', 'unicorn', 'unified', 'uniform', 'unify', 'unimaginable', 'unimportant', 'unintended', 'unintentionally', 'uninteresting', 'union', 'unique', 'uniquely', 'uniqueness', 'unit', 'unite', 'united', 'unity', 'universal', 'universally', 'universe', 'university', 'unjust', 'unjustly', 'unkind', 'unknowingly', 'unknown', 'unleash', 'unleashed', 'unless', 'unlikable', 'unlike', 'unlikeable', 'unlikely', 'unlimited', 'unlucky', 'unmarried', 'unmatched', 'unnamed', 'unnatural', 'unnecessarily', 'unnecessary', 'unnoticed', 'unorthodox', 'unparalleled', 'unpleasant', 'unpopular', 'unprecedented', 'unpredictable', 'unprepared', 'unquestionably', 'unravel', 'unravels', 'unread', 'unreadable', 'unreal', 'unrealistic', 'unreasonable', 'unrelated', 'unrelenting', 'unreliable', 'unremarkable', 'unrequited', 'unresolved', 'unrest', 'unsatisfied', 'unsatisfying', 'unsavory', 'unscrupulous', 'unseen', 'unsettle', 'unsolved', 'unspeakable', 'unstable', 'unstoppable', 'unstuck', 'unsuccessful', 'unsure', 'unsurpassed', 'unsuspecting', 'unsympathetic', 'unthinkable', 'untimely', 'unto', 'untold', 'untouched', 'unusual', 'unusually', 'unwanted', 'unwavering', 'unwilling', 'unwittingly', 'unworthy', 'upbeat', 'upbringing', 'upcoming', 'update', 'updike', 'upheaval', 'uphold', 'uplift', 'upon', 'upper', 'upright', 'upset', 'upside', 'upstairs', 'urban', 'urberville', 'urbervilles', 'urge', 'urgency', 'urgent', 'uriah', 'ursula', 'usage', 'useful', 'useless', 'user', 'usher', 'ussr', 'usual', 'usually', 'utilitarianism', 'utility', 'utilize', 'utilized', 'utilizes', 'utmost', 'utopia', 'utopian', 'utter', 'utterly', 'utterson', 'vacation', 'vacuum', 'vague', 'vaguely', 'vain', 'valentine', 'valiant', 'valid', 'validate', 'validity', 'valjean', 'valley', 'valuable', 'value', 'vampire', 'vane', 'vanish', 'vanished', 'vanity', 'vantage', 'vapid', 'variation', 'varied', 'varies', 'variety', 'various', 'vary', 'vast', 'vastly', 'vatican', 'vega', 'vegetable', 'vehicle', 'veil', 'vein', 'vendor', 'veneer', 'vengeance', 'vengeful', 'venice', 'vent', 'venture', 'venus', 'verb', 'verbal', 'verbatim', 'verbiage', 'verbose', 'verdict', 'verge', 'verify', 'veritable', 'vermeer', 'vernacular', 'verne', 'versa', 'verse', 'version', 'versus', 'vessel', 'veteran', 'viable', 'vibrant', 'vicar', 'vice', 'vicious', 'victim', 'victimize', 'victor', 'victoria', 'victorian', 'victory', 'video', 'viet', 'vietnam', 'vietnamese', 'view', 'viewer', 'viewpoint', 'vignette', 'vigor', 'vigorous', 'viii', 'viking', 'viktor', 'vile', 'village', 'villager', 'villain', 'villainous', 'villette', 'villian', 'villians', 'vimes', 'vincent', 'vinci', 'vindictive', 'vintage', 'violate', 'violation', 'violence', 'violent', 'violently', 'violet', 'virgin', 'virginia', 'virginity', 'virtual', 'virtually', 'virtue', 'virtuous', 'virus', 'visceral', 'visible', 'vision', 'visionary', 'visit', 'visitor', 'visual', 'visualize', 'visually', 'visuals', 'vital', 'vitality', 'vivid', 'vividly', 'vividness', 'vocabulary', 'vocal', 'vogue', 'voice', 'void', 'volcano', 'voldemort', 'voltaire', 'volume', 'voluntarily', 'volunteer', 'vomit', 'vonnegut', 'voracious', 'vote', 'voting', 'vowed', 'voyage', 'vulgar', 'vulnerability', 'vulnerable', 'wacky', 'wade', 'wage', 'wager', 'waist', 'wait', 'waiter', 'waitress', 'wake', 'walden', 'walk', 'walker', 'wall', 'wallace', 'wallow', 'walt', 'walter', 'wander', 'wanders', 'wang', 'wannabe', 'want', 'ward', 'wardrobe', 'warfare', 'wargs', 'warm', 'warmly', 'warmth', 'warn', 'warning', 'warns', 'warp', 'warrant', 'warren', 'warrior', 'wart', 'wartime', 'wary', 'wash', 'washington', 'wasnt', 'waste', 'wasteland', 'watch', 'watcher', 'watchman', 'water', 'watership', 'watson', 'waugh', 'wave', 'waver', 'wayne', 'weak', 'weaken', 'weaker', 'weakness', 'wealth', 'wealthier', 'wealthy', 'weapon', 'wear', 'weary', 'weasel', 'weather', 'weave', 'weaver', 'website', 'wedding', 'wedlock', 'weed', 'week', 'weekend', 'weekly', 'weep', 'weigh', 'weighs', 'weight', 'weighty', 'weird', 'weirdness', 'welcome', 'welfare', 'well', 'weller', 'wemmick', 'wentworth', 'werewolf', 'wessex', 'west', 'western', 'westerner', 'westeros', 'weston', 'weyden', 'whale', 'whaler', 'wharton', 'whatever', 'whats', 'whatsoever', 'wheat', 'wheel', 'whenever', 'whereas', 'whereby', 'wherein', 'wherever', 'whether', 'whichever', 'whilst', 'whim', 'whimsical', 'whine', 'whiny', 'whip', 'whirl', 'whirlwind', 'whisk', 'whiskey', 'whisper', 'whistle', 'white', 'whitman', 'whoa', 'whodunit', 'whoever', 'whole', 'wholeheartedly', 'wholesome', 'wholly', 'whore', 'whose', 'wich', 'wicked', 'wickedly', 'wickedness', 'wickham', 'wide', 'widely', 'wider', 'widespread', 'widow', 'widowed', 'widower', 'wield', 'wiesel', 'wife', 'wikipedia', 'wilbur', 'wilcox', 'wild', 'wilde', 'wilder', 'wilderness', 'wildly', 'wilkes', 'wilkie', 'will', 'willa', 'willful', 'william', 'williams', 'willie', 'willing', 'willingly', 'willingness', 'willis', 'willoughby', 'willow', 'willy', 'wilson', 'wimp', 'winchester', 'wind', 'windmill', 'window', 'wine', 'wing', 'wink', 'winner', 'winston', 'winter', 'wipe', 'wire', 'wisconsin', 'wisdom', 'wise', 'wisely', 'wiser', 'wish', 'witch', 'witchcraft', 'wither', 'within', 'without', 'withstand', 'withstood', 'witness', 'witted', 'witticism', 'witty', 'wizard', 'woke', 'wolf', 'wolfe', 'woman', 'womanhood', 'wonder', 'wonderful', 'wonderfull', 'wonderfully', 'wonderland', 'wondrous', 'wont', 'wood', 'wooden', 'woodhouse', 'woolf', 'word', 'wordplay', 'wordsmith', 'wordsworth', 'wordy', 'wore', 'work', 'worker', 'working', 'world', 'worldly', 'worldview', 'worldwide', 'worm', 'wormwood', 'worn', 'worried', 'worry', 'worship', 'worth', 'worthless', 'worthwhile', 'worthy', 'wotton', 'would', 'wound', 'wove', 'woven', 'wrap', 'wrath', 'wreak', 'wreck', 'wrench', 'wrestle', 'wrestling', 'wretched', 'wright', 'wrinkle', 'write', 'writen', 'writer', 'writes', 'writing', 'writting', 'wrong', 'wrongly', 'wrought', 'wuthering', 'wwii', 'wynand', 'yahoo', 'yankee', 'yard', 'yarn', 'yawn', 'yeah', 'year', 'yearn', 'yearns', 'yell', 'yellow', 'yesterday', 'yield', 'york', 'yorker', 'yorkshire', 'yossarian', 'young', 'youngster', 'youth', 'youthful', 'zany', 'zaphod', 'zeal', 'zeena', 'zelda', 'zero', 'zombie', 'zone', 'zooey']\n"
     ]
    }
   ],
   "source": [
    "print(new_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New vocab list seem to be in reasonable range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate tfidf transformer\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf=True,use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = tfidf_transformer.fit_transform(count_vector_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1806240, 10000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Sampling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our datset is still way too big to process with current resources. <br> we will use pandas sample to randomly sample out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample 500000 samples from our dataset\n",
    "sampled_data = df_re.sample(n=10000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_review = sampled_data.review_lemmatized\n",
    "sampled_output = sampled_data.asin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector_sampled = vectorizer_5.transform(sampled_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector_sampled = tfidf_transformer.transform(count_vector_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(tfidf_vector_sampled, sampled_output, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.5 Review Dataset Revisited\n",
    "\n",
    "In attempt to create a classification model for the above tfidf vector revealed an obstacle.<br> Sheer number of reviews AKA documents are creating way too much burden for the available resources and is running to no end.\n",
    "\n",
    "Although it would be best if we can make use of all the data available, but model is not great because it has more data than other models. <br> We will bring back our older version of the full review dataset which has been cleaned but not yet trimmed down. <br> The only filtering done for this dataset is the minimum review count for 50 that was originally done.\n",
    "\n",
    "From this dataset, to reduce the number of documents, we will first go through an updated, more rigorous data trimming and tigher restriction on the number of reviews.  <br> The reason for this decision is because we do not want to reduce our selection of books too much.  <br>We will sacrifice a little bit of validity of the reviews to save the selection of books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import full dataset with 6 million reviews\n",
    "df_main = pd.read_csv('data/df_re_dupCleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SPAM Removal**\n",
    "\n",
    "We noticed there was an abundance of spam reviews (single reviewer, many books, same reviews).  <br> In prior duplicate checking, it was done for the whole dataframe which means the duplicate was only checked for the whole rows. <br> In the case of SPAM reviews, they are not row-duplicates but mostly reviewer-review duplicates. \n",
    "\n",
    "However, we are conducting a more rigorous data trimming so any duplicated reviews will be removed keeping none of the duplicates. <br> Here, we are not keeping any of the duplicates as we are not assuming any two different books reviews or reviews from two different users are the same, and that spam reviews do not contribute to the actual good reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6006462 entries, 0 to 6006461\n",
      "Data columns (total 5 columns):\n",
      "asin          object\n",
      "title         object\n",
      "reviewerID    object\n",
      "overall       float64\n",
      "review        object\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 229.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_main.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates based on column review\n",
    "df_main.drop_duplicates(subset='review', keep=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1281215 entries, 0 to 6006290\n",
      "Data columns (total 5 columns):\n",
      "asin          1281215 non-null object\n",
      "title         1281162 non-null object\n",
      "reviewerID    1281215 non-null object\n",
      "overall       1281215 non-null float64\n",
      "review        1281215 non-null object\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 58.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_main.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a big drop in the total number of reviews, 6 million to 1.3 million.  This goes to show that how our review dataset was teeming with duplicated reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lower Bound : 30 reviews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of different books:  16393\n"
     ]
    }
   ],
   "source": [
    "main_asin = df_main.groupby('asin').asin.count()\n",
    "\n",
    "print('number of different books: ', len(main_asin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are currently 16393 books after duplicate drops.  However, current dataset contains reviews for book that after cleaning, contains only few reviews. <br> Since for this review-based content based filtering recommender system, it is important to have enough review data for recommender to actually recommend. \n",
    "\n",
    "<br>We will drop books with less than 30 reviews as opposed to 50 before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of books with less than 30 reviews:  3902\n"
     ]
    }
   ],
   "source": [
    "print('number of books with less than 30 reviews: ',len(main_asin[main_asin<30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter \n",
    "df_main = df_main.loc[~df_main.asin.isin(main_asin[main_asin<30].index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upper Bound : 50 reviews**\n",
    "\n",
    "Next, we will set an upper limit to the reviews to 50.  <br> This means any books in our process review dataframe will only contain 30 to 50 reviews per books. <br> This is a decision made to reduce the number of data but not lose the number of books.  <br> Doing this will also introduce a bit of fairness to the lesser reviewed books and this is okay. <br>We are trying to build a recommender system based on user reviews not based on how many reviews the book has gotten.\n",
    "\n",
    "However, setting an upper limit to the reviews is far difficult than removing books with reviews less than 30 because we need to make a decision of which reviews will be picked. <br> To make sure the selection is not biased, we will re-use the dataframe sample method to sample out 50 reviews from any books that have more than 50 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Takes in dataframe\n",
    "\n",
    "Outputs sampled dataframe\n",
    "'''\n",
    "\n",
    "def takeSample(df):\n",
    "    \n",
    "    #return sampled dataframe\n",
    "    return df.sample(n=100, random_state=0)\n",
    "    \n",
    "\n",
    "    \n",
    "def removeExcess(df):\n",
    "    \n",
    "    #get asin list \n",
    "    asin_list = df.groupby('asin').asin.count()\n",
    "    \n",
    "    #get list of books with too many reviews\n",
    "    excess_reviewed_books = asin_list[asin_list>50].index\n",
    "    \n",
    "    #save the non-excessive reviews to output dataframe\n",
    "    df_result = df.loc[~df.asin.isin(excess_reviewed_books)]\n",
    "    \n",
    "    \n",
    "    #loop through all excessive review books\n",
    "    for book in excess_reviewed_books :\n",
    "        \n",
    "        #isolate the book at scope\n",
    "        df_slice = df.loc[df.asin==book]\n",
    "    \n",
    "        #sample 50 reviews from our dataframe\n",
    "        df_slice = df_slice.sample(n=50, random_state=0)\n",
    "        \n",
    "        #merge back to the primary dataframe\n",
    "        df_result = pd.concat([df_result,df_slice])\n",
    "        \n",
    "    \n",
    "    return df_result\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9432\n",
      "Time:  3420.539488839\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "df_re = removeExcess(df_main)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_re.to_csv('data/re_upperbound.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_re = pd.read_csv('data/re_upperbound.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_re.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up asin, title, reviewerID\n",
    "df_re['asin'] = df_re['asin'].apply(lambda x: x.lower())\n",
    "df_re['title'] = df_re['title'].apply(lambda x: cleanText(x))\n",
    "df_re['reviewerID'] = df_re['reviewerID'].apply(lambda x: x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add title to review text\n",
    "df_re['review'] = df_re['title'] + ' ' + df_re['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate unique asin-title\n",
    "asin_title = df_re[['asin','title']].drop_duplicates(keep='first')\n",
    "\n",
    "#drop redundant title \n",
    "df_re.drop(columns='title',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up review\n",
    "df_re['review'] = df_re['review'].apply(lambda x: cleanText(x))\n",
    "\n",
    "#build stopwords\n",
    "eng_stopwords = set(stopwords.words('english') + ['book','books','author','authors'])\n",
    "\n",
    "\n",
    "#tokenize and remove stopwords\n",
    "df_re['review'] = df_re['review'].apply(lambda x: removeStopwords(x, eng_stopwords))\n",
    "\n",
    "#lemmatize each work token to root word given we know the pos_tag of the word\n",
    "df_re['review_lemmatized'] = df_re['review'].apply(lambda x: lemmatize_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/byungchankim/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>review</th>\n",
       "      <th>review_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b0000630mu</td>\n",
       "      <td>a332u346e9t5pu</td>\n",
       "      <td>4.5</td>\n",
       "      <td>[html, complete, reference, great, think, good...</td>\n",
       "      <td>[html, complete, reference, great, think, good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0700608761</td>\n",
       "      <td>a3sofls15m0iq2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[stopped, stalingrad, luftwaffe, hitler, defea...</td>\n",
       "      <td>[stop, stalingrad, luftwaffe, hitler, defeat, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0743471474</td>\n",
       "      <td>a3fy7ov19hp0q7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[shadow, lion, tried, couple, times, read, tim...</td>\n",
       "      <td>[shadow, lion, try, couple, time, read, time, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0743471474</td>\n",
       "      <td>a2n8h6udrjk531</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[shadow, lion, brilliant, mercedes, descriptio...</td>\n",
       "      <td>[shadow, lion, brilliant, mercedes, descriptio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0060953616</td>\n",
       "      <td>aqanmvbtro0k2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>[climbing, high, woman, account, surviving, ev...</td>\n",
       "      <td>[climb, high, woman, account, survive, everest...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin      reviewerID  overall  \\\n",
       "0  b0000630mu  a332u346e9t5pu      4.5   \n",
       "1  0700608761  a3sofls15m0iq2      5.0   \n",
       "2  0743471474  a3fy7ov19hp0q7      2.0   \n",
       "3  0743471474  a2n8h6udrjk531      5.0   \n",
       "4  0060953616   aqanmvbtro0k2      1.5   \n",
       "\n",
       "                                              review  \\\n",
       "0  [html, complete, reference, great, think, good...   \n",
       "1  [stopped, stalingrad, luftwaffe, hitler, defea...   \n",
       "2  [shadow, lion, tried, couple, times, read, tim...   \n",
       "3  [shadow, lion, brilliant, mercedes, descriptio...   \n",
       "4  [climbing, high, woman, account, surviving, ev...   \n",
       "\n",
       "                                   review_lemmatized  \n",
       "0  [html, complete, reference, great, think, good...  \n",
       "1  [stop, stalingrad, luftwaffe, hitler, defeat, ...  \n",
       "2  [shadow, lion, try, couple, time, read, time, ...  \n",
       "3  [shadow, lion, brilliant, mercedes, descriptio...  \n",
       "4  [climb, high, woman, account, survive, everest...  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find spam index\n",
    "spam = findSpam(df_re.review_lemmatized)\n",
    "\n",
    "#make it into index list\n",
    "spam_ind = list(set(spam))\n",
    "\n",
    "#remove spam\n",
    "df_re = df_re.loc[~df_re.index.isin(spam_ind)]\n",
    "\n",
    "#reset index\n",
    "df_re.reset_index(inplace=True)\n",
    "\n",
    "df_re.drop(columns='index',inplace=True)\n",
    "\n",
    "df_re.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/byungchankim/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#process text again\n",
    "df_re['review_lemmatized'] = df_re['review_lemmatized'].apply(lambda x: processText(x))\n",
    "\n",
    "df_re.to_csv('data/upperbound_lemmatized.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consine Similarity**\n",
    "\n",
    "Now that we have the dataset ready, let's try building the review-based recommender system to see how effective it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import titles df so we can match the output asin to title\n",
    "titles = pd.read_csv('data/titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when reading in our word list again, pandas parses it as string instead of list of words.\n",
    "#using literal_eval to fix this\n",
    "df_re = pd.read_csv('data/upperbound_lemmatized.csv',converters={'review_lemmatized': literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate the text for easier processing\n",
    "lemmatized_text = df_re.review_lemmatized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate CountVectorizer with default settings: no lower casing, preprocessing or tokenizing.\n",
    "vectorizer = CountVectorizer(lowercase=False,preprocessor=dummy, tokenizer=dummy, min_df=5, max_df=0.5, max_features=50000)\n",
    "\n",
    "#tokenize and build vocab fitting the corpora then tranform to make count vector\n",
    "count_vector = vectorizer.fit_transform(lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(578449, 50000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate tfidf transformer\n",
    "transformer = TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_vector = transformer.fit_transform(count_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a fairly tuned tfidf vector, we will use this to recommend similar products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Takes in book title to search, tfidf of corpus and number of recommendations\n",
    "\n",
    "Outputs recommendations \n",
    "'''\n",
    "\n",
    "def recommend(book, titles, df, cv, tt, tf, num_rec=5):\n",
    "    \n",
    "    book_text = cleanText(book)\n",
    "    book_text = removeStopwords(book_text)\n",
    "    book_text = lemmatize_words(book_text)\n",
    "    \n",
    "    book_vector = cv.transform([book_text])\n",
    "    book_tfidf = tt.transform(book_vector)\n",
    "    \n",
    "    cosine_matrix = linear_kernel(book_tfidf,tf).flatten()\n",
    "    related_docs_indices = cosine_matrix.argsort()[:-num_rec:-1]\n",
    "\n",
    "    \n",
    "    print('recommending for ',book,'\\n')\n",
    "    \n",
    "    print('recommendations: ')\n",
    "    \n",
    "    for i in related_docs_indices:\n",
    "        \n",
    "        print(titles.loc[titles.asin == df_re.asin.iloc[i]].title)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommending for  HTML Complete Reference \n",
      "\n",
      "recommendations: \n",
      "0    HTML: The Complete Reference\n",
      "Name: title, dtype: object\n",
      "0    HTML: The Complete Reference\n",
      "Name: title, dtype: object\n",
      "0    HTML: The Complete Reference\n",
      "Name: title, dtype: object\n",
      "4833    HTML Goodies\n",
      "Name: title, dtype: object\n",
      "0    HTML: The Complete Reference\n",
      "Name: title, dtype: object\n",
      "0    HTML: The Complete Reference\n",
      "Name: title, dtype: object\n",
      "0    HTML: The Complete Reference\n",
      "Name: title, dtype: object\n",
      "0    HTML: The Complete Reference\n",
      "Name: title, dtype: object\n",
      "25377    HTML 4 for Dummies, Fourth Edition\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "recommend('HTML Complete Reference', titles, df_re, vectorizer, transformer, tfidf_vector, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommending for  Lord of the Rings: Two Towers \n",
      "\n",
      "recommendations: \n",
      "22646    The Dark Tide: Book One of the Iron Tower Trilogy\n",
      "Name: title, dtype: object\n",
      "35736    The Lord of the Rings Weapons and Warfare\n",
      "Name: title, dtype: object\n",
      "23926    The Iron Tower Omnibus (Mithgar)\n",
      "Name: title, dtype: object\n",
      "35790    Dark Tower Boxed Set: v. 1-1v\n",
      "Name: title, dtype: object\n",
      "23926    The Iron Tower Omnibus (Mithgar)\n",
      "Name: title, dtype: object\n",
      "23926    The Iron Tower Omnibus (Mithgar)\n",
      "Name: title, dtype: object\n",
      "13907    The Dark Tower, Books 1-3: The Gunslinger, The...\n",
      "Name: title, dtype: object\n",
      "31607    The Fifth Ring\n",
      "Name: title, dtype: object\n",
      "23926    The Iron Tower Omnibus (Mithgar)\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "recommend('Lord of the Rings: Two Towers', titles, df_re, vectorizer, transformer, tfidf_vector, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommending for  statistics application \n",
      "\n",
      "recommendations: \n",
      "12273    The Lady Tasting Tea: How Statistics Revolutio...\n",
      "Name: title, dtype: object\n",
      "35574    Statistics For Dummies (For Dummies (Math & Sc...\n",
      "Name: title, dtype: object\n",
      "33939    Statistics for the Utterly Confused (Schaum's ...\n",
      "Name: title, dtype: object\n",
      "35574    Statistics For Dummies (For Dummies (Math & Sc...\n",
      "Name: title, dtype: object\n",
      "35574    Statistics For Dummies (For Dummies (Math & Sc...\n",
      "Name: title, dtype: object\n",
      "12273    The Lady Tasting Tea: How Statistics Revolutio...\n",
      "Name: title, dtype: object\n",
      "33939    Statistics for the Utterly Confused (Schaum's ...\n",
      "Name: title, dtype: object\n",
      "35574    Statistics For Dummies (For Dummies (Math & Sc...\n",
      "Name: title, dtype: object\n",
      "17863    History: Fiction or Science?\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "recommend('statistics application', titles, df_re, vectorizer, transformer, tfidf_vector, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our review-based recommender is providing the same recommendation multiple times.  This is due to multiple reviews being available for each books.  We could further expand our recommender to skip the asin if they were selected to be recommendation in the future. However, we are seeing the limitation of review content based recommender system as the keywords are determined by the user reviews.  Although our current recommender system is doing a good job in recommending similar (mostly the same for now) books, there were many manual data trimming involved to keep the corpora manageable.  This means that the corpora itself was built by the decision of the developer to keep certain reviews or not introducing bias.  This may not work best in production situation.\n",
    "\n",
    "Content based filtering is usually applied for situations where we analyze text for titles, descriptions or even transcripts, but not usually a someone's opinion as there are not many variation to describe someone's emotion towards a product as opposed to the product's direct descriptions.\n",
    "\n",
    "As part of building a recommender system for this project, we will take two steps back at this time to create a basic content based recommender system with 1) title of the books,  2) descriptions and genre of the book.\n",
    "\n",
    "We will do this in a separate notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
